// Generated by Mochi v0.10.63 on 2025-08-11 18:38:04 GMT+7

export interface DataPoint { x: number[]; y: number }
function absf(x: number): number {
  if ((x < 0.0)) {
    return -x;
  }
  return x;
}
function hypothesis_value(input: number[], params: number[]): number {
  let value: number = params[(()=>{const _mochi_idx = Math.trunc(0); return _mochi_idx < 0 ? params.length + _mochi_idx : _mochi_idx;})()];
  let i: number = 0;
  while ((i < _len(input))) {
    value = (value + (input[(()=>{const _mochi_idx = i; return _mochi_idx < 0 ? input.length + _mochi_idx : _mochi_idx;})()] * params[(()=>{const _mochi_idx = Math.trunc((i + 1)); return _mochi_idx < 0 ? params.length + _mochi_idx : _mochi_idx;})()]));
    i = (i + 1);
  }
  return value;
}
function calc_error(dp: DataPoint, params: number[]): number {
  return (hypothesis_value(dp.x, params) - dp.y);
}
function summation_of_cost_derivative(index: number, params: number[], data: DataPoint[]): number {
  let sum: number = 0.0;
  let i: number = 0;
  while ((i < _len(data))) {
    let dp: DataPoint = data[(()=>{const _mochi_idx = i; return _mochi_idx < 0 ? data.length + _mochi_idx : _mochi_idx;})()];
    let e: number = calc_error(dp, params);
    if ((index == -1)) {
      sum = (sum + e);
    } else {
      sum = (sum + (e * dp.x[(()=>{const _mochi_idx = index; return _mochi_idx < 0 ? dp.x.length + _mochi_idx : _mochi_idx;})()]));
    }
    i = (i + 1);
  }
  return sum;
}
function get_cost_derivative(index: number, params: number[], data: DataPoint[]): number {
  return (summation_of_cost_derivative(index, params, data) / _len(data));
}
function allclose(a: number[], b: number[], atol: number, rtol: number): boolean {
  let i: number = 0;
  while ((i < _len(a))) {
    let diff: number = absf((a[(()=>{const _mochi_idx = i; return _mochi_idx < 0 ? a.length + _mochi_idx : _mochi_idx;})()] - b[(()=>{const _mochi_idx = i; return _mochi_idx < 0 ? b.length + _mochi_idx : _mochi_idx;})()]));
    let limit: number = (atol + (rtol * absf(b[(()=>{const _mochi_idx = i; return _mochi_idx < 0 ? b.length + _mochi_idx : _mochi_idx;})()])));
    if ((diff > limit)) {
      return false;
    }
    i = (i + 1);
  }
  return true;
}
function run_gradient_descent(train_data: DataPoint[], initial_params: number[]): number[] {
  let learning_rate: number = 0.009;
  let absolute_error_limit: number = 2e-06;
  let relative_error_limit: number = 0.0;
  let j: number = 0;
  let params: number[] = initial_params;
  while (true) {
    j = (j + 1);
    let temp: number[] = [];
    let i: number = 0;
    while ((i < _len(params))) {
      let deriv: number = get_cost_derivative((i - 1), params, train_data);
      temp.push((params[(()=>{const _mochi_idx = i; return _mochi_idx < 0 ? params.length + _mochi_idx : _mochi_idx;})()] - (learning_rate * deriv)));
      i = (i + 1);
    }
    if (allclose(params, temp, absolute_error_limit, relative_error_limit)) {
      console.log(_str(("Number of iterations:" + _str(j))));
      break
    }
    params = temp;
  }
  return params;
}
function test_gradient_descent(test_data: DataPoint[], params: number[]) {
  let i: number = 0;
  while ((i < _len(test_data))) {
    let dp: DataPoint = test_data[(()=>{const _mochi_idx = i; return _mochi_idx < 0 ? test_data.length + _mochi_idx : _mochi_idx;})()];
    console.log(_str(("Actual output value:" + _str(dp.y))));
    console.log(_str(("Hypothesis output:" + _str(hypothesis_value(dp.x, params)))));
    i = (i + 1);
  }
}
let train_data: DataPoint[] = [{"x": [5.0, 2.0, 3.0], "y": 15.0}, {"x": [6.0, 5.0, 9.0], "y": 25.0}, {"x": [11.0, 12.0, 13.0], "y": 41.0}, {"x": [1.0, 1.0, 1.0], "y": 8.0}, {"x": [11.0, 12.0, 13.0], "y": 41.0}];
let test_data: DataPoint[] = [{"x": [515.0, 22.0, 13.0], "y": 555.0}, {"x": [61.0, 35.0, 49.0], "y": 150.0}];
let parameter_vector: number[] = [2.0, 4.0, 1.0, 5.0];
var _nowSeed = 0;
var _nowSeeded = false;
{
  let s = "";
  if (typeof Deno !== "undefined") {
    try {
      s = Deno.env.get("MOCHI_NOW_SEED") ?? "";
    } catch (_e) {
      s = "";
    }
  } else if (typeof process !== "undefined") {
    s = process.env.MOCHI_NOW_SEED || "";
  }
  if (s) {
    const v = parseInt(s, 10);
    if (!isNaN(v)) {
      _nowSeed = v;
      _nowSeeded = true;
    }
  } else {
    _nowSeed = 1;
    _nowSeeded = true;
  }
}
function _now(): number {
  if (_nowSeeded) {
    _nowSeed = (_nowSeed * 1664525 + 1013904223) % 2147483647;
    return _nowSeed;
  }
  if (typeof Deno !== 'undefined') {
    return Math.trunc(performance.now() * 1e6);
  }
  if (typeof performance !== 'undefined') {
    return Math.trunc(performance.now() * 1e6);
  }
  return Date.now() * 1000;
}
function _mem(): number {
  if (typeof Deno !== 'undefined') {
    return (Deno.memoryUsage?.().heapUsed ?? 0);
  }
  if (typeof process !== 'undefined') {
    return process.memoryUsage().heapUsed;
  }
  if (typeof performance !== 'undefined' && (performance as any).memory) {
    return (performance as any).memory.usedJSHeapSize;
  }
  return 0;
}
function _len(x: any): number { return Array.isArray(x) || typeof x === 'string' ? x.length : Object.keys(x ?? {}).length; }
function _str(x: any): string {
  if (typeof x === 'number') {
    if (Object.is(x, -0)) return '-0';
    if (x === Infinity) return '+Inf';
    if (x === -Infinity) return '-Inf';
    if (Number.isNaN(x)) return 'NaN';
  }
  return String(x);
}
(() => {
  globalThis.gc?.()
  const _startMem = _mem()
  const _start = _now()
  parameter_vector = run_gradient_descent(train_data, parameter_vector);
  console.log(_str("\nTesting gradient descent for a linear hypothesis function.\n"));
  test_gradient_descent(test_data, parameter_vector);
  const _end = _now()
  const _duration = _end - _start
  const _duration_us = Math.trunc(_duration / 1000)
  globalThis.gc?.()
  const _endMem = _mem()
  const _memory_bytes = Math.max(0, _endMem - _startMem)
  console.log(JSON.stringify({
    "duration_us": _duration_us,
    "memory_bytes": _memory_bytes,
    "name": "main"
  }, null, "  "))
})();

