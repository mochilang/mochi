// Generated by Mochi transpiler v0.10.63
use std::sync::atomic::{AtomicBool, AtomicI64, Ordering};
use std::time::{SystemTime, UNIX_EPOCH};
static NOW_SEEDED: AtomicBool = AtomicBool::new(false);
static NOW_SEED: AtomicI64 = AtomicI64::new(0);
fn _now() -> i64 {
    if !NOW_SEEDED.load(Ordering::SeqCst) {
        if let Ok(s) = std::env::var("MOCHI_NOW_SEED") {
            if let Ok(v) = s.parse::<i64>() {
                NOW_SEED.store(v, Ordering::SeqCst);
                NOW_SEEDED.store(true, Ordering::SeqCst);
            }
        }
    }
    if NOW_SEEDED.load(Ordering::SeqCst) {
        let seed = (NOW_SEED.load(Ordering::SeqCst)*1664525 + 1013904223) % 2147483647;
        NOW_SEED.store(seed, Ordering::SeqCst);
        seed
    } else {
        SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_nanos() as i64
    }
}
fn _mem() -> i64 {
    if let Ok(mut f) = std::fs::File::open("/proc/self/statm") {
        let mut s = String::new();
        use std::io::Read;
        if f.read_to_string(&mut s).is_ok() {
            if let Some(rss) = s.split_whitespace().nth(1) {
                if let Ok(v) = rss.parse::<i64>() {
                    return v * 4096;
                }
            }
        }
    }
    0
}
fn main() {
        let _start: i64 = _now();
    fn int_to_float(mut x: i64) -> f64 {
    return ((x as f64) * 1.0)
};
    fn abs_float(mut x: f64) -> f64 {
    if (x < 0.0) {
        return (0.0 - x)
    }
    return x
};
    fn exp_approx(mut x: f64) -> f64 {
    let mut term: f64 = 1.0;
    let mut sum: f64 = 1.0;
    let mut i: i64 = 1;
    while (i < 10) {
        term = ((term * x) / int_to_float(i));
        sum = (sum + term);
        i = (i + 1);
    }
    return sum
};
    fn floor_int(mut x: f64) -> i64 {
    let mut i: i64 = 0;
    while (int_to_float((i + 1)) <= x) {
        i = (i + 1);
    }
    return i
};
    fn dot(mut a: Vec<f64>, mut b: Vec<f64>) -> f64 {
    let mut s: f64 = 0.0;
    let mut i: i64 = 0;
    while (i < (a.len() as i64)) {
        s = (s + (a[i as usize] * b[i as usize]));
        i = (i + 1);
    }
    return s
};
    fn transpose(mut m: Vec<Vec<f64>>) -> Vec<Vec<f64>> {
    let mut rows: i64 = (m.len() as i64);
    let mut cols: i64 = (m[0 as usize].clone().len() as i64);
    let mut res: Vec<Vec<f64>> = vec![];
    let mut j: i64 = 0;
    while (j < cols) {
        let mut row: Vec<f64> = vec![];
        let mut i: i64 = 0;
        while (i < rows) {
            row = { let mut _v = row.clone(); _v.push(m[i as usize].clone()[j as usize]); _v };
            i = (i + 1);
        }
        res = { let mut _v = res.clone(); _v.push(row.clone()); _v };
        j = (j + 1);
    }
    return res
};
    fn matmul(mut a: Vec<Vec<f64>>, mut b: Vec<Vec<f64>>) -> Vec<Vec<f64>> {
    let mut n: i64 = (a.len() as i64);
    let mut m: i64 = (b[0 as usize].clone().len() as i64);
    let mut p: i64 = (b.len() as i64);
    let mut res: Vec<Vec<f64>> = vec![];
    let mut i: i64 = 0;
    while (i < n) {
        let mut row: Vec<f64> = vec![];
        let mut j: i64 = 0;
        while (j < m) {
            let mut s: f64 = 0.0;
            let mut k: i64 = 0;
            while (k < p) {
                s = (s + (a[i as usize].clone()[k as usize] * b[k as usize].clone()[j as usize]));
                k = (k + 1);
            }
            row = { let mut _v = row.clone(); _v.push(s); _v };
            j = (j + 1);
        }
        res = { let mut _v = res.clone(); _v.push(row.clone()); _v };
        i = (i + 1);
    }
    return res
};
    fn matvec(mut a: Vec<Vec<f64>>, mut b: Vec<f64>) -> Vec<f64> {
    let mut res: Vec<f64> = vec![];
    let mut i: i64 = 0;
    while (i < (a.len() as i64)) {
        res = { let mut _v = res.clone(); _v.push(dot(a[i as usize].clone(), b.clone())); _v };
        i = (i + 1);
    }
    return res
};
    fn identity(mut n: i64) -> Vec<Vec<f64>> {
    let mut res: Vec<Vec<f64>> = vec![];
    let mut i: i64 = 0;
    while (i < n) {
        let mut row: Vec<f64> = vec![];
        let mut j: i64 = 0;
        while (j < n) {
            row = { let mut _v = row.clone(); _v.push(if (i == j) { 1.0 } else { 0.0 }); _v };
            j = (j + 1);
        }
        res = { let mut _v = res.clone(); _v.push(row.clone()); _v };
        i = (i + 1);
    }
    return res
};
    fn invert(mut mat: Vec<Vec<f64>>) -> Vec<Vec<f64>> {
    let mut n: i64 = (mat.len() as i64);
    let mut a: Vec<Vec<f64>> = mat.clone();
    let mut inv: Vec<Vec<f64>> = identity(n);
    let mut i: i64 = 0;
    while (i < n) {
        let mut pivot: f64 = a[i as usize].clone()[i as usize];
        let mut j: i64 = 0;
        while (j < n) {
            a[i as usize][j as usize] = (a[i as usize].clone()[j as usize] / pivot);
            inv[i as usize][j as usize] = (inv[i as usize].clone()[j as usize] / pivot);
            j = (j + 1);
        }
        let mut k: i64 = 0;
        while (k < n) {
            if (k != i) {
                let mut factor: f64 = a[k as usize].clone()[i as usize];
                j = 0;
                while (j < n) {
                    a[k as usize][j as usize] = (a[k as usize].clone()[j as usize] - (factor * a[i as usize].clone()[j as usize]));
                    inv[k as usize][j as usize] = (inv[k as usize].clone()[j as usize] - (factor * inv[i as usize].clone()[j as usize]));
                    j = (j + 1);
                }
            }
            k = (k + 1);
        }
        i = (i + 1);
    }
    return inv
};
    fn normal_equation(mut X: Vec<Vec<f64>>, mut y: Vec<f64>) -> Vec<f64> {
    let mut Xt: Vec<Vec<f64>> = transpose(X.clone());
    let mut XtX: Vec<Vec<f64>> = matmul(Xt.clone(), X.clone());
    let mut XtX_inv: Vec<Vec<f64>> = invert(XtX.clone());
    let mut Xty: Vec<f64> = matvec(Xt.clone(), y.clone());
    return matvec(XtX_inv.clone(), Xty.clone())
};
    fn linear_regression_prediction(mut train_dt: Vec<f64>, mut train_usr: Vec<f64>, mut train_mtch: Vec<f64>, mut test_dt: Vec<f64>, mut test_mtch: Vec<f64>) -> f64 {
    let mut X: Vec<Vec<f64>> = vec![];
    let mut i: i64 = 0;
    while (i < (train_dt.len() as i64)) {
        X = { let mut _v = X.clone(); _v.push(vec![1.0, train_dt[i as usize], train_mtch[i as usize]]); _v };
        i = (i + 1);
    }
    let mut beta: Vec<f64> = normal_equation(X.clone(), train_usr.clone());
    return abs_float(((beta[0 as usize] + (test_dt[0 as usize] * beta[1 as usize])) + (test_mtch[0 as usize] * beta[2 as usize])))
};
    fn sarimax_predictor(mut train_user: Vec<f64>, mut train_match: Vec<f64>, mut test_match: Vec<f64>) -> f64 {
    let mut n: i64 = (train_user.len() as i64);
    let mut X: Vec<Vec<f64>> = vec![];
    let mut y: Vec<f64> = vec![];
    let mut i: i64 = 1;
    while (i < n) {
        X = { let mut _v = X.clone(); _v.push(vec![1.0, train_user[(i - 1) as usize], train_match[i as usize]]); _v };
        y = { let mut _v = y.clone(); _v.push(train_user[i as usize]); _v };
        i = (i + 1);
    }
    let mut beta: Vec<f64> = normal_equation(X.clone(), y.clone());
    return ((beta[0 as usize] + (beta[1 as usize] * train_user[(n - 1) as usize])) + (beta[2 as usize] * test_match[0 as usize]))
};
    fn rbf_kernel(mut a: Vec<f64>, mut b: Vec<f64>, mut gamma: f64) -> f64 {
    let mut sum: f64 = 0.0;
    let mut i: i64 = 0;
    while (i < (a.len() as i64)) {
        let mut diff: f64 = (a[i as usize] - b[i as usize]);
        sum = (sum + (diff * diff));
        i = (i + 1);
    }
    return exp_approx((-gamma * sum))
};
    fn support_vector_regressor(mut x_train: Vec<Vec<f64>>, mut x_test: Vec<Vec<f64>>, mut train_user: Vec<f64>) -> f64 {
    let mut gamma: f64 = 0.1;
    let mut weights: Vec<f64> = vec![];
    let mut i: i64 = 0;
    while (i < (x_train.len() as i64)) {
        weights = { let mut _v = weights.clone(); _v.push(rbf_kernel(x_train[i as usize].clone(), x_test[0 as usize].clone(), gamma)); _v };
        i = (i + 1);
    }
    let mut num: f64 = 0.0;
    let mut den: f64 = 0.0;
    i = 0;
    while (i < (train_user.len() as i64)) {
        num = (num + (weights[i as usize] * train_user[i as usize]));
        den = (den + weights[i as usize]);
        i = (i + 1);
    }
    return (num / den)
};
    fn set_at_float(mut xs: Vec<f64>, mut idx: i64, mut value: f64) -> Vec<f64> {
    let mut i: i64 = 0;
    let mut res: Vec<f64> = vec![];
    while (i < (xs.len() as i64)) {
        if (i == idx) {
            res = { let mut _v = res.clone(); _v.push(value); _v };
        } else {
            res = { let mut _v = res.clone(); _v.push(xs[i as usize]); _v };
        }
        i = (i + 1);
    }
    return res
};
    fn sort_float(mut xs: Vec<f64>) -> Vec<f64> {
    let mut res: Vec<f64> = xs.clone();
    let mut i: i64 = 1;
    while (i < (res.len() as i64)) {
        let mut key: f64 = res[i as usize];
        let mut j: i64 = (i - 1);
        while ((j >= 0) && (res[j as usize] > key)) {
            res = set_at_float(res.clone(), (j + 1), res[j as usize]);
            j = (j - 1);
        }
        res = set_at_float(res.clone(), (j + 1), key);
        i = (i + 1);
    }
    return res
};
    fn percentile(mut data: Vec<f64>, mut q: f64) -> f64 {
    let mut sorted: Vec<f64> = sort_float(data.clone());
    let mut n: i64 = (sorted.len() as i64);
    let mut pos: f64 = ((q / 100.0) * int_to_float((n - 1)));
    let mut idx: i64 = floor_int(pos);
    let mut frac: f64 = (pos - int_to_float(idx));
    if ((idx + 1) < n) {
        return ((sorted[idx as usize] * (1.0 - frac)) + (sorted[(idx + 1) as usize] * frac))
    }
    return sorted[idx as usize]
};
    fn interquartile_range_checker(mut train_user: Vec<f64>) -> f64 {
    let mut q1: f64 = percentile(train_user.clone(), 25.0);
    let mut q3: f64 = percentile(train_user.clone(), 75.0);
    let mut iqr: f64 = (q3 - q1);
    return (q1 - (iqr * 0.1))
};
    fn data_safety_checker(mut list_vote: Vec<f64>, mut actual_result: f64) -> bool {
    let mut safe: i64 = 0;
    let mut not_safe: i64 = 0;
    let mut i: i64 = 0;
    while (i < (list_vote.len() as i64)) {
        let mut v: f64 = list_vote[i as usize];
        if (v > actual_result) {
            safe = (not_safe + 1);
        } else if (abs_float((abs_float(v) - abs_float(actual_result))) <= 0.1) {
            safe = (safe + 1);
        } else {
            not_safe = (not_safe + 1);
        }
        i = (i + 1);
    }
    return (safe > not_safe)
};
    fn mochi_main() {
    let mut vote: Vec<f64> = vec![linear_regression_prediction(vec![2.0, 3.0, 4.0, 5.0], vec![5.0, 3.0, 4.0, 6.0], vec![3.0, 1.0, 2.0, 4.0], vec![2.0], vec![2.0]), sarimax_predictor(vec![4.0, 2.0, 6.0, 8.0], vec![3.0, 1.0, 2.0, 4.0], vec![2.0]), support_vector_regressor(vec![vec![5.0, 2.0].clone(), vec![1.0, 5.0].clone(), vec![6.0, 2.0].clone()], vec![vec![3.0, 2.0].clone()], vec![2.0, 1.0, 4.0])];
    println!("{}", format!("{:?}", vote[0 as usize]));
    println!("{}", format!("{:?}", vote[1 as usize]));
    println!("{}", format!("{:?}", vote[2 as usize]));
    println!("{}", if data_safety_checker(vote.clone(), 5.0) { 1 } else { 0 });
};
    mochi_main();
    let _end: i64 = _now();
    let duration_us: i64 = ((_end - _start) / 1000);
    let memory_bytes: i64 = _mem();
    println!("{{\n  \"duration_us\": {},\n  \"memory_bytes\": {},\n  \"name\": \"{}\"\n}}", duration_us, memory_bytes, "main");

}
