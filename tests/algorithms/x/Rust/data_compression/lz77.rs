// Generated by Mochi transpiler v0.10.60
use std::sync::atomic::{AtomicBool, AtomicI64, Ordering};
use std::time::{SystemTime, UNIX_EPOCH};
static NOW_SEEDED: AtomicBool = AtomicBool::new(false);
static NOW_SEED: AtomicI64 = AtomicI64::new(0);
fn _now() -> i64 {
    if !NOW_SEEDED.load(Ordering::SeqCst) {
        if let Ok(s) = std::env::var("MOCHI_NOW_SEED") {
            if let Ok(v) = s.parse::<i64>() {
                NOW_SEED.store(v, Ordering::SeqCst);
                NOW_SEEDED.store(true, Ordering::SeqCst);
            }
        }
    }
    if NOW_SEEDED.load(Ordering::SeqCst) {
        let seed = (NOW_SEED.load(Ordering::SeqCst)*1664525 + 1013904223) % 2147483647;
        NOW_SEED.store(seed, Ordering::SeqCst);
        seed
    } else {
        SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_nanos() as i64
    }
}
fn _mem() -> i64 {
    if let Ok(mut f) = std::fs::File::open("/proc/self/statm") {
        let mut s = String::new();
        use std::io::Read;
        if f.read_to_string(&mut s).is_ok() {
            if let Some(rss) = s.split_whitespace().nth(1) {
                if let Ok(v) = rss.parse::<i64>() {
                    return v * 4096;
                }
            }
        }
    }
    0
}
#[derive(Debug, Clone, Default)]
struct Token {
    offset: i64,
    length: i64,
    indicator: String,
}
impl std::fmt::Display for Token {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{{")?;
        write!(f, "\"offset\": {}", self.offset)?;
        write!(f, ", ")?;
        write!(f, "\"length\": {}", self.length)?;
        write!(f, ", ")?;
        write!(f, "\"indicator\": \"{}\"", self.indicator)?;
        write!(f, "}}")
    }
}

static mut g_tokens_example: Vec<Token> = Vec::new();
fn main() {
    unsafe {
        g_tokens_example = vec![Token {offset: 0, length: 0, indicator: String::from("c")}, Token {offset: 0, length: 0, indicator: String::from("a")}, Token {offset: 0, length: 0, indicator: String::from("b")}, Token {offset: 0, length: 0, indicator: String::from("r")}, Token {offset: 3, length: 1, indicator: String::from("c")}, Token {offset: 2, length: 1, indicator: String::from("d")}, Token {offset: 7, length: 4, indicator: String::from("r")}, Token {offset: 3, length: 5, indicator: String::from("d")}];
                let _start: i64 = _now();
        unsafe fn token_to_string(t: &Token) -> String {
    return format!("{}{}", format!("{}{}", format!("{}{}", format!("{}{}", format!("{}{}", format!("{}{}", "(", t.offset.to_string()), ", "), t.length.to_string()), ", "), t.indicator.clone()), ")").clone()
};
        unsafe fn tokens_to_string(mut ts: Vec<Token>) -> String {
    let mut res: String = String::from("[").clone();
    let mut i: i64 = 0;
    while (i < (ts.len() as i64)) {
        res = format!("{}{}", res, token_to_string(&ts[i as usize].clone()));
        if (i < ((ts.len() as i64) - 1)) {
            res = format!("{}{}", res, ", ");
        }
        i = (i + 1);
    }
    return format!("{}{}", res, "]").clone()
};
        unsafe fn match_length_from_index(mut text: String, window: &str, mut text_index: i64, mut window_index: i64) -> i64 {
    if ((text_index >= (text.len() as i64)) || (window_index >= (window.len() as i64))) {
        return 0
    }
    let mut tc: String = { let tmp = &text; tmp.chars().skip(text_index as usize).take(((text_index + 1) - text_index) as usize).collect::<String>() }.clone();
    let mut wc: String = { let tmp = &window; tmp.chars().skip(window_index as usize).take(((window_index + 1) - window_index) as usize).collect::<String>() }.clone();
    if (tc.as_str() != wc.as_str()) {
        return 0
    }
    return (1 + match_length_from_index(text.clone(), &format!("{}{}", window, tc), (text_index + 1), (window_index + 1)))
};
        unsafe fn find_encoding_token(mut text: String, search_buffer: &str) -> Token {
    if ((text.len() as i64) == 0) {
        panic!("We need some text to work with.");
    }
    let mut length: i64 = 0;
    let mut offset: i64 = 0;
    if ((search_buffer.len() as i64) == 0) {
        return Token {offset: offset, length: length, indicator: { let tmp = &text; tmp.chars().skip(0 as usize).take((1 - 0) as usize).collect::<String>() }.clone()}
    }
    let mut i: i64 = 0;
    while (i < (search_buffer.len() as i64)) {
        let mut ch: String = { let tmp = &search_buffer; tmp.chars().skip(i as usize).take(((i + 1) - i) as usize).collect::<String>() }.clone();
        let mut found_offset = ((search_buffer.len() as i64) - i);
        if (ch.as_str() == { let tmp = &text; tmp.chars().skip(0 as usize).take((1 - 0) as usize).collect::<String>() }.as_str()) {
            let mut found_length: i64 = match_length_from_index(text.clone(), search_buffer, 0, i);
            if (found_length >= length) {
                offset = found_offset;
                length = found_length;
            }
        }
        i = (i + 1);
    }
    return Token {offset: offset, length: length, indicator: { let tmp = &text; tmp.chars().skip(length as usize).take(((length + 1) - length) as usize).collect::<String>() }.clone()}
};
        unsafe fn lz77_compress(text: &str, mut window_size: i64, mut lookahead: i64) -> Vec<Token> {
    let mut search_buffer_size: i64 = (window_size - lookahead);
    let mut output: Vec<Token> = vec![];
    let mut search_buffer: String = String::from("").clone();
    let mut remaining: String = text.to_string().clone();
    while ((remaining.len() as i64) > 0) {
        let mut token: Token = find_encoding_token(remaining.clone(), &search_buffer);
        let mut add_len: i64 = (token.length + 1);
        search_buffer = format!("{}{}", search_buffer, { let tmp = &remaining; tmp.chars().skip(0 as usize).take((add_len - 0) as usize).collect::<String>() });
        if ((search_buffer.len() as i64) > search_buffer_size) {
            search_buffer = { let tmp = &search_buffer; tmp.chars().skip(((search_buffer.len() as i64) - search_buffer_size) as usize).take(((search_buffer.len() as i64) - ((search_buffer.len() as i64) - search_buffer_size)) as usize).collect::<String>() };
        }
        remaining = { let tmp = &remaining; tmp.chars().skip(add_len as usize).take(((remaining.len() as i64) - add_len) as usize).collect::<String>() };
        output = { let mut _v = output.clone(); _v.push(token.clone()); _v };
    }
    return output
};
        unsafe fn lz77_decompress(mut tokens: Vec<Token>) -> String {
    let mut output: String = String::from("").clone();
    for t in tokens.iter().cloned() {
        let mut i: i64 = 0;
        while (i < t.length) {
            output = format!("{}{}", output, { let tmp = &output; tmp.chars().skip(((output.len() as i64) - t.offset) as usize).take(((((output.len() as i64) - t.offset) + 1) - ((output.len() as i64) - t.offset)) as usize).collect::<String>() });
            i = (i + 1);
        }
        output = format!("{}{}", output, t.indicator);
    }
    return output.clone()
};
        let mut c1: Vec<Token> = lz77_compress(&"ababcbababaa", 13, 6);
        println!("{}", tokens_to_string(c1.clone()));
        let mut c2: Vec<Token> = lz77_compress(&"aacaacabcabaaac", 13, 6);
        println!("{}", tokens_to_string(c2.clone()));
        println!("{}", lz77_decompress(g_tokens_example.clone().clone()));
        let _end: i64 = _now();
        let duration_us: i64 = ((_end - _start) / 1000);
        let memory_bytes: i64 = _mem();
        println!("{{\n  \"duration_us\": {},\n  \"memory_bytes\": {},\n  \"name\": \"{}\"\n}}", duration_us, memory_bytes, "main");

    }
}
