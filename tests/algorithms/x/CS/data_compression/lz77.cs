// Generated by Mochi 0.10.59 on 2025-08-06 22:16 +0700
using System;
using System.Collections.Generic;
using System.Linq;
using System.Text.Json;
using System.Numerics;
using System.Collections;

class Token {
    public long offset;
    public long length;
    public string indicator;
    public override string ToString() => $"Token {{offset = {offset}, length = {length}, indicator = \"{indicator}\"}}";
}
class Program {
    static bool seededNow = false;
    static long nowSeed = 0;
    static long _now() {
        if (!seededNow) {
            var s = Environment.GetEnvironmentVariable("MOCHI_NOW_SEED");
            if (long.TryParse(s, out var v)) {
                nowSeed = v;
                seededNow = true;
            }
        }
        if (seededNow) {
            nowSeed = unchecked(nowSeed * 1664525 + 1013904223);
            nowSeed %= 9223372036854775783L;
            if (nowSeed < 0) nowSeed += 9223372036854775783L;
            return nowSeed;
        }
        return DateTime.UtcNow.Ticks / 100;
    }
    static long _mem() {
        return GC.GetTotalAllocatedBytes(true);
    }
    static long _len(object v) {
        if (v is Array a) return a.Length;
        if (v is string s) return s.Length;
        if (v is System.Collections.ICollection c) return c.Count;
        return Convert.ToString(v).Length;
    }
    static string _substr(string s, long start, long end) {
        if (start < 0) start = 0;
        if (end < 0) end = 0;
        if (start > s.Length) start = s.Length;
        if (end > s.Length) end = s.Length;
        if (start > end) start = end;
        return s.Substring((int)start, (int)(end - start));
    }
    static string _fmt(object v) {
        if (v is Array a) {
            var parts = new List<string>();
            foreach (var x in a) parts.Add(_fmt(x));
            return "[" + string.Join(", ", parts) + "]";
        }
        if (v is System.Collections.IDictionary d) {
            var keys = new List<string>();
            foreach (var k in d.Keys) keys.Add(k.ToString());
            keys.Sort();
            var parts = new List<string>();
            foreach (var k in keys) parts.Add(k + ":" + _fmt(d[k]));
            return "map[" + string.Join(", ", parts) + "]";
        }
        if (v is System.Collections.IEnumerable e && !(v is string)) {
            var parts = new List<string>();
            foreach (var x in e) parts.Add(_fmt(x));
            return string.Join(", ", parts);
        }
        if (v is string s) return "\"" + s.Replace("\"", "\\\"") + "\"";
        if (v is bool b) return b ? "true" : "false";
        return Convert.ToString(v);
    }
    static string _fmtStr(object v) {
        if (v is Array a) {
            var parts = new List<string>();
            foreach (var x in a) parts.Add(_fmtStr(x));
            return "[" + string.Join(" ", parts) + "]";
        }
        if (v is System.Collections.IDictionary d) {
            var keys = new List<string>();
            foreach (var k in d.Keys) keys.Add(k.ToString());
            keys.Sort();
            var parts = new List<string>();
            foreach (var k in keys) parts.Add(k + ":" + _fmtStr(d[k]));
            return "map[" + string.Join(" ", parts) + "]";
        }
        if (v is System.Collections.IEnumerable e && !(v is string)) {
            var parts = new List<string>();
            foreach (var x in e) parts.Add(_fmtStr(x));
            return string.Join(" ", parts);
        }
        if (v is string s) return "\"" + s.Replace("\"", "\\\"") + "\"";
        if (v is bool b) return b ? "true" : "false";
        return Convert.ToString(v);
    }
    public static string _fmtTop(object v) {
        if (v is Array a && a.Length > 0 && a.GetValue(0) is Array) {
            var parts = new List<string>();
            foreach (var x in a) parts.Add(_fmt(x));
            return string.Join(" ", parts);
        }
        if (v is string s) return s;
        return _fmt(v);
    }
    static Token[] c1_31 = Program.lz77_compress("ababcbababaa", 13, 6);
    public static string token_to_string(Token t_0) {
        return (((((("(" + _fmtStr(t_0.offset)) + ", ") + _fmtStr(t_0.length)) + ", ") + t_0.indicator) + ")");
    }

    public static string tokens_to_string(Token[] ts_1) {
        string res_2 = "[";
        long i_3 = 0;
        while ((i_3 < ts_1.Length)) {
            res_2 = (res_2 + Program.token_to_string(ts_1[(int)(i_3)]));
            if ((i_3 < (ts_1.Length - 1))) {
                res_2 = (res_2 + ", ");
            }
            i_3 = (i_3 + 1);
        };
        return (res_2 + "]");
    }

    public static long match_length_from_index(string text_4, string window_5, long text_index_6, long window_index_7) {
        if (((text_index_6 >= text_4.Length) || (window_index_7 >= window_5.Length))) {
            return 0;
        };
        string tc_8 = _substr(text_4, text_index_6, (text_index_6 + 1));
        string wc_9 = _substr(window_5, window_index_7, (window_index_7 + 1));
        if ((tc_8 != wc_9)) {
            return 0;
        };
        return (1 + Program.match_length_from_index(text_4, (window_5 + tc_8), (text_index_6 + 1), (window_index_7 + 1)));
    }

    public static Token find_encoding_token(string text_10, string search_buffer_11) {
        if ((text_10.Length == 0)) {
            throw new Exception("We need some text to work with.");
        };
        long length_12 = 0;
        long offset_13 = 0;
        if ((search_buffer_11.Length == 0)) {
            return new Token{offset = offset_13, length = length_12, indicator = _substr(text_10, 0, 1)};
        };
        long i_14 = 0;
        while ((i_14 < search_buffer_11.Length)) {
            string ch_15 = _substr(search_buffer_11, i_14, (i_14 + 1));
            long found_offset_16 = (search_buffer_11.Length - i_14);
            if ((ch_15 == _substr(text_10, 0, 1))) {
                long found_length_17 = Program.match_length_from_index(text_10, search_buffer_11, 0, i_14);
                if ((found_length_17 >= length_12)) {
                    offset_13 = found_offset_16;
                    length_12 = found_length_17;
                }
            }
            i_14 = (i_14 + 1);
        };
        return new Token{offset = offset_13, length = length_12, indicator = _substr(text_10, length_12, (length_12 + 1))};
    }

    public static Token[] lz77_compress(string text_18, long window_size_19, long lookahead_20) {
        long search_buffer_size_21 = (window_size_19 - lookahead_20);
        Token[] output_22 = new Token[]{};
        string search_buffer_23 = "";
        string remaining_24 = text_18;
        while ((remaining_24.Length > 0)) {
            Token token_25 = Program.find_encoding_token(remaining_24, search_buffer_23);
            long add_len_26 = (token_25.length + 1);
            search_buffer_23 = (search_buffer_23 + _substr(remaining_24, 0, add_len_26));
            if ((search_buffer_23.Length > search_buffer_size_21)) {
                search_buffer_23 = _substr(search_buffer_23, (search_buffer_23.Length - search_buffer_size_21), search_buffer_23.Length);
            }
            remaining_24 = _substr(remaining_24, add_len_26, remaining_24.Length);
            output_22 = (Enumerable.ToArray(Enumerable.Append<Token>(output_22, token_25)));
        };
        return output_22;
    }

    public static string lz77_decompress(Token[] tokens_27) {
        string output_28 = "";
        foreach (Token t_29 in tokens_27) {
            long i_30 = 0;
            while ((i_30 < t_29.length)) {
                output_28 = (output_28 + _substr(output_28, (output_28.Length - t_29.offset), ((output_28.Length - t_29.offset) + 1)));
                i_30 = (i_30 + 1);
            }
            output_28 = (output_28 + t_29.indicator);
        };
        return output_28;
    }

    static void Main() {
        {
            var __memStart = _mem();
            var __start = _now();
            Console.WriteLine(Program._fmtTop(Program.tokens_to_string(c1_31)));
            Token[] c2_32 = Program.lz77_compress("aacaacabcabaaac", 13, 6);
            Console.WriteLine(Program._fmtTop(Program.tokens_to_string(c2_32)));
            Token[] tokens_example_33 = new Token[]{new Token{offset = 0, length = 0, indicator = "c"}, new Token{offset = 0, length = 0, indicator = "a"}, new Token{offset = 0, length = 0, indicator = "b"}, new Token{offset = 0, length = 0, indicator = "r"}, new Token{offset = 3, length = 1, indicator = "c"}, new Token{offset = 2, length = 1, indicator = "d"}, new Token{offset = 7, length = 4, indicator = "r"}, new Token{offset = 3, length = 5, indicator = "d"}};
            Console.WriteLine(Program._fmtTop(Program.lz77_decompress(tokens_example_33)));
            var __end = _now();
            var __memEnd = _mem();
            var __dur = (__end - __start);
            if (__dur <= 0) __dur = 1;
            var __memDiff = __memEnd - __memStart;
            if (__memDiff <= 0) __memDiff = __memEnd;
            Console.WriteLine("{\"name\":\"main\",\"duration_us\":" + __dur + ",\"memory_bytes\":" + __memDiff + "}");
        }
    }
}
