# Code generated by Mochi transpiler.
# Version 0.10.61, generated on 2025-08-08 17:42 +0700
from __future__ import annotations
from dataclasses import dataclass
from typing import List, Dict
import dataclasses

import sys
sys.set_int_max_str_digits(0)
import os
if os.path.dirname(__file__) in sys.path:
    sys.path.remove(os.path.dirname(__file__))


def panic(msg):
    raise RuntimeError(msg)


def _concat(a, b):
    if a is None:
        return b
    if b is None:
        return a
    return a + b


def _append(lst, v):
    return (lst or []) + [v]


def _str(v):
    if isinstance(v, float) and v.is_integer():
        return str(int(v))
    return str(v)

@dataclass
class DataSet:
    images: [[int]]
    labels: [[int]]
    num_examples: int
    index_in_epoch: int
    epochs_completed: int

@dataclass
class Datasets:
    train: DataSet
    validation: DataSet
    test_ds: DataSet

def dense_to_one_hot(labels, num_classes):
    result = []
    i = 0
    while i < len(labels):
        row = []
        j = 0
        while j < num_classes:
            if j == labels[i]:
                row = _append(row, 1)
            else:
                row = _append(row, 0)
            j = j + 1
        result = _append(result, row)
        i = i + 1
    return result
def new_dataset(images, labels):
    return DataSet(images=images, labels=labels, num_examples=len(images), index_in_epoch=0, epochs_completed=0)
@dataclass
class BatchResult:
    dataset: DataSet
    images: [[int]]
    labels: [[int]]

def next_batch(ds, batch_size):
    start = ds.index_in_epoch
    if start + batch_size > ds.num_examples:
        rest = ds.num_examples - start
        images_rest = ds.images[start:ds.num_examples]
        labels_rest = ds.labels[start:ds.num_examples]
        new_index = batch_size - rest
        images_new = ds.images[0:new_index]
        labels_new = ds.labels[0:new_index]
        batch_images = _concat(images_rest, images_new)
        batch_labels = _concat(labels_rest, labels_new)
        new_ds = DataSet(images=ds.images, labels=ds.labels, num_examples=ds.num_examples, index_in_epoch=new_index, epochs_completed=ds.epochs_completed + 1)
        return BatchResult(dataset=new_ds, images=batch_images, labels=batch_labels)
    else:
        end = start + batch_size
        batch_images = ds.images[start:end]
        batch_labels = ds.labels[start:end]
        new_ds = DataSet(images=ds.images, labels=ds.labels, num_examples=ds.num_examples, index_in_epoch=end, epochs_completed=ds.epochs_completed)
        return BatchResult(dataset=new_ds, images=batch_images, labels=batch_labels)
def read_data_sets(train_images, train_labels_raw, test_images, test_labels_raw, validation_size, num_classes):
    train_labels = dense_to_one_hot(train_labels_raw, num_classes)
    test_labels = dense_to_one_hot(test_labels_raw, num_classes)
    validation_images = train_images[0:validation_size]
    validation_labels = train_labels[0:validation_size]
    train_images_rest = train_images[validation_size:len(train_images)]
    train_labels_rest = train_labels[validation_size:len(train_labels)]
    train = new_dataset(train_images_rest, train_labels_rest)
    validation = new_dataset(validation_images, validation_labels)
    testset = new_dataset(test_images, test_labels)
    return Datasets(train=train, validation=validation, test_ds=testset)
def main():
    train_images = [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5]]
    train_labels_raw = [0, 1, 2, 3, 4]
    test_images = [[5, 6], [6, 7]]
    test_labels_raw = [5, 6]
    data = read_data_sets(train_images, train_labels_raw, test_images, test_labels_raw, 2, 10)
    ds = data.train
    res = next_batch(ds, 2)
    ds = res.dataset
    print(_str(res.images))
    print(_str(res.labels))
    res = next_batch(ds, 2)
    ds = res.dataset
    print(_str(res.images))
    print(_str(res.labels))
    res = next_batch(ds, 2)
    ds = res.dataset
    print(_str(res.images))
    print(_str(res.labels))
main()
