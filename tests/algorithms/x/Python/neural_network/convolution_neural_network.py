# Code generated by Mochi transpiler.
# Version 0.10.64, generated on 2025-08-12 15:27 +0700
from __future__ import annotations
from dataclasses import dataclass
from typing import List, Dict
import dataclasses
import json
import time

try:
    import resource
except Exception:
    resource = None
import sys
if hasattr(sys, "set_int_max_str_digits"):
    sys.set_int_max_str_digits(0)
import os
if os.path.dirname(__file__) in sys.path:
    sys.path.remove(os.path.dirname(__file__))


_now_seed = 0
_now_seeded = False
s = os.getenv("MOCHI_NOW_SEED")
if s and s != "":
    try:
        _now_seed = int(s)
        _now_seeded = True
    except Exception:
        pass

def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())


def _append(lst, v):
    return (lst or []) + [v]


def _set_index(lst, idx, val):
    if lst is None:
        lst = []
    if idx >= len(lst):
        lst.extend([None] * (idx - len(lst) + 1))
    lst[idx] = val
    return lst

@dataclass
class CNN:
    conv_kernels: [[[float]]]
    conv_bias: [float]
    conv_step: int
    pool_size: int
    w_hidden: [[float]]
    w_out: [[float]]
    b_hidden: [float]
    b_out: [float]
    rate_weight: float
    rate_bias: float

seed = 1
def random():
    global seed
    seed = (seed * 13 + 7) % 100
    return (float(seed)) / 100.0
def sigmoid(x):
    return 1.0 / (1.0 + exp(-x))
def to_float(x):
    return x * 1.0
def exp(x):
    term = 1.0
    sum = 1.0
    n = 1
    while n < 20:
        term = term * x / float(n)
        sum = sum + term
        n = n + 1
    return sum
def convolve(data, kernel, step, bias):
    size_data = len(data)
    size_kernel = len(kernel)
    out = []
    i = 0
    while i <= size_data - size_kernel:
        row = []
        j = 0
        while j <= size_data - size_kernel:
            sum = 0.0
            a = 0
            while a < size_kernel:
                b = 0
                while b < size_kernel:
                    sum = sum + data[i + a][j + b] * kernel[a][b]
                    b = b + 1
                a = a + 1
            row = _append(row, sigmoid(sum - bias))
            j = j + step
        out = _append(out, row)
        i = i + step
    return out
def average_pool(map, size):
    out = []
    i = 0
    while i < len(map):
        row = []
        j = 0
        while j < len(map[i]):
            sum = 0.0
            a = 0
            while a < size:
                b = 0
                while b < size:
                    sum = sum + map[i + a][j + b]
                    b = b + 1
                a = a + 1
            row = _append(row, sum / (float((size * size))))
            j = j + size
        out = _append(out, row)
        i = i + size
    return out
def flatten(maps):
    out = []
    i = 0
    while i < len(maps):
        j = 0
        while j < len(maps[i]):
            k = 0
            while k < len(maps[i][j]):
                out = _append(out, maps[i][j][k])
                k = k + 1
            j = j + 1
        i = i + 1
    return out
def vec_mul_mat(v, m):
    cols = len(m[0])
    res = []
    j = 0
    while j < cols:
        sum = 0.0
        i = 0
        while i < len(v):
            sum = sum + v[i] * m[i][j]
            i = i + 1
        res = _append(res, sum)
        j = j + 1
    return res
def matT_vec_mul(m, v):
    res = []
    i = 0
    while i < len(m):
        sum = 0.0
        j = 0
        while j < len(m[i]):
            sum = sum + m[i][j] * v[j]
            j = j + 1
        res = _append(res, sum)
        i = i + 1
    return res
def vec_add(a, b):
    res = []
    i = 0
    while i < len(a):
        res = _append(res, a[i] + b[i])
        i = i + 1
    return res
def vec_sub(a, b):
    res = []
    i = 0
    while i < len(a):
        res = _append(res, a[i] - b[i])
        i = i + 1
    return res
def vec_mul(a, b):
    res = []
    i = 0
    while i < len(a):
        res = _append(res, a[i] * b[i])
        i = i + 1
    return res
def vec_map_sig(v):
    res = []
    i = 0
    while i < len(v):
        res = _append(res, sigmoid(v[i]))
        i = i + 1
    return res
@dataclass
class TrainSample:
    image: [[float]]
    target: [float]

def new_cnn():
    k1 = [[1.0, 0.0], [0.0, 1.0]]
    k2 = [[0.0, 1.0], [1.0, 0.0]]
    conv_kernels = [k1, k2]
    conv_bias = [0.0, 0.0]
    conv_step = 2
    pool_size = 2
    input_size = 2
    hidden_size = 2
    output_size = 2
    w_hidden = []
    i = 0
    while i < input_size:
        row = []
        j = 0
        while j < hidden_size:
            row = _append(row, random() - 0.5)
            j = j + 1
        w_hidden = _append(w_hidden, row)
        i = i + 1
    w_out = []
    i = 0
    while i < hidden_size:
        row = []
        j = 0
        while j < output_size:
            row = _append(row, random() - 0.5)
            j = j + 1
        w_out = _append(w_out, row)
        i = i + 1
    b_hidden = [0.0, 0.0]
    b_out = [0.0, 0.0]
    return CNN(conv_kernels=conv_kernels, conv_bias=conv_bias, conv_step=conv_step, pool_size=pool_size, w_hidden=w_hidden, w_out=w_out, b_hidden=b_hidden, b_out=b_out, rate_weight=0.2, rate_bias=0.2)
def forward(cnn, data):
    maps = []
    i = 0
    while i < len(cnn.conv_kernels):
        conv_map = convolve(data, cnn.conv_kernels[i], cnn.conv_step, cnn.conv_bias[i])
        pooled = average_pool(conv_map, cnn.pool_size)
        maps = _append(maps, pooled)
        i = i + 1
    flat = flatten(maps)
    hidden_net = vec_add(vec_mul_mat(flat, cnn.w_hidden), cnn.b_hidden)
    hidden_out = vec_map_sig(hidden_net)
    out_net = vec_add(vec_mul_mat(hidden_out, cnn.w_out), cnn.b_out)
    out = vec_map_sig(out_net)
    return out
def train(cnn, samples, epochs):
    w_out = cnn.w_out
    b_out = cnn.b_out
    w_hidden = cnn.w_hidden
    b_hidden = cnn.b_hidden
    e = 0
    while e < epochs:
        s = 0
        while s < len(samples):
            data = samples[s].image
            target = samples[s].target
            maps = []
            i = 0
            while i < len(cnn.conv_kernels):
                conv_map = convolve(data, cnn.conv_kernels[i], cnn.conv_step, cnn.conv_bias[i])
                pooled = average_pool(conv_map, cnn.pool_size)
                maps = _append(maps, pooled)
                i = i + 1
            flat = flatten(maps)
            hidden_net = vec_add(vec_mul_mat(flat, w_hidden), b_hidden)
            hidden_out = vec_map_sig(hidden_net)
            out_net = vec_add(vec_mul_mat(hidden_out, w_out), b_out)
            out = vec_map_sig(out_net)
            error_out = vec_sub(target, out)
            pd_out = vec_mul(error_out, vec_mul(out, vec_sub([1.0, 1.0], out)))
            error_hidden = matT_vec_mul(w_out, pd_out)
            pd_hidden = vec_mul(error_hidden, vec_mul(hidden_out, vec_sub([1.0, 1.0], hidden_out)))
            j = 0
            while j < len(w_out):
                k = 0
                while k < len(w_out[j]):
                    w_out[j][k] = w_out[j][k] + cnn.rate_weight * hidden_out[j] * pd_out[k]
                    k = k + 1
                j = j + 1
            j = 0
            while j < len(b_out):
                b_out[j] = b_out[j] - cnn.rate_bias * pd_out[j]
                j = j + 1
            i_h = 0
            while i_h < len(w_hidden):
                j_h = 0
                while j_h < len(w_hidden[i_h]):
                    w_hidden[i_h][j_h] = w_hidden[i_h][j_h] + cnn.rate_weight * flat[i_h] * pd_hidden[j_h]
                    j_h = j_h + 1
                i_h = i_h + 1
            j = 0
            while j < len(b_hidden):
                b_hidden[j] = b_hidden[j] - cnn.rate_bias * pd_hidden[j]
                j = j + 1
            s = s + 1
        e = e + 1
    return CNN(conv_kernels=cnn.conv_kernels, conv_bias=cnn.conv_bias, conv_step=cnn.conv_step, pool_size=cnn.pool_size, w_hidden=w_hidden, w_out=w_out, b_hidden=b_hidden, b_out=b_out, rate_weight=cnn.rate_weight, rate_bias=cnn.rate_bias)
def main():
    if resource:
        _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    else:
        _bench_mem_start = 0
    _bench_start = _now()
    try:
        cnn = new_cnn()
        image = [[1.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 1.0], [1.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 1.0]]
        sample = TrainSample(image=image, target=[1.0, 0.0])
        print("Before training:", forward(cnn, image))
        trained = train(cnn, [sample], 50)
        print("After training:", forward(trained, image))
    finally:
        _bench_end = _now()
        if resource:
            _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
        else:
            _bench_mem_end = 0
        print(json.dumps({"duration_us": (_bench_end - _bench_start)//1000, "memory_bytes": _bench_mem_end*1024, "name": "main"}, indent=2))
main()

