# Code generated by Mochi transpiler.
# Version 0.10.66, generated on 2025-08-16 11:48 +0700
from __future__ import annotations
from dataclasses import dataclass
from typing import List, Dict
import dataclasses

import sys
if hasattr(sys, "set_int_max_str_digits"):
    sys.set_int_max_str_digits(0)
sys.setrecursionlimit(1000000)
import os
if os.path.dirname(__file__) in sys.path:
    sys.path.remove(os.path.dirname(__file__))


def _append(lst, v):
    if lst is None:
        lst = []
    return lst + [v]


def _set_index(lst, idx, val):
    if lst is None:
        lst = []
    if idx >= len(lst):
        lst.extend([None] * (idx - len(lst) + 1))
    lst[idx] = val
    return lst

@dataclass
class Dataset:
    data: [[float]]
    target: [float]

@dataclass
class Tree:
    threshold: float
    left_value: float
    right_value: float

def data_handling(dataset):
    return dataset
def xgboost(features, target, test_features):
    learning_rate = 0.5
    n_estimators = 3
    trees = []
    predictions = []
    i = 0
    while i < len(target):
        predictions = _append(predictions, 0.0)
        i = i + 1
    est = 0
    while est < n_estimators:
        residuals = []
        j = 0
        while j < len(target):
            residuals = _append(residuals, target[j] - predictions[j])
            j = j + 1
        sum_feat = 0.0
        j = 0
        while j < len(features):
            sum_feat = sum_feat + features[j][0]
            j = j + 1
        threshold = sum_feat / (float(len(features)))
        left_sum = 0.0
        left_count = 0
        right_sum = 0.0
        right_count = 0
        j = 0
        while j < len(features):
            if features[j][0] <= threshold:
                left_sum = left_sum + residuals[j]
                left_count = left_count + 1
            else:
                right_sum = right_sum + residuals[j]
                right_count = right_count + 1
            j = j + 1
        left_value = 0.0
        if left_count > 0:
            left_value = left_sum / (float(left_count))
        right_value = 0.0
        if right_count > 0:
            right_value = right_sum / (float(right_count))
        j = 0
        while j < len(features):
            if features[j][0] <= threshold:
                predictions[j] = predictions[j] + learning_rate * left_value
            else:
                predictions[j] = predictions[j] + learning_rate * right_value
            j = j + 1
        trees = _append(trees, Tree(threshold=threshold, left_value=left_value, right_value=right_value))
        est = est + 1
    preds = []
    t = 0
    while t < len(test_features):
        pred = 0.0
        k = 0
        while k < len(trees):
            if test_features[t][0] <= trees[k].threshold:
                pred = pred + learning_rate * trees[k].left_value
            else:
                pred = pred + learning_rate * trees[k].right_value
            k = k + 1
        preds = _append(preds, pred)
        t = t + 1
    return preds
def mean_absolute_error(y_true, y_pred):
    sum_ = 0.0
    i = 0
    while i < len(y_true):
        diff = y_true[i] - y_pred[i]
        if diff < 0.0:
            diff = -diff
        sum_ = sum_ + diff
        i = i + 1
    return sum_ / (float(len(y_true)))
def mean_squared_error(y_true, y_pred):
    sum_ = 0.0
    i = 0
    while i < len(y_true):
        diff = y_true[i] - y_pred[i]
        sum_ = sum_ + diff * diff
        i = i + 1
    return sum_ / (float(len(y_true)))
def main():
    california = Dataset(data=[[1.0], [2.0], [3.0], [4.0]], target=[2.0, 3.0, 4.0, 5.0])
    ds = data_handling(california)
    x_train = ds.data
    y_train = ds.target
    x_test = [[1.5], [3.5]]
    y_test = [2.5, 4.5]
    predictions = xgboost(x_train, y_train, x_test)
    print("Predictions:")
    print(predictions)
    print("Mean Absolute Error:")
    print(mean_absolute_error(y_test, predictions))
    print("Mean Square Error:")
    print(mean_squared_error(y_test, predictions))
main()

