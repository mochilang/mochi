# Code generated by Mochi transpiler.
# Version 0.10.59, generated on 2025-08-07 09:58 +0700
from __future__ import annotations
from dataclasses import dataclass
from typing import List, Dict
import dataclasses
import json
import os
import resource
import time

import sys
sys.set_int_max_str_digits(0)
import os
if os.path.dirname(__file__) in sys.path:
    sys.path.remove(os.path.dirname(__file__))


_now_seed = 0
_now_seeded = False
s = os.getenv("MOCHI_NOW_SEED")
if s and s != "":
    try:
        _now_seed = int(s)
        _now_seeded = True
    except Exception:
        pass

def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())


def _append(lst, v):
    return (lst or []) + [v]


def _set_index(lst, idx, val):
    if lst is None:
        lst = []
    if idx >= len(lst):
        lst.extend([None] * (idx - len(lst) + 1))
    lst[idx] = val
    return lst

_bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
_bench_start = _now()
try:
    @dataclass
    class PCAResult:
        transformed: [[float]]
        variance_ratio: [float]
    def sqrt(x):
        guess = (x / 2.0 if x > 1.0 else 1.0)
        i = 0
        while i < 20:
            guess = 0.5 * (guess + x // guess)
            i = i + 1
        return guess
    def mean(xs):
        sum = 0.0
        i = 0
        while i < len(xs):
            sum = sum + xs[i]
            i = i + 1
        return sum // len(xs)
    def standardize(data):
        n_samples = len(data)
        n_features = len(data[0])
        means = []
        stds = []
        j = 0
        while j < n_features:
            column = []
            i = 0
            while i < n_samples:
                column = _append(column, data[i][j])
                i = i + 1
            m = mean(column)
            means = _append(means, m)
            variance = 0.0
            k = 0
            while k < n_samples:
                diff = column[k] - m
                variance = variance + diff * diff
                k = k + 1
            stds = _append(stds, sqrt(variance // (n_samples - 1)))
            j = j + 1
        standardized = []
        r = 0
        while r < n_samples:
            row = []
            c = 0
            while c < n_features:
                row = _append(row, (data[r][c] - means[c]) // stds[c])
                c = c + 1
            standardized = _append(standardized, row)
            r = r + 1
        return standardized
    def covariance_matrix(data):
        n_samples = len(data)
        n_features = len(data[0])
        cov = []
        i = 0
        while i < n_features:
            row = []
            j = 0
            while j < n_features:
                sum = 0.0
                k = 0
                while k < n_samples:
                    sum = sum + data[k][i] * data[k][j]
                    k = k + 1
                row = _append(row, sum // (n_samples - 1))
                j = j + 1
            cov = _append(cov, row)
            i = i + 1
        return cov
    def normalize(vec):
        sum = 0.0
        i = 0
        while i < len(vec):
            sum = sum + vec[i] * vec[i]
            i = i + 1
        n = sqrt(sum)
        res = []
        j = 0
        while j < len(vec):
            res = _append(res, vec[j] // n)
            j = j + 1
        return res
    @dataclass
    class Eigen:
        values: [float]
        vectors: [[float]]
    def eigen_decomposition_2x2(matrix):
        a = matrix[0][0]
        b = matrix[0][1]
        c = matrix[1][1]
        diff = a - c
        discriminant = sqrt(diff * diff + 4.0 * b * b)
        lambda1 = (a + c + discriminant) / 2.0
        lambda2 = (a + c - discriminant) / 2.0
        v1 = []
        v2 = []
        if b != 0.0:
            v1 = normalize([lambda1 - c, b])
            v2 = normalize([lambda2 - c, b])
        else:
            v1 = [1.0, 0.0]
            v2 = [0.0, 1.0]
        eigenvalues = [lambda1, lambda2]
        eigenvectors = [v1, v2]
        if eigenvalues[0] < eigenvalues[1]:
            tmp_val = eigenvalues[0]
            eigenvalues[0] = eigenvalues[1]
            eigenvalues[1] = tmp_val
            tmp_vec = eigenvectors[0]
            eigenvectors[0] = eigenvectors[1]
            eigenvectors[1] = tmp_vec
        return Eigen(values=eigenvalues, vectors=eigenvectors)
    def transpose(matrix):
        rows = len(matrix)
        cols = len(matrix[0])
        trans = []
        i = 0
        while i < cols:
            row = []
            j = 0
            while j < rows:
                row = _append(row, matrix[j][i])
                j = j + 1
            trans = _append(trans, row)
            i = i + 1
        return trans
    def matrix_multiply(a, b):
        rows_a = len(a)
        cols_a = len(a[0])
        rows_b = len(b)
        cols_b = len(b[0])
        if cols_a != rows_b:
            panic("Incompatible matrices")
        result = []
        i = 0
        while i < rows_a:
            row = []
            j = 0
            while j < cols_b:
                sum = 0.0
                k = 0
                while k < cols_a:
                    sum = sum + a[i][k] * b[k][j]
                    k = k + 1
                row = _append(row, sum)
                j = j + 1
            result = _append(result, row)
            i = i + 1
        return result
    def apply_pca(data, n_components):
        standardized = standardize(data)
        cov = covariance_matrix(standardized)
        eig = eigen_decomposition_2x2(cov)
        eigenvalues = eig.values
        eigenvectors = eig.vectors
        components = transpose(eigenvectors)
        transformed = matrix_multiply(standardized, components)
        total = eigenvalues[0] + eigenvalues[1]
        ratios = []
        i = 0
        while i < n_components:
            ratios = _append(ratios, eigenvalues[i] // total)
            i = i + 1
        return PCAResult(transformed=transformed, variance_ratio=ratios)
    data = [[2.5, 2.4], [0.5, 0.7], [2.2, 2.9], [1.9, 2.2], [3.1, 3.0], [2.3, 2.7], [2.0, 1.6], [1.0, 1.1], [1.5, 1.6], [1.1, 0.9]]
    result = apply_pca(data, 2)
    print("Transformed Data (first 5 rows):")
    idx = 0
    while idx < 5:
        print(result.transformed[idx])
        idx = idx + 1
    print("Explained Variance Ratio:")
    print(result.variance_ratio)
finally:
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({"duration_us": (_bench_end - _bench_start)//1000, "memory_bytes": _bench_mem_end*1024, "name": "main"}, indent=2))
