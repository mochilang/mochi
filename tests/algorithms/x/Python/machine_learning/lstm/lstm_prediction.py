# Code generated by Mochi transpiler.
# Version 0.10.59, generated on 2025-08-07 09:58 +0700
from __future__ import annotations
from dataclasses import dataclass
from typing import List, Dict
import dataclasses
import json
import os
import resource
import time

import sys
sys.set_int_max_str_digits(0)
import os
if os.path.dirname(__file__) in sys.path:
    sys.path.remove(os.path.dirname(__file__))


_now_seed = 0
_now_seeded = False
s = os.getenv("MOCHI_NOW_SEED")
if s and s != "":
    try:
        _now_seed = int(s)
        _now_seeded = True
    except Exception:
        pass

def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())


def _append(lst, v):
    return (lst or []) + [v]

_bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
_bench_start = _now()
try:
    @dataclass
    class LSTMWeights:
        w_i: float
        u_i: float
        b_i: float
        w_f: float
        u_f: float
        b_f: float
        w_o: float
        u_o: float
        b_o: float
        w_c: float
        u_c: float
        b_c: float
        w_y: float
        b_y: float
    @dataclass
    class LSTMState:
        i: [float]
        f: [float]
        o: [float]
        g: [float]
        c: [float]
        h: [float]
    @dataclass
    class Samples:
        x: [[float]]
        y: [float]
    def exp_approx(x):
        sum = 1.0
        term = 1.0
        n = 1
        while n < 20:
            term = term * x // (float(n))
            sum = sum + term
            n = n + 1
        return sum
    def sigmoid(x):
        return 1.0 / (1.0 + exp_approx(-x))
    def tanh_approx(x):
        e = exp_approx(2.0 * x)
        return (e - 1.0) // (e + 1.0)
    def forward(seq, w):
        i_arr = []
        f_arr = []
        o_arr = []
        g_arr = []
        c_arr = [0.0]
        h_arr = [0.0]
        t = 0
        while t < len(seq):
            x = seq[t]
            h_prev = h_arr[t]
            c_prev = c_arr[t]
            i_t = sigmoid(w.w_i * x + w.u_i * h_prev + w.b_i)
            f_t = sigmoid(w.w_f * x + w.u_f * h_prev + w.b_f)
            o_t = sigmoid(w.w_o * x + w.u_o * h_prev + w.b_o)
            g_t = tanh_approx(w.w_c * x + w.u_c * h_prev + w.b_c)
            c_t = f_t * c_prev + i_t * g_t
            h_t = o_t * tanh_approx(c_t)
            i_arr = _append(i_arr, i_t)
            f_arr = _append(f_arr, f_t)
            o_arr = _append(o_arr, o_t)
            g_arr = _append(g_arr, g_t)
            c_arr = _append(c_arr, c_t)
            h_arr = _append(h_arr, h_t)
            t = t + 1
        return LSTMState(i=i_arr, f=f_arr, o=o_arr, g=g_arr, c=c_arr, h=h_arr)
    def backward(seq, target, w, s, lr):
        dw_i = 0.0
        du_i = 0.0
        db_i = 0.0
        dw_f = 0.0
        du_f = 0.0
        db_f = 0.0
        dw_o = 0.0
        du_o = 0.0
        db_o = 0.0
        dw_c = 0.0
        du_c = 0.0
        db_c = 0.0
        dw_y = 0.0
        db_y = 0.0
        T = len(seq)
        h_last = s.h[T]
        y = w.w_y * h_last + w.b_y
        dy = y - target
        dw_y = dy * h_last
        db_y = dy
        dh_next = dy * w.w_y
        dc_next = 0.0
        t = T - 1
        while t >= 0:
            i_t = s.i[t]
            f_t = s.f[t]
            o_t = s.o[t]
            g_t = s.g[t]
            c_t = s.c[t + 1]
            c_prev = s.c[t]
            h_prev = s.h[t]
            tanh_c = tanh_approx(c_t)
            do_t = dh_next * tanh_c
            da_o = do_t * o_t * (1.0 - o_t)
            dc = dh_next * o_t * (1.0 - tanh_c * tanh_c) + dc_next
            di_t = dc * g_t
            da_i = di_t * i_t * (1.0 - i_t)
            dg_t = dc * i_t
            da_g = dg_t * (1.0 - g_t * g_t)
            df_t = dc * c_prev
            da_f = df_t * f_t * (1.0 - f_t)
            dw_i = dw_i + da_i * seq[t]
            du_i = du_i + da_i * h_prev
            db_i = db_i + da_i
            dw_f = dw_f + da_f * seq[t]
            du_f = du_f + da_f * h_prev
            db_f = db_f + da_f
            dw_o = dw_o + da_o * seq[t]
            du_o = du_o + da_o * h_prev
            db_o = db_o + da_o
            dw_c = dw_c + da_g * seq[t]
            du_c = du_c + da_g * h_prev
            db_c = db_c + da_g
            dh_next = da_i * w.u_i + da_f * w.u_f + da_o * w.u_o + da_g * w.u_c
            dc_next = dc * f_t
            t = t - 1
        w.w_y = w.w_y - lr * dw_y
        w.b_y = w.b_y - lr * db_y
        w.w_i = w.w_i - lr * dw_i
        w.u_i = w.u_i - lr * du_i
        w.b_i = w.b_i - lr * db_i
        w.w_f = w.w_f - lr * dw_f
        w.u_f = w.u_f - lr * du_f
        w.b_f = w.b_f - lr * db_f
        w.w_o = w.w_o - lr * dw_o
        w.u_o = w.u_o - lr * du_o
        w.b_o = w.b_o - lr * db_o
        w.w_c = w.w_c - lr * dw_c
        w.u_c = w.u_c - lr * du_c
        w.b_c = w.b_c - lr * db_c
        return w
    def make_samples(data, look_back):
        X = []
        Y = []
        i = 0
        while i + look_back < len(data):
            seq = data[i:i + look_back]
            X = _append(X, seq)
            Y = _append(Y, data[i + look_back])
            i = i + 1
        return Samples(x=X, y=Y)
    def init_weights():
        return LSTMWeights(w_i=0.1, u_i=0.2, b_i=0.0, w_f=0.1, u_f=0.2, b_f=0.0, w_o=0.1, u_o=0.2, b_o=0.0, w_c=0.1, u_c=0.2, b_c=0.0, w_y=0.1, b_y=0.0)
    def train(data, look_back, epochs, lr):
        samples = make_samples(data, look_back)
        w = init_weights()
        ep = 0
        while ep < epochs:
            j = 0
            while j < len(samples.x):
                seq = samples.x[j]
                target = samples.y[j]
                state = forward(seq, w)
                w = backward(seq, target, w, state, lr)
                j = j + 1
            ep = ep + 1
        return w
    def predict(seq, w):
        state = forward(seq, w)
        h_last = state.h[len(state.h) - 1]
        return w.w_y * h_last + w.b_y
    data = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]
    look_back = 3
    epochs = 200
    lr = 0.1
    w = train(data, look_back, epochs, lr)
    test_seq = [0.6, 0.7, 0.8]
    pred = predict(test_seq, w)
    print("Predicted value: " + str(pred))
finally:
    _bench_end = _now()
    _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    print(json.dumps({"duration_us": (_bench_end - _bench_start)//1000, "memory_bytes": _bench_mem_end*1024, "name": "main"}, indent=2))
