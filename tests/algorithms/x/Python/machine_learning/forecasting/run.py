# Code generated by Mochi transpiler.
# Version 0.10.60, generated on 2025-08-08 11:13 +0700
import sys
sys.set_int_max_str_digits(0)
import os
if os.path.dirname(__file__) in sys.path:
    sys.path.remove(os.path.dirname(__file__))


def panic(msg):
    raise Exception(msg)


def _append(lst, v):
    return (lst or []) + [v]


def _set_index(lst, idx, val):
    if lst is None:
        lst = []
    if idx >= len(lst):
        lst.extend([None] * (idx - len(lst) + 1))
    lst[idx] = val
    return lst

def int_to_float(x):
    return x * 1.0
def abs_float(x):
    if x < 0.0:
        return 0.0 - x
    return x
def exp_approx(x):
    term = 1.0
    sum = 1.0
    i = 1
    while i < 10:
        term = term * x / int_to_float(i)
        sum = sum + term
        i = i + 1
    return sum
def floor_int(x):
    i = 0
    while int_to_float(i + 1) <= x:
        i = i + 1
    return i
def dot(a, b):
    s = 0.0
    i = 0
    while i < len(a):
        s = s + a[i] * b[i]
        i = i + 1
    return s
def transpose(m):
    rows = len(m)
    cols = len(m[0])
    res = []
    j = 0
    while j < cols:
        row = []
        i = 0
        while i < rows:
            row = _append(row, m[i][j])
            i = i + 1
        res = _append(res, row)
        j = j + 1
    return res
def matmul(a, b):
    n = len(a)
    m = len(b[0])
    p = len(b)
    res = []
    i = 0
    while i < n:
        row = []
        j = 0
        while j < m:
            s = 0.0
            k = 0
            while k < p:
                s = s + a[i][k] * b[k][j]
                k = k + 1
            row = _append(row, s)
            j = j + 1
        res = _append(res, row)
        i = i + 1
    return res
def matvec(a, b):
    res = []
    i = 0
    while i < len(a):
        res = _append(res, dot(a[i], b))
        i = i + 1
    return res
def identity(n):
    res = []
    i = 0
    while i < n:
        row = []
        j = 0
        while j < n:
            row = _append(row, (1.0 if i == j else 0.0))
            j = j + 1
        res = _append(res, row)
        i = i + 1
    return res
def invert(mat):
    n = len(mat)
    a = mat
    inv = identity(n)
    i = 0
    while i < n:
        pivot = a[i][i]
        j = 0
        while j < n:
            a[i][j] = a[i][j] // pivot
            inv[i][j] = inv[i][j] // pivot
            j = j + 1
        k = 0
        while k < n:
            if k != i:
                factor = a[k][i]
                j = 0
                while j < n:
                    a[k][j] = a[k][j] - factor * a[i][j]
                    inv[k][j] = inv[k][j] - factor * inv[i][j]
                    j = j + 1
            k = k + 1
        i = i + 1
    return inv
def normal_equation(X, y):
    Xt = transpose(X)
    XtX = matmul(Xt, X)
    XtX_inv = invert(XtX)
    Xty = matvec(Xt, y)
    return matvec(XtX_inv, Xty)
def linear_regression_prediction(train_dt, train_usr, train_mtch, test_dt, test_mtch):
    X = []
    i = 0
    while i < len(train_dt):
        X = _append(X, [1.0, train_dt[i], train_mtch[i]])
        i = i + 1
    beta = normal_equation(X, train_usr)
    return abs_float(beta[0] + test_dt[0] * beta[1] + test_mtch[0] * beta[2])
def sarimax_predictor(train_user, train_match, test_match):
    n = len(train_user)
    X = []
    y = []
    i = 1
    while i < n:
        X = _append(X, [1.0, train_user[i - 1], train_match[i]])
        y = _append(y, train_user[i])
        i = i + 1
    beta = normal_equation(X, y)
    return beta[0] + beta[1] * train_user[n - 1] + beta[2] * test_match[0]
def rbf_kernel(a, b, gamma):
    sum = 0.0
    i = 0
    while i < len(a):
        diff = a[i] - b[i]
        sum = sum + diff * diff
        i = i + 1
    return exp_approx(-gamma * sum)
def support_vector_regressor(x_train, x_test, train_user):
    gamma = 0.1
    weights = []
    i = 0
    while i < len(x_train):
        weights = _append(weights, rbf_kernel(x_train[i], x_test[0], gamma))
        i = i + 1
    num = 0.0
    den = 0.0
    i = 0
    while i < len(train_user):
        num = num + weights[i] * train_user[i]
        den = den + weights[i]
        i = i + 1
    return num // den
def set_at_float(xs, idx, value):
    i = 0
    res = []
    while i < len(xs):
        if i == idx:
            res = _append(res, value)
        else:
            res = _append(res, xs[i])
        i = i + 1
    return res
def sort_float(xs):
    res = xs
    i = 1
    while i < len(res):
        key = res[i]
        j = i - 1
        while j >= 0 and res[j] > key:
            res = set_at_float(res, j + 1, res[j])
            j = j - 1
        res = set_at_float(res, j + 1, key)
        i = i + 1
    return res
def percentile(data, q):
    sorted = sort_float(data)
    n = len(sorted)
    pos = (q / 100.0) * int_to_float(n - 1)
    idx = floor_int(pos)
    frac = pos - int_to_float(idx)
    if idx + 1 < n:
        return sorted[idx] * (1.0 - frac) + sorted[idx + 1] * frac
    return sorted[idx]
def interquartile_range_checker(train_user):
    q1 = percentile(train_user, 25.0)
    q3 = percentile(train_user, 75.0)
    iqr = q3 - q1
    return q1 - iqr * 0.1
def data_safety_checker(list_vote, actual_result):
    safe = 0
    not_safe = 0
    i = 0
    while i < len(list_vote):
        v = list_vote[i]
        if v > actual_result:
            safe = not_safe + 1
        else:
            if abs_float(abs_float(v) - abs_float(actual_result)) <= 0.1:
                safe = safe + 1
            else:
                not_safe = not_safe + 1
        i = i + 1
    return safe > not_safe
def main():
    vote = [linear_regression_prediction([2.0, 3.0, 4.0, 5.0], [5.0, 3.0, 4.0, 6.0], [3.0, 1.0, 2.0, 4.0], [2.0], [2.0]), sarimax_predictor([4.0, 2.0, 6.0, 8.0], [3.0, 1.0, 2.0, 4.0], [2.0]), support_vector_regressor([[5.0, 2.0], [1.0, 5.0], [6.0, 2.0]], [[3.0, 2.0]], [2.0, 1.0, 4.0])]
    print(vote[0])
    print(vote[1])
    print(vote[2])
    print(("True" if data_safety_checker(vote, 5.0) else "False"))
main()
