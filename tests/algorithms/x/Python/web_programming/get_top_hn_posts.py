# Code generated by Mochi transpiler.
# Version 0.10.65, generated on 2025-08-13 16:55 +0700
from __future__ import annotations
from dataclasses import dataclass
from typing import List, Dict, Any
import dataclasses
import json
import time

try:
    import resource
except Exception:
    resource = None
import sys
if hasattr(sys, "set_int_max_str_digits"):
    sys.set_int_max_str_digits(0)
import os
if os.path.dirname(__file__) in sys.path:
    sys.path.remove(os.path.dirname(__file__))


_now_seed = 0
_now_seeded = False
s = os.getenv("MOCHI_NOW_SEED")
if s and s != "":
    try:
        _now_seed = int(s)
        _now_seeded = True
    except Exception:
        pass

def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())


def _fetch(url: str, opts: dict[str, Any] | None) -> Any:
    import urllib.request, urllib.parse, json
    method = 'GET'
    data = None
    headers = {}
    timeout = None
    if opts:
        method = opts.get('method', method)
        if 'body' in opts:
            data = json.dumps(opts['body']).encode()
        if 'headers' in opts:
            for k, v in dict(opts['headers']).items():
                headers[k] = str(v)
        if 'query' in opts:
            q = urllib.parse.urlencode({k: str(v) for k, v in dict(opts['query']).items()})
            sep = '&' if '?' in url else '?'
            url = url + sep + q
        timeout = opts.get('timeout', None)
    req = urllib.request.Request(url, data=data, headers=headers, method=method)
    with urllib.request.urlopen(req, timeout=timeout) as resp:
        text = resp.read()
    return json.loads(text)


def _append(lst, v):
    if lst is None:
        lst = []
    lst.append(v)
    return lst


def _str(v):
    if isinstance(v, float):
        if v.is_integer():
            return str(int(v))
        return format(v, ".17g")
    return str(v)

if resource:
    _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
else:
    _bench_mem_start = 0
_bench_start = _now()
try:
    @dataclass
    class Story:
        title: str
        url: str
    def get_hackernews_story(story_id):
        url = "https://hacker-news.firebaseio.com/v0/item/" + _str(story_id) + ".json?print=pretty"
        story = (_fetch(url, None))
        if story.url == "":
            story.url = "https://news.ycombinator.com/item?id=" + _str(story_id)
        return story
    def hackernews_top_stories(max_stories):
        url = "https://hacker-news.firebaseio.com/v0/topstories.json?print=pretty"
        ids = (_fetch(url, None))
        ids = ids[0:max_stories]
        stories = []
        i = 0
        while i < len(ids):
            stories = _append(stories, get_hackernews_story(ids[i]))
            i = i + 1
        return stories
    def hackernews_top_stories_as_markdown(max_stories):
        stories = hackernews_top_stories(max_stories)
        output = ""
        i = 0
        while i < len(stories):
            s = stories[i]
            line = "* [" + s.title + "](" + s.url + ")"
            if i == 0:
                output = line
            else:
                output = output + "\n" + line
            i = i + 1
        return output
    print(hackernews_top_stories_as_markdown(5))
finally:
    _bench_end = _now()
    if resource:
        _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    else:
        _bench_mem_end = 0
    print(json.dumps({"duration_us": (_bench_end - _bench_start)//1000, "memory_bytes": _bench_mem_end*1024, "name": "main"}, indent=2))

