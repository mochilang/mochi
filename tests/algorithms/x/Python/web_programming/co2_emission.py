# Code generated by Mochi transpiler.
# Version 0.10.65, generated on 2025-08-13 16:55 +0700
from __future__ import annotations
from dataclasses import dataclass
from typing import List, Dict, Any
import dataclasses
import json
import time

try:
    import resource
except Exception:
    resource = None
import sys
if hasattr(sys, "set_int_max_str_digits"):
    sys.set_int_max_str_digits(0)
import os
if os.path.dirname(__file__) in sys.path:
    sys.path.remove(os.path.dirname(__file__))


_now_seed = 0
_now_seeded = False
s = os.getenv("MOCHI_NOW_SEED")
if s and s != "":
    try:
        _now_seed = int(s)
        _now_seeded = True
    except Exception:
        pass

def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())


def _fetch(url: str, opts: dict[str, Any] | None) -> Any:
    import urllib.request, urllib.parse, json
    method = 'GET'
    data = None
    headers = {}
    timeout = None
    if opts:
        method = opts.get('method', method)
        if 'body' in opts:
            data = json.dumps(opts['body']).encode()
        if 'headers' in opts:
            for k, v in dict(opts['headers']).items():
                headers[k] = str(v)
        if 'query' in opts:
            q = urllib.parse.urlencode({k: str(v) for k, v in dict(opts['query']).items()})
            sep = '&' if '?' in url else '?'
            url = url + sep + q
        timeout = opts.get('timeout', None)
    req = urllib.request.Request(url, data=data, headers=headers, method=method)
    with urllib.request.urlopen(req, timeout=timeout) as resp:
        text = resp.read()
    return json.loads(text)

@dataclass
class Intensity:
    forecast: int
    actual: int
    index: str

@dataclass
class Entry:
    from_: str
    to: str
    intensity: Intensity

@dataclass
class Response:
    data: [Entry]

BASE_URL = "https://api.carbonintensity.org.uk/intensity"
def fetch_last_half_hour():
    resp = _fetch(BASE_URL, dict({"timeout": 10.0}))
    entry = resp.data[0]
    return entry.intensity.actual
def fetch_from_to(start, end):
    url = BASE_URL + "/" + start + "/" + end
    resp = _fetch(url, dict({"timeout": 10.0}))
    return resp.data
def main():
    if resource:
        _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    else:
        _bench_mem_start = 0
    _bench_start = _now()
    try:
        entries = fetch_from_to("2020-10-01", "2020-10-03")
        i = 0
        while i < len(entries):
            e = entries[i]
            print("from", e.from_, "to", e.to, ":", e.intensity.actual)
            i = i + 1
        last = fetch_last_half_hour()
        print("fetch_last_half_hour() =", last)
    finally:
        _bench_end = _now()
        if resource:
            _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
        else:
            _bench_mem_end = 0
        print(json.dumps({"duration_us": (_bench_end - _bench_start)//1000, "memory_bytes": _bench_mem_end*1024, "name": "main"}, indent=2))
main()

