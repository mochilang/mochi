# Code generated by Mochi transpiler.
# Version 0.10.66, generated on 2025-08-15 15:17 +0700
import json
import time

try:
    import resource
except Exception:
    resource = None
import sys
if hasattr(sys, "set_int_max_str_digits"):
    sys.set_int_max_str_digits(0)
sys.setrecursionlimit(1000000)
import os
if os.path.dirname(__file__) in sys.path:
    sys.path.remove(os.path.dirname(__file__))


_now_seed = 0
_now_seeded = False
s = os.getenv("MOCHI_NOW_SEED")
if s and s != "":
    try:
        _now_seed = int(s)
        _now_seeded = True
    except Exception:
        pass

def _now():
    global _now_seed
    if _now_seeded:
        _now_seed = (_now_seed * 1664525 + 1013904223) % 2147483647
        return _now_seed
    return int(time.time_ns())


def _append(lst, v):
    if lst is None:
        lst = []
    return lst + [v]


def _set_index(lst, idx, val):
    if lst is None:
        lst = []
    if idx >= len(lst):
        lst.extend([None] * (idx - len(lst) + 1))
    lst[idx] = val
    return lst

def topological_sort(graph):
    indegree = []
    i = 0
    while i < len(graph):
        indegree = _append(indegree, 0)
        i = i + 1
    for edges in list(graph.values()):
        j = 0
        while j < len(edges):
            v = edges[j]
            indegree[v] = indegree[v] + 1
            j = j + 1
    queue = []
    i = 0
    while i < len(indegree):
        if indegree[i] == 0:
            queue = _append(queue, i)
        i = i + 1
    order = []
    head = 0
    processed = 0
    while head < len(queue):
        v = queue[head]
        head = head + 1
        processed = processed + 1
        order = _append(order, v)
        neighbors = graph.get(v, [])
        k = 0
        while k < len(neighbors):
            nb = neighbors[k]
            indegree[nb] = indegree[nb] - 1
            if indegree[nb] == 0:
                queue = _append(queue, nb)
            k = k + 1
    if processed != len(graph):
        return None
    return order
def main():
    if resource:
        _bench_mem_start = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
    else:
        _bench_mem_start = 0
    _bench_start = _now()
    try:
        graph = {0: [1, 2], 1: [3], 2: [3], 3: [4, 5], 4: [], 5: []}
        print(topological_sort(graph))
        cyclic = {0: [1], 1: [2], 2: [0]}
        print(topological_sort(cyclic))
    finally:
        _bench_end = _now()
        if resource:
            _bench_mem_end = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
        else:
            _bench_mem_end = 0
        print(json.dumps({"duration_us": (_bench_end - _bench_start)//1000, "memory_bytes": _bench_mem_end*1024, "name": "main"}, indent=2))
main()

