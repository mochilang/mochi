// Generated by Mochi transpiler
import 'dart:convert';
import 'dart:io';

int _nowSeed = 0;
bool _nowSeeded = false;
void _initNow() {
  var s = Platform.environment['MOCHI_NOW_SEED'];
  if (s != null && s.isNotEmpty) {
    var v = int.tryParse(s);
    if (v != null) {
      _nowSeed = v;
      _nowSeeded = true;
    }
  }
}
int _now() {
  if (_nowSeeded) {
    _nowSeed = (_nowSeed * 1664525 + 1013904223) % 2147483647;
    return _nowSeed;
  }
  return DateTime.now().microsecondsSinceEpoch;
}

String _substr(String s, num start, num end) {
  var n = s.length;
  int s0 = start.toInt();
  int e0 = end.toInt();
  if (s0 < 0) s0 += n;
  if (e0 < 0) e0 += n;
  if (s0 < 0) s0 = 0;
  if (s0 > n) s0 = n;
  if (e0 < 0) e0 = 0;
  if (e0 > n) e0 = n;
  if (s0 > e0) s0 = e0;
  return s.substring(s0, e0);
}

class DataPoint {
  List<double> x;
  double y;
  DataPoint({required this.x, required this.y});
}

double absf(double x) {
  if (x < 0.0) {
    return -x;
  }
  return x;
}

double hypothesis_value(List<double> input, List<double> params) {
  double value = params[0];
  int i = 0;
  while (i < input.length) {
    value = value + input[i] * params[i + 1];
    i = i + 1;
  }
  return value;
}

double calc_error(DataPoint dp, List<double> params) {
  return hypothesis_value(dp.x, params) - dp.y;
}

double summation_of_cost_derivative(int index, List<double> params, List<DataPoint> data) {
  double sum = 0.0;
  int i = 0;
  while (i < data.length) {
    DataPoint dp = data[i];
    double e = calc_error(dp, params);
    if (index == -1) {
    sum = sum + e;
  } else {
    sum = sum + e * dp.x[index];
  }
    i = i + 1;
  }
  return sum;
}

double get_cost_derivative(int index, List<double> params, List<DataPoint> data) {
  return summation_of_cost_derivative(index, params, data) / (data.length as double);
}

bool allclose(List<double> a, List<double> b, double atol, double rtol) {
  int i = 0;
  while (i < a.length) {
    double diff = absf(a[i] - b[i]);
    double limit = atol + rtol * absf(b[i]);
    if (diff > limit) {
    return false;
  }
    i = i + 1;
  }
  return true;
}

List<double> run_gradient_descent(List<DataPoint> train_data, List<double> initial_params) {
  double learning_rate = 0.009;
  double absolute_error_limit = 0.000002;
  double relative_error_limit = 0.0;
  int j = 0;
  List<double> params = initial_params;
  while (true) {
    j = j + 1;
    List<double> temp = <double>[];
    int i = 0;
    while (i < params.length) {
    double deriv = get_cost_derivative(i - 1, params, train_data);
    temp = [...temp, params[i] - learning_rate * deriv];
    i = i + 1;
  }
    if (allclose(params, temp, absolute_error_limit, relative_error_limit)) {
    print("Number of iterations:" + (j).toString());
    break;
  }
    params = temp;
  }
  return params;
}

void test_gradient_descent(List<DataPoint> test_data, List<double> params) {
  int i = 0;
  while (i < test_data.length) {
    DataPoint dp = test_data[i];
    print("Actual output value:" + (dp.y).toString());
    print("Hypothesis output:" + (hypothesis_value(dp.x, params)).toString());
    i = i + 1;
  }
}

List<DataPoint> train_data = [DataPoint(x: [5.0, 2.0, 3.0], y: 15.0), DataPoint(x: [6.0, 5.0, 9.0], y: 25.0), DataPoint(x: [11.0, 12.0, 13.0], y: 41.0), DataPoint(x: [1.0, 1.0, 1.0], y: 8.0), DataPoint(x: [11.0, 12.0, 13.0], y: 41.0)];
List<DataPoint> test_data = [DataPoint(x: [515.0, 22.0, 13.0], y: 555.0), DataPoint(x: [61.0, 35.0, 49.0], y: 150.0)];
List<double> parameter_vector = [2.0, 4.0, 1.0, 5.0];
void main() {
  var _benchMem0 = ProcessInfo.currentRss;
  var _benchSw = Stopwatch()..start();
  _initNow();
  {
  var _benchMem0 = ProcessInfo.currentRss;
  var _benchSw = Stopwatch()..start();
  parameter_vector = run_gradient_descent(train_data, parameter_vector);
  print("\nTesting gradient descent for a linear hypothesis function.\n");
  test_gradient_descent(test_data, parameter_vector);
  _benchSw.stop();
  var _benchMem1 = ProcessInfo.currentRss;
  print(jsonEncode({"duration_us": _benchSw.elapsedMicroseconds, "memory_bytes": (_benchMem1 - _benchMem0).abs(), "name": "main"}));
}
  _benchSw.stop();
  var _benchMem1 = ProcessInfo.currentRss;
  print(jsonEncode({"duration_us": _benchSw.elapsedMicroseconds, "memory_bytes": (_benchMem1 - _benchMem0).abs(), "name": "main"}));
}
