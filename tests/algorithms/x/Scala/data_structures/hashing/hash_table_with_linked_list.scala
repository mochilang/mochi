// Generated by Mochi v0.10.59 on 2025-08-06 23:23:19 GMT+7
import scala.collection.mutable.{ArrayBuffer, Map}
import scala.math.BigInt
import scala.collection.immutable.ListMap
object Main {
  private var _nowSeed: Long = 0L
  private var _nowSeeded: Boolean = false
  private def _now(): Int = {
    if (!_nowSeeded) {
      sys.env.get("MOCHI_NOW_SEED").foreach { s =>
      try { _nowSeed = s.toInt; _nowSeeded = true } catch { case _ : NumberFormatException => () }
    }
  }
  if (_nowSeeded) {
    _nowSeed = (_nowSeed * 1664525 + 1013904223) % 2147483647
    _nowSeed.toInt
  } else {
    Math.abs((System.nanoTime() / 1000).toInt)
  }
}

def toJson(value: Any, indent: Int = 0): String = value match {
  case m: scala.collection.Map[_, _] =>
  val items = ListMap(m.toSeq.sortBy(_._1.toString): _*).toSeq.map{ case (k,v) => "  "*(indent+1)+"\""+k.toString+"\": "+toJson(v, indent+1) }
  "{\n"+items.mkString(",\n")+"\n"+"  "*indent+"}"
  case s: Seq[_] =>
  val items = s.map(x => "  "*(indent+1)+toJson(x, indent+1))
  "[\n"+items.mkString(",\n")+"\n"+"  "*indent+"]"
  case s: String => "\""+s+"\""
  case other => other.toString
}

case class HashTableWithLinkedList(var size_table: BigInt, var charge_factor: BigInt, var values: ArrayBuffer[ArrayBuffer[BigInt]], var keys: scala.collection.mutable.Map[BigInt,ArrayBuffer[BigInt]])

def make_table(size_table: BigInt, charge_factor: BigInt): HashTableWithLinkedList = {
  var vals: ArrayBuffer[ArrayBuffer[BigInt]] = ArrayBuffer()
  var i: BigInt = 0
  while (i < size_table) {
    vals = vals :+ ArrayBuffer()
    i = i + 1
  }
  return HashTableWithLinkedList(size_table, charge_factor, vals, scala.collection.mutable.Map())
}

def hash_function(ht: HashTableWithLinkedList, key: BigInt): BigInt = {
  var res: BigInt = key % ht.asInstanceOf[HashTableWithLinkedList].size_table
  if (res < 0) {
    res = res + ht.asInstanceOf[HashTableWithLinkedList].size_table
  }
  return res
}

def prepend(lst: ArrayBuffer[BigInt], value: BigInt): ArrayBuffer[BigInt] = {
  var result: ArrayBuffer[BigInt] = ArrayBuffer(value)
  var i: BigInt = 0
  while (i < BigInt((lst).size)) {
    result = result :+ lst((i.toInt).toInt)
    i = i + 1
  }
  return result
}

def set_value(ht: HashTableWithLinkedList, key: BigInt, data: BigInt): Any = {
  val current: ArrayBuffer[BigInt] = ht.asInstanceOf[HashTableWithLinkedList].values((key.toInt).toInt)
  val updated: ArrayBuffer[BigInt] = prepend(current, data)
  var vals: ArrayBuffer[ArrayBuffer[BigInt]] = ht.asInstanceOf[HashTableWithLinkedList].values
  vals((key).toInt) = updated
  ht.asInstanceOf[HashTableWithLinkedList].values = vals
  var ks: scala.collection.mutable.Map[BigInt,ArrayBuffer[BigInt]] = ht.asInstanceOf[HashTableWithLinkedList].keys
  ks.update(key, updated)
  ht.asInstanceOf[HashTableWithLinkedList].keys = ks
}

def count_empty(ht: HashTableWithLinkedList): BigInt = {
  var count: BigInt = 0
  var i: BigInt = 0
  while (i < BigInt((ht.asInstanceOf[HashTableWithLinkedList].values).size)) {
    if (BigInt((ht.asInstanceOf[HashTableWithLinkedList].values((i.toInt).toInt)).size) == 0) {
      count = count + 1
    }
    i = i + 1
  }
  return count
}

def balanced_factor(ht: HashTableWithLinkedList): Double = {
  var total: BigInt = 0
  var i: BigInt = 0
  while (i < BigInt((ht.asInstanceOf[HashTableWithLinkedList].values).size)) {
    total = total + (ht.asInstanceOf[HashTableWithLinkedList].charge_factor - BigInt((ht.asInstanceOf[HashTableWithLinkedList].values((i.toInt).toInt)).size))
    i = i + 1
  }
  return total.toString.toDouble / (ht.asInstanceOf[HashTableWithLinkedList].size_table).toString.toDouble * (ht.asInstanceOf[HashTableWithLinkedList].charge_factor).toString.toDouble
}

def collision_resolution(ht: HashTableWithLinkedList, key: BigInt): BigInt = {
  if (!(BigInt((ht.asInstanceOf[HashTableWithLinkedList].values((key.toInt).toInt)).size) == ht.asInstanceOf[HashTableWithLinkedList].charge_factor && count_empty(ht) == 0).asInstanceOf[Boolean]) {
    return key
  }
  var new_key: BigInt = (key + 1) % ht.asInstanceOf[HashTableWithLinkedList].size_table
  var steps: BigInt = 0
  while (BigInt((ht.asInstanceOf[HashTableWithLinkedList].values((new_key.toInt).toInt)).size) == ht.asInstanceOf[HashTableWithLinkedList].charge_factor && steps < ht.asInstanceOf[HashTableWithLinkedList].size_table - 1) {
    new_key = (new_key + 1) % ht.asInstanceOf[HashTableWithLinkedList].size_table
    steps = steps + 1
  }
  if (BigInt((ht.asInstanceOf[HashTableWithLinkedList].values((new_key.toInt).toInt)).size) < ht.asInstanceOf[HashTableWithLinkedList].charge_factor) {
    return new_key
  }
  return -1
}

def insert(ht: HashTableWithLinkedList, data: BigInt): Any = {
  var key: BigInt = hash_function(ht, data)
  if ((BigInt((ht.asInstanceOf[HashTableWithLinkedList].values((key.toInt).toInt)).size) == 0 || BigInt((ht.asInstanceOf[HashTableWithLinkedList].values((key.toInt).toInt)).size) < ht.asInstanceOf[HashTableWithLinkedList].charge_factor).asInstanceOf[Boolean]) {
    set_value(ht, key, data)
    return
  }
  var dest: BigInt = collision_resolution(ht, key)
  if (dest >= 0) {
    set_value(ht, dest, data)
  } else {
    println("table full")
  }
  return null
}

def main(): Any = {
  var ht: HashTableWithLinkedList = make_table(3, 2)
  insert(ht, 10)
  insert(ht, 20)
  insert(ht, 30)
  insert(ht, 40)
  insert(ht, 50)
  println(String.valueOf(ht.asInstanceOf[HashTableWithLinkedList].values))
  println(String.valueOf(balanced_factor(ht)))
}

def main(args: Array[String]): Unit = {
  {
    System.gc()
    val _startMem = Runtime.getRuntime.totalMemory() - Runtime.getRuntime.freeMemory()
    val _start = _now()
    main()
    val _end = _now()
    System.gc()
    val _endMem = Runtime.getRuntime.totalMemory() - Runtime.getRuntime.freeMemory()
    val _durUs = (_end - _start) / 1000
    var _memDiff = _endMem - _startMem
    if (_memDiff <= 0) _memDiff = _endMem
    println(toJson(scala.collection.immutable.Map("duration_us" -> _durUs, "memory_bytes" -> _memDiff, "name" -> "main")))
  }
}
}
