// Generated by Mochi v0.10.67 on 2025-08-16 21:30:14 GMT+7
import scala.collection.mutable.{ArrayBuffer, Map}
import scala.math.BigInt
import scala.collection.immutable.ListMap
object Main {
  private var _nowSeed: Long = 0L
  private var _nowSeeded: Boolean = false
  private def _now(): Int = {
    if (!_nowSeeded) {
      sys.env.get("MOCHI_NOW_SEED").foreach { s =>
      try { _nowSeed = s.toInt; _nowSeeded = true } catch { case _ : NumberFormatException => () }
    }
    if (!_nowSeeded) { _nowSeed = 0L; _nowSeeded = true }
  }
  if (_nowSeeded) {
    _nowSeed = (_nowSeed * 1664525 + 1013904223) % 2147483647
    _nowSeed.toInt
  } else {
    Math.abs((System.nanoTime() / 1000).toInt)
  }
}

def toJson(value: Any, indent: Int = 0): String = value match {
  case m: scala.collection.Map[_, _] =>
  val items = ListMap(m.toSeq.sortBy(_._1.toString): _*).toSeq.map{ case (k,v) => "  "*(indent+1)+"\""+k.toString+"\": "+toJson(v, indent+1) }
  "{\n"+items.mkString(",\n")+"\n"+"  "*indent+"}"
  case s: Seq[_] =>
  val items = s.map(x => "  "*(indent+1)+toJson(x, indent+1))
  "[\n"+items.mkString(",\n")+"\n"+"  "*indent+"]"
  case s: String => "\""+s+"\""
  case other => other.toString
}

private def _str(x: Any): String = x match {
  case m: scala.collection.Map[_, _] => scala.collection.immutable.ListMap(m.toSeq.sortBy(_._1.toString): _*).toString.replace("ListMap", "Map")
  case d: Double => { val s = java.lang.Double.toString(d); if (s.indexOf('.') < 0 && !s.contains("e") && !s.contains("E")) s + ".0" else s }
  case other => String.valueOf(other)
}

def dot(x: ArrayBuffer[Double], y: ArrayBuffer[Double]): Double = {
  var sum: Double = 0.0
  var i: BigInt = BigInt(0)
  while (i < BigInt((x).size)) {
    sum = sum + x.lift((i.toInt).toInt).getOrElse(0.0) * y.lift((i.toInt).toInt).getOrElse(0.0)
    i = i + BigInt(1)
  }
  return sum
}

def run_steep_gradient_descent(data_x: ArrayBuffer[ArrayBuffer[Double]], data_y: ArrayBuffer[Double], len_data: BigInt, alpha: Double, theta: ArrayBuffer[Double]): ArrayBuffer[Double] = {
  var gradients: ArrayBuffer[Double] = ArrayBuffer[Double]()
  var j: BigInt = BigInt(0)
  while (j < BigInt((theta).size)) {
    gradients = (gradients :+ 0.0)
    j = j + BigInt(1)
  }
  var i: BigInt = BigInt(0)
  while (i < len_data) {
    var prediction: Double = dot(theta, data_x.lift((i.toInt).toInt).getOrElse(ArrayBuffer[Double]()))
    var error: Double = prediction - data_y.lift((i.toInt).toInt).getOrElse(0.0)
    var k: BigInt = BigInt(0)
    while (k < BigInt((theta).size)) {
      gradients((k).toInt) = gradients.lift((k.toInt).toInt).getOrElse(0.0) + error * data_x.lift((i.toInt).toInt).getOrElse(ArrayBuffer[Double]()).lift((k.toInt).toInt).getOrElse(0.0)
      k = k + BigInt(1)
    }
    i = i + BigInt(1)
  }
  var t: ArrayBuffer[Double] = ArrayBuffer[Double]()
  var g: BigInt = BigInt(0)
  while (g < BigInt((theta).size)) {
    t = (t :+ theta.lift((g.toInt).toInt).getOrElse(0.0) - alpha / len_data.toString.toDouble * gradients.lift((g.toInt).toInt).getOrElse(0.0))
    g = g + BigInt(1)
  }
  return t
}

def sum_of_square_error(data_x: ArrayBuffer[ArrayBuffer[Double]], data_y: ArrayBuffer[Double], len_data: BigInt, theta: ArrayBuffer[Double]): Double = {
  var total: Double = 0.0
  var i: BigInt = BigInt(0)
  while (i < len_data) {
    var prediction: Double = dot(theta, data_x.lift((i.toInt).toInt).getOrElse(ArrayBuffer[Double]()))
    var diff: Double = prediction - data_y.lift((i.toInt).toInt).getOrElse(0.0)
    total = total + diff * diff
    i = i + BigInt(1)
  }
  return total / (2.0 * len_data.toString.toDouble)
}

def run_linear_regression(data_x: ArrayBuffer[ArrayBuffer[Double]], data_y: ArrayBuffer[Double]): ArrayBuffer[Double] = {
  var iterations: BigInt = BigInt(10)
  var alpha: Double = 0.01
  var no_features: BigInt = BigInt((data_x.lift((BigInt(0).toInt).toInt).getOrElse(ArrayBuffer[Double]())).size)
  var len_data: BigInt = BigInt((data_x).size)
  var theta: ArrayBuffer[Double] = ArrayBuffer[Double]()
  var i: BigInt = BigInt(0)
  while (i < no_features) {
    theta = (theta :+ 0.0)
    i = i + BigInt(1)
  }
  var iter: BigInt = BigInt(0)
  while (iter < iterations) {
    theta = run_steep_gradient_descent(data_x, data_y, len_data, alpha, theta)
    var error: Double = sum_of_square_error(data_x, data_y, len_data, theta)
    println(_str("At Iteration " + _str(iter + BigInt(1)) + " - Error is " + _str(error)))
    iter = iter + BigInt(1)
  }
  return theta
}

def absf(x: Double): Double = {
  if (x < 0.0) {
    return -x
  } else {
    return x
  }
  return 0.0
}

def mean_absolute_error(predicted_y: ArrayBuffer[Double], original_y: ArrayBuffer[Double]): Double = {
  var total: Double = 0.0
  var i: BigInt = BigInt(0)
  while (i < BigInt((predicted_y).size)) {
    var diff: Double = absf(predicted_y.lift((i.toInt).toInt).getOrElse(0.0) - original_y.lift((i.toInt).toInt).getOrElse(0.0))
    total = total + diff
    i = i + BigInt(1)
  }
  return total / (BigInt((predicted_y).size)).toDouble
}

var data_x: ArrayBuffer[ArrayBuffer[Double]] = ArrayBuffer(ArrayBuffer(1.0, 1.0), ArrayBuffer(1.0, 2.0), ArrayBuffer(1.0, 3.0))

var data_y: ArrayBuffer[Double] = ArrayBuffer(1.0, 2.0, 3.0)

var i: BigInt = BigInt(0)

var predicted_y: ArrayBuffer[Double] = ArrayBuffer(3.0, -0.5, 2.0, 7.0)

var original_y: ArrayBuffer[Double] = ArrayBuffer(2.5, 0.0, 2.0, 8.0)

def main(args: Array[String]): Unit = {
  {
    System.gc()
    val _startMem = Runtime.getRuntime.totalMemory() - Runtime.getRuntime.freeMemory()
    val _start = _now()
    var theta: ArrayBuffer[Double] = run_linear_regression(data_x, data_y)
    println(_str("Resultant Feature vector :"))
    while (i < BigInt((theta).size)) {
      println(_str(_str(theta.lift((i.toInt).toInt).getOrElse(0.0))))
      i = i + BigInt(1)
    }
    var mae: Double = mean_absolute_error(predicted_y, original_y)
    println(_str("Mean Absolute Error : " + _str(mae)))
    val _end = _now()
    System.gc()
    val _endMem = Runtime.getRuntime.totalMemory() - Runtime.getRuntime.freeMemory()
    val _durUs = (_end - _start).abs / 1000
    var _memDiff = _endMem - _startMem
    if (_memDiff <= 0) _memDiff = _endMem
    println(toJson(scala.collection.immutable.Map("duration_us" -> _durUs, "memory_bytes" -> _memDiff, "name" -> "main")))
  }
}
}
