// Generated by Mochi v0.10.59 on 2025-08-07 12:43:53 GMT+7
import scala.collection.mutable.{ArrayBuffer, Map}
import scala.math.BigInt
import scala.collection.immutable.ListMap
object Main {
  private var _nowSeed: Long = 0L
  private var _nowSeeded: Boolean = false
  private def _now(): Int = {
    if (!_nowSeeded) {
      sys.env.get("MOCHI_NOW_SEED").foreach { s =>
      try { _nowSeed = s.toInt; _nowSeeded = true } catch { case _ : NumberFormatException => () }
    }
  }
  if (_nowSeeded) {
    _nowSeed = (_nowSeed * 1664525 + 1013904223) % 2147483647
    _nowSeed.toInt
  } else {
    Math.abs((System.nanoTime() / 1000).toInt)
  }
}

def toJson(value: Any, indent: Int = 0): String = value match {
  case m: scala.collection.Map[_, _] =>
  val items = ListMap(m.toSeq.sortBy(_._1.toString): _*).toSeq.map{ case (k,v) => "  "*(indent+1)+"\""+k.toString+"\": "+toJson(v, indent+1) }
  "{\n"+items.mkString(",\n")+"\n"+"  "*indent+"}"
  case s: Seq[_] =>
  val items = s.map(x => "  "*(indent+1)+toJson(x, indent+1))
  "[\n"+items.mkString(",\n")+"\n"+"  "*indent+"]"
  case s: String => "\""+s+"\""
  case other => other.toString
}

def dot(x: ArrayBuffer[Double], y: ArrayBuffer[Double]): Double = {
  var sum: Double = 0.0
  var i: BigInt = BigInt(0)
  while (i < BigInt((x).size)) {
    sum = sum + x((i.toInt).toInt) * y((i.toInt).toInt)
    i = i + BigInt(1)
  }
  return sum
}

def run_steep_gradient_descent(data_x: ArrayBuffer[ArrayBuffer[Double]], data_y: ArrayBuffer[Double], len_data: BigInt, alpha: Double, theta: ArrayBuffer[Double]): ArrayBuffer[Double] = {
  var gradients: ArrayBuffer[Double] = ArrayBuffer[Double]()
  var j: BigInt = BigInt(0)
  while (j < BigInt((theta).size)) {
    gradients = gradients :+ 0.0
    j = j + BigInt(1)
  }
  var i: BigInt = BigInt(0)
  while (i < len_data) {
    val prediction: Double = dot(theta, data_x((i.toInt).toInt))
    val error: Double = prediction - data_y((i.toInt).toInt)
    var k: BigInt = BigInt(0)
    while (k < BigInt((theta).size)) {
      gradients((k).toInt) = gradients((k.toInt).toInt) + error * data_x((i.toInt).toInt)((k.toInt).toInt)
      k = k + BigInt(1)
    }
    i = i + BigInt(1)
  }
  var t: ArrayBuffer[Double] = ArrayBuffer[Double]()
  var g: BigInt = BigInt(0)
  while (g < BigInt((theta).size)) {
    t = t :+ theta((g.toInt).toInt) - alpha / len_data.toString.toDouble * gradients((g.toInt).toInt)
    g = g + BigInt(1)
  }
  return t
}

def sum_of_square_error(data_x: ArrayBuffer[ArrayBuffer[Double]], data_y: ArrayBuffer[Double], len_data: BigInt, theta: ArrayBuffer[Double]): Double = {
  var total: Double = 0.0
  var i: BigInt = BigInt(0)
  while (i < len_data) {
    val prediction: Double = dot(theta, data_x((i.toInt).toInt))
    val diff: Double = prediction - data_y((i.toInt).toInt)
    total = total + diff * diff
    i = i + BigInt(1)
  }
  return total / (2.0 * len_data.toString.toDouble)
}

def run_linear_regression(data_x: ArrayBuffer[ArrayBuffer[Double]], data_y: ArrayBuffer[Double]): ArrayBuffer[Double] = {
  val iterations: BigInt = BigInt(10)
  val alpha: Double = 0.01
  val no_features: BigInt = BigInt((data_x((BigInt(0).toInt).toInt)).size)
  val len_data: BigInt = BigInt((data_x).size)
  var theta: ArrayBuffer[Double] = ArrayBuffer[Double]()
  var i: BigInt = BigInt(0)
  while (i < no_features) {
    theta = theta :+ 0.0
    i = i + BigInt(1)
  }
  var iter: BigInt = BigInt(0)
  while (iter < iterations) {
    theta = run_steep_gradient_descent(data_x, data_y, len_data, alpha, theta)
    val error: Double = sum_of_square_error(data_x, data_y, len_data, theta)
    println("At Iteration " + String.valueOf(iter + BigInt(1)) + " - Error is " + String.valueOf(error))
    iter = iter + BigInt(1)
  }
  return theta
}

def absf(x: Double): Double = {
  if (x < 0.0) {
    return -x
  } else {
    return x
  }
  return 0.0
}

def mean_absolute_error(predicted_y: ArrayBuffer[Double], original_y: ArrayBuffer[Double]): Double = {
  var total: Double = 0.0
  var i: BigInt = BigInt(0)
  while (i < BigInt((predicted_y).size)) {
    val diff: Double = absf(predicted_y((i.toInt).toInt) - original_y((i.toInt).toInt))
    total = total + diff
    i = i + BigInt(1)
  }
  return total / (BigInt((predicted_y).size)).toString.toDouble
}

val data_x: ArrayBuffer[ArrayBuffer[Double]] = ArrayBuffer(ArrayBuffer(1.0, 1.0), ArrayBuffer(1.0, 2.0), ArrayBuffer(1.0, 3.0))

val data_y: ArrayBuffer[Double] = ArrayBuffer(1.0, 2.0, 3.0)

val theta: ArrayBuffer[Double] = run_linear_regression(data_x, data_y)

val predicted_y: ArrayBuffer[Double] = ArrayBuffer(3.0, -0.5, 2.0, 7.0)

val original_y: ArrayBuffer[Double] = ArrayBuffer(2.5, 0.0, 2.0, 8.0)

val mae: Double = mean_absolute_error(predicted_y, original_y)

def main(args: Array[String]): Unit = {
  {
    System.gc()
    val _startMem = Runtime.getRuntime.totalMemory() - Runtime.getRuntime.freeMemory()
    val _start = _now()
    println("Resultant Feature vector :")
    var i: BigInt = BigInt(0)
    while (i < BigInt((theta).size)) {
      println(String.valueOf(theta((i.toInt).toInt)))
      i = i + BigInt(1)
    }
    println("Mean Absolute Error : " + String.valueOf(mae))
    val _end = _now()
    System.gc()
    val _endMem = Runtime.getRuntime.totalMemory() - Runtime.getRuntime.freeMemory()
    val _durUs = (_end - _start) / 1000
    var _memDiff = _endMem - _startMem
    if (_memDiff <= 0) _memDiff = _endMem
    println(toJson(scala.collection.immutable.Map("duration_us" -> _durUs, "memory_bytes" -> _memDiff, "name" -> "main")))
  }
}
}
