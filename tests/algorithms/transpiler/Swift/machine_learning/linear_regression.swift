// Generated by Mochi transpiler v0.10.62 on 2025-08-09 16:38:17 GMT+7
import Foundation
import Dispatch
#if canImport(FoundationNetworking)
import FoundationNetworking
#endif

let stdout = FileHandle.standardOutput
extension FileHandle {
    func write(_ string: String) {
        if let data = string.data(using: .utf8) {
            self.write(data)
        }
    }
}

func _p(_ v: Any?) -> String {
    if let val = v {
        if let d = val as? Double {
            if d.rounded(.towardZero) == d {
                return String(Int64(d))
            }
        }
        return String(describing: val)
    }
    return "<nil>"
}

extension Double { init(_ v: Any) { if let d = v as? Double { self = d } else if let i = v as? Int { self = Double(i) } else if let i = v as? Int64 { self = Double(i) } else if let s = v as? String { self = Double(s) ?? 0 } else { self = 0 } } }
var _nowSeed = 0
var _nowSeeded = false
func _now() -> Int {
    if !_nowSeeded {
        if let s = ProcessInfo.processInfo.environment["MOCHI_NOW_SEED"], let v = Int(s) {
            _nowSeed = v
            _nowSeeded = true
        }
    }
    if _nowSeeded {
        _nowSeed = (_nowSeed * 1664525 + 1013904223) % 2147483647
        return _nowSeed
    }
    return Int(DispatchTime.now().uptimeNanoseconds)
}
func _int(_ v: Any) -> Int {
    if let s = v as? String { return Int(s) ?? 0 }
    if let i = v as? Int { return i }
    if let i = v as? Int64 { return Int(i) }
    if let d = v as? Double { return Int(d) }
    return 0
}
func _mem() -> Int {
    if let status = try? String(contentsOfFile: "/proc/self/status") {
        for line in status.split(separator: "\n") {
            if line.hasPrefix("VmRSS:") {
                let parts = line.split(whereSeparator: { $0 == " " || $0 == "\t" })
                if parts.count >= 2, let kb = Int(parts[1]) {
                    return kb * 1024
                }
            }
        }
    }
    return 0
}
func _idx<T>(_ xs: [T], _ i: Int) -> T? {
    var idx = i
    if idx < 0 { idx += xs.count }
    if idx >= 0 && idx < xs.count { return xs[idx] }
    return xs.first
}
func _append<T>(_ xs: [T], _ v: T) -> [T] {
    var out = xs
    out.append(v)
    return out
}
func _set<T>(_ xs: [T], _ idx: Int, _ v: T) -> [T] {
    var out = xs
    if idx < out.count {
        out[idx] = v
    } else {
        out.append(contentsOf: Array(repeating: v, count: idx - out.count + 1))
        out[idx] = v
    }
    return out
}
func _set<K: Hashable, V>(_ xs: [K: V], _ key: K, _ v: V) -> [K: V] {
    var out = xs
    out[key] = v
    return out
}
do {
    let _benchMemStart = _mem()
    let _benchStart = _now()
    func dot(_ x: [Double], _ y: [Double]) -> Double {
        var sum: Double = 0.0
        var i: Int = 0
        while (i < _int(((x).count))) {
            sum = Double((sum + (Double(_idx(x, i)) * Double(_idx(y, i)))))
            i = _int((i &+ 1))
        }
        return sum
    }
    func run_steep_gradient_descent(_ data_x: [[Double]], _ data_y: [Double], _ len_data: Int, _ alpha: Double, _ theta: [Double]) -> [Double] {
        var gradients: [Double] = ([] as! [Double])
        var j: Int = 0
        while (j < _int(((theta).count))) {
            gradients = (_append(gradients, 0.0) as! [Double])
            j = _int((j &+ 1))
        }
        var i: Int = 0
        while (i < len_data) {
            let prediction = Double(dot((theta as! [Double]), (_idx(data_x, i) as! [Double])))
            let error = (prediction - Double(_idx(data_y, i)))
            var k: Int = 0
            while (k < _int(((theta).count))) {
                gradients = _set(gradients, k, Double((Double(_idx(gradients, k)) + (error * Double(_idx(_idx(data_x, i)!, k))))))
                k = _int((k &+ 1))
            }
            i = _int((i &+ 1))
        }
        var t: [Double] = ([] as! [Double])
        var g: Int = 0
        while (g < _int(((theta).count))) {
            t = (_append(t, (Double(_idx(theta, g)) - (Double((alpha / Double(len_data))) * Double(_idx(gradients, g))))) as! [Double])
            g = _int((g &+ 1))
        }
        return t
    }
    func sum_of_square_error(_ data_x: [[Double]], _ data_y: [Double], _ len_data: Int, _ theta: [Double]) -> Double {
        var total: Double = 0.0
        var i: Int = 0
        while (i < len_data) {
            let prediction = Double(dot((theta as! [Double]), (_idx(data_x, i) as! [Double])))
            let diff = (prediction - Double(_idx(data_y, i)))
            total = Double((total + (diff * diff)))
            i = _int((i &+ 1))
        }
        return (total / Double((2.0 * Double(len_data))))
    }
    func run_linear_regression(_ data_x: [[Double]], _ data_y: [Double]) -> [Double] {
        let iterations: Int = 10
        let alpha: Double = 0.01
        let no_features: Int = _int((((_idx(data_x, 0) as! [Double])).count))
        let len_data: Int = _int(((data_x).count))
        var theta: [Double] = ([] as! [Double])
        var i: Int = 0
        while (i < no_features) {
            theta = (_append(theta, 0.0) as! [Double])
            i = _int((i &+ 1))
        }
        var iter: Int = 0
        while (iter < iterations) {
            theta = (run_steep_gradient_descent((data_x as! [[Double]]), (data_y as! [Double]), len_data, Double(alpha), (theta as! [Double])) as! [Double])
            let error = Double(sum_of_square_error((data_x as! [[Double]]), (data_y as! [Double]), len_data, (theta as! [Double])))
            print(_p(((("At Iteration " + _p((iter &+ 1))) + " - Error is ") + _p(error))))
            iter = _int((iter &+ 1))
        }
        return theta
    }
    func absf(_ x: Double) -> Double {
        if (x < 0.0) {
            return -x
        } else {
            return x
        }
    }
    func mean_absolute_error(_ predicted_y: [Double], _ original_y: [Double]) -> Double {
        var total: Double = 0.0
        var i: Int = 0
        while (i < _int(((predicted_y).count))) {
            let diff = Double(absf(Double((Double(_idx(predicted_y, i)) - Double(_idx(original_y, i))))))
            total = Double((total + diff))
            i = _int((i &+ 1))
        }
        return (total / Double(_int(((predicted_y).count))))
    }
    let data_x: [[Double]] = ({
        var _arr: [[Double]] = []
        _arr = _append(_arr, ({
            var _arr: [Double] = []
            _arr = _append(_arr, 1.0)
            _arr = _append(_arr, 1.0)
            return _arr
        }() as! [Double]))
        _arr = _append(_arr, ({
            var _arr: [Double] = []
            _arr = _append(_arr, 1.0)
            _arr = _append(_arr, 2.0)
            return _arr
        }() as! [Double]))
        _arr = _append(_arr, ({
            var _arr: [Double] = []
            _arr = _append(_arr, 1.0)
            _arr = _append(_arr, 3.0)
            return _arr
        }() as! [Double]))
        return _arr
    }() as! [[Double]])
    let data_y: [Double] = ({
        var _arr: [Double] = []
        _arr = _append(_arr, 1.0)
        _arr = _append(_arr, 2.0)
        _arr = _append(_arr, 3.0)
        return _arr
    }() as! [Double])
    var theta: [Double] = (run_linear_regression((data_x as! [[Double]]), (data_y as! [Double])) as! [Double])
    print(_p("Resultant Feature vector :"))
    var i: Int = 0
    while (i < _int(((theta).count))) {
        print(_p(_p(Double(_idx(theta, i)))))
        i = _int((i &+ 1))
    }
    let predicted_y: [Double] = ({
        var _arr: [Double] = []
        _arr = _append(_arr, 3.0)
        _arr = _append(_arr, -0.5)
        _arr = _append(_arr, 2.0)
        _arr = _append(_arr, 7.0)
        return _arr
    }() as! [Double])
    let original_y: [Double] = ({
        var _arr: [Double] = []
        _arr = _append(_arr, 2.5)
        _arr = _append(_arr, 0.0)
        _arr = _append(_arr, 2.0)
        _arr = _append(_arr, 8.0)
        return _arr
    }() as! [Double])
    let mae = Double(mean_absolute_error((predicted_y as! [Double]), (original_y as! [Double])))
    print(_p(("Mean Absolute Error : " + _p(mae))))
    let _benchEnd = _now()
    let _benchMemEnd = _mem()
    print("{\n  \"duration_us\": \((_benchEnd - _benchStart) / 1000),\n  \"memory_bytes\": \(_benchMemEnd - _benchMemStart),\n  \"name\": \"main\"\n}")
}
