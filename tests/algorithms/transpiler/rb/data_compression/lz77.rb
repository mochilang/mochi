# Generated by Mochi transpiler v0.10.59 on 2025-08-06 20:30 +0700
require 'json'

$now_seed = 0
$now_seeded = false
s = ENV['MOCHI_NOW_SEED']
if (!s || s == '') && ENV['MOCHI_BENCHMARK']
  s = '1'
end
if s && s != ''
  begin
    $now_seed = Integer(s)
    $now_seeded = true
  rescue StandardError
  end
end
def _now()
  if $now_seeded
    $now_seed += 1_000_000
    $now_seed
  else
    Process.clock_gettime(Process::CLOCK_MONOTONIC, :nanosecond)
  end
end


require 'objspace'
def _mem()
  ObjectSpace.memsize_of_all
end


def _add(a, b)
  if a.is_a?(Array) && b.is_a?(String)
    a.join + b
  elsif a.is_a?(String) && b.is_a?(Array)
    a + b.join
  else
    a + b
  end
end


def _padStart(s, len, ch)
  s.to_s.rjust(len, ch)
end


class String
  alias each each_char
end

start_mem = _mem()
start = _now()
  def token_to_string(t)
    return _add(_add(_add(_add(_add(_add("(", (t["offset"]).to_s), ", "), (t["length"]).to_s), ", "), t["indicator"]), ")")
  end
  def tokens_to_string(ts)
    res = "["
    i = 0
    while i < ts.length
      res = _add(res, token_to_string(ts[i]))
      if i < ts.length - 1
        res = _add(res, ", ")
      end
      i = _add(i, 1)
    end
    return _add(res, "]")
  end
  def match_length_from_index(text, window, text_index, window_index)
    if text_index >= text.length || window_index >= window.length
      return 0
    end
    tc = text[text_index..._add(text_index, 1)]
    wc = window[window_index..._add(window_index, 1)]
    if tc != wc
      return 0
    end
    return _add(1, match_length_from_index(text, _add(window, tc), _add(text_index, 1), _add(window_index, 1)))
  end
  def find_encoding_token(text, search_buffer)
    if text.length == 0
      panic("We need some text to work with.")
    end
    length = 0
    offset = 0
    if search_buffer.length == 0
      return Token.new(offset: offset, length: length, indicator: text[0...1])
    end
    i = 0
    while i < search_buffer.length
      ch = search_buffer[i..._add(i, 1)]
      found_offset = search_buffer.length - i
      if ch == text[0...1]
        found_length = match_length_from_index(text, search_buffer, 0, i)
        if found_length >= length
          offset = found_offset
          length = found_length
        end
      end
      i = _add(i, 1)
    end
    return Token.new(offset: offset, length: length, indicator: text[length..._add(length, 1)])
  end
  def lz77_compress(text, window_size, lookahead)
    search_buffer_size = window_size - lookahead
    output = []
    search_buffer = ""
    remaining = text
    while remaining.length > 0
      token = find_encoding_token(remaining, search_buffer)
      add_len = _add(token["length"], 1)
      search_buffer = _add(search_buffer, remaining[0...add_len])
      if search_buffer.length > search_buffer_size
        search_buffer = search_buffer[search_buffer.length - search_buffer_size...search_buffer.length]
      end
      remaining = remaining[add_len...remaining.length]
      output = (output + [token])
    end
    return output
  end
  def lz77_decompress(tokens)
    output = ""
        __tmp21 = tokens
    if __tmp21.respond_to?(:keys) && !__tmp21.is_a?(String)
      __tmp21 = __tmp21.keys
    end
    __tmp21.each do |t|
      i = 0
      while i < t["length"]
        output = _add(output, output[output.length - t["offset"]..._add(output.length - t["offset"], 1)])
        i = _add(i, 1)
      end
      output = _add(output, t["indicator"])
    end
    return output
  end
  Token = Struct.new(:offset, :length, :indicator, keyword_init: true)
  $c1 = lz77_compress("ababcbababaa", 13, 6)
  puts(tokens_to_string($c1))
  $c2 = lz77_compress("aacaacabcabaaac", 13, 6)
  puts(tokens_to_string($c2))
  $tokens_example = [Token.new(offset: 0, length: 0, indicator: "c"), Token.new(offset: 0, length: 0, indicator: "a"), Token.new(offset: 0, length: 0, indicator: "b"), Token.new(offset: 0, length: 0, indicator: "r"), Token.new(offset: 3, length: 1, indicator: "c"), Token.new(offset: 2, length: 1, indicator: "d"), Token.new(offset: 7, length: 4, indicator: "r"), Token.new(offset: 3, length: 5, indicator: "d")]
  puts(lz77_decompress($tokens_example))
end_time = _now()
end_mem = _mem()
result = {"duration_us" => ((end_time - start) / 1000), "memory_bytes" => (end_mem - start_mem), "name" => "main"}
puts(JSON.pretty_generate(result))
