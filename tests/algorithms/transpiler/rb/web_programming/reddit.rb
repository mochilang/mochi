# Generated by Mochi transpiler v0.10.59 on 2025-08-07 11:45 +0700
require 'json'

$now_seed = 0
$now_seeded = false
s = ENV['MOCHI_NOW_SEED']
if (!s || s == '') && ENV['MOCHI_BENCHMARK']
  s = '1'
end
if s && s != ''
  begin
    $now_seed = Integer(s)
    $now_seeded = true
  rescue StandardError
  end
end
def _now()
  if $now_seeded
    $now_seed += 1_000_000
    $now_seed
  else
    Process.clock_gettime(Process::CLOCK_MONOTONIC, :nanosecond)
  end
end


require 'net/http'
require 'uri'
require 'ostruct'
require 'json'
def _json_to_struct(obj)
  case obj
  when Hash
    OpenStruct.new(obj.transform_values { |v| _json_to_struct(v) })
  when Array
    obj.map { |v| _json_to_struct(v) }
  else
    obj
  end
end
def _fetch(url, opts = nil)
  uri = URI.parse(url)
  if uri.scheme.nil? || uri.scheme == ''
    base = File.expand_path('../../../../..', __dir__)
    body = File.read(File.expand_path(url, base))
  else
    method = opts && opts['method'] ? opts['method'].to_s.upcase : 'GET'
    req_class = Net::HTTP.const_get(method.capitalize)
    req = req_class.new(uri)
    if opts && opts['headers']
      opts['headers'].each { |k,v| req[k] = v }
    end
    if opts && opts.key?('body')
      req.body = opts['body'].to_json
    end
    if opts && opts['query']
      uri.query = URI.encode_www_form(opts['query'])
    end
    resp = Net::HTTP.start(uri.host, uri.port, use_ssl: uri.scheme == 'https') do |http|
      http.request(req)
    end
    body = resp.body
  end
  begin
    data = JSON.parse(body)
    _json_to_struct(data)
  rescue StandardError
    body
  end
end


require 'objspace'
def _mem()
  ObjectSpace.memsize_of_all
end


def _add(a, b)
  if a.is_a?(Array) && b.is_a?(String)
    a.join + b
  elsif a.is_a?(String) && b.is_a?(Array)
    a + b.join
  else
    a + b
  end
end


def _padStart(s, len, ch)
  s.to_s.rjust(len, ch)
end


def _str(x)
  if x.is_a?(Float) && x == x.to_i
    x.to_i.to_s
  else
    x.to_s
  end
end


class String
  alias each each_char
end


def panic(msg)
  raise RuntimeError, msg
end

start_mem = _mem()
start = _now()
  def contains(xs, x)
    i = 0.clone
    while i < xs.length
      if xs[i] == x
        return true
      end
      i = _add(i, 1).clone
    end
    return false
  end
  def join_with_comma(xs)
    s = "".clone
    i = 0.clone
    while i < xs.length
      if i > 0
        s = _add(s, ", ").clone
      end
      s = _add(s, xs[i]).clone
      i = _add(i, 1).clone
    end
    return s
  end
  def get_subreddit_data(subreddit, limit, age, wanted_data)
    invalid = [].clone
    i = 0.clone
    while i < wanted_data.length
      term = wanted_data[i]
      if !contains($valid_terms, term)
        invalid = (invalid << (term)).clone
      end
      i = _add(i, 1).clone
    end
    if invalid.length > 0
      msg = _add("Invalid search term: ", join_with_comma(invalid))
      panic(msg)
    end
    resp = _fetch("tests/github/TheAlgorithms/Mochi/web_programming/reddit_sample.json")
    result = {}.clone
    idx = 0.clone
    while idx < limit
      post = resp["data"]["children"][idx]["data"]
      post_map = {}.clone
      if wanted_data.length == 0
        post_map["title"] = post["title"]
        post_map["url"] = post["url"]
        post_map["selftext"] = post["selftext"]
      else
        j = 0.clone
        while j < wanted_data.length
          field = wanted_data[j]
          if field == "title"
            post_map["title"] = post["title"]
          else
            if field == "url"
              post_map["url"] = post["url"]
            else
              if field == "selftext"
                post_map["selftext"] = post["selftext"]
              end
            end
          end
          j = _add(j, 1).clone
        end
      end
      result[idx] = post_map
      idx = _add(idx, 1).clone
    end
    return result
  end
  Post = Struct.new(:title, :url, :selftext, keyword_init: true)
  Child = Struct.new(:data, keyword_init: true)
  ListingData = Struct.new(:children, keyword_init: true)
  Listing = Struct.new(:data, keyword_init: true)
  $valid_terms = ["approved_at_utc", "approved_by", "author_flair_background_color", "author_flair_css_class", "author_flair_richtext", "author_flair_template_id", "author_fullname", "author_premium", "can_mod_post", "category", "clicked", "content_categories", "created_utc", "downs", "edited", "gilded", "gildings", "hidden", "hide_score", "is_created_from_ads_ui", "is_meta", "is_original_content", "is_reddit_media_domain", "is_video", "link_flair_css_class", "link_flair_richtext", "link_flair_text", "link_flair_text_color", "media_embed", "mod_reason_title", "name", "permalink", "pwls", "quarantine", "saved", "score", "secure_media", "secure_media_embed", "selftext", "subreddit", "subreddit_name_prefixed", "subreddit_type", "thumbnail", "title", "top_awarded_type", "total_awards_received", "ups", "upvote_ratio", "url", "user_reports"]
  puts(get_subreddit_data("learnpython", 1, "new", ["title", "url", "selftext"]))
end_time = _now()
end_mem = _mem()
result = {"duration_us" => ((end_time - start) / 1000), "memory_bytes" => (end_mem - start_mem), "name" => "main"}
puts(JSON.pretty_generate(result))
