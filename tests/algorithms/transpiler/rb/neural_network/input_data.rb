# Generated by Mochi transpiler v0.10.73 on 2025-08-26 08:36 +0700
$VERBOSE = nil
require 'json'

$now_seed = 0
$now_seeded = false
s = ENV['MOCHI_NOW_SEED']
if s && s != ''
  begin
    $now_seed = Integer(s)
    $now_seeded = true
  rescue StandardError
  end
end
if !$now_seeded && ENV['MOCHI_BENCHMARK']
  $now_seeded = true
end
def _now()
  if $now_seeded
    $now_seed = ($now_seed * 1_664_525 + 1_013_904_223) % 2_147_483_647
    $now_seed
  else
    Process.clock_gettime(Process::CLOCK_MONOTONIC, :nanosecond)
  end
end


require 'objspace'
def _mem()
  ObjectSpace.memsize_of_all
end


def _idx(arr, idx)
  return nil if arr.nil?
  if (arr.is_a?(Array) || arr.is_a?(String)) && idx.is_a?(Numeric)
    idx += arr.length if idx < 0
    return nil if idx < 0 || idx >= arr.length
  end
  arr[idx]
end


def _pow(a, b)
  res = (a.nil? ? 0 : a) ** (b.nil? ? 0 : b)
  res.is_a?(Float) && res == res.to_i ? res.to_i : res
end


def _len(x)
  x.respond_to?(:length) ? x.length : 0
end


def _has(obj, key)
  if obj.is_a?(Hash)
    obj.key?(key)
  elsif obj.respond_to?(:include?)
    obj.include?(key)
  elsif obj.respond_to?(:to_h)
    k = key.respond_to?(:to_sym) ? key.to_sym : key
    obj.to_h.key?(k)
  else
    false
  end
end


def _add(a, b)
  if a.is_a?(Array) && b.is_a?(String)
    a.join + b
  elsif a.is_a?(String) && b.is_a?(Array)
    a + b.join
  elsif a.is_a?(Array) && b.is_a?(Array)
    a + b
  elsif a.is_a?(Array) && !b.is_a?(Array)
    a + [b]
  elsif !a.is_a?(Array) && b.is_a?(Array)
    [a] + b
  elsif a.is_a?(String) || b.is_a?(String)
    a.to_s + b.to_s
  else
    (a.nil? ? 0 : a) + (b.nil? ? 0 : b)
  end
end


def _append(arr, x)
  arr = arr.nil? ? [] : arr.clone
  x = x.clone if x.is_a?(Array)
  arr << x
  arr
end


def _eq(a, b)
  if a.is_a?(Float) || b.is_a?(Float)
    diff = (a.to_f - b.to_f).abs
    scale = [a.to_f.abs, b.to_f.abs].max
    scale = 1.0 if scale == 0.0
    diff <= 1e-8 * scale
  else
    a == b
  end
end


def _padStart(s, len, ch)
  s.to_s.rjust(len, ch)
end


def _padEnd(s, len, ch)
  s.to_s.ljust(len, ch)
end


def _str(x)
  if x.is_a?(Array)
    "[" + x.map { |e| _str(e) }.join(' ') + "]"
  elsif x.is_a?(Float)
    x % 1 == 0 ? x.to_i.to_s : x.to_s
  else
    x.to_s
  end
end


class String
  alias each each_char
end


def panic(msg)
  raise RuntimeError, msg
end

__name__ = '__main__'
start_mem = _mem()
start = Process.clock_gettime(Process::CLOCK_MONOTONIC, :nanosecond)
  def dense_to_one_hot(labels, num_classes)
    result = []
    i = 0
    while i < _len(labels)
      row = []
      j = 0
      while j < num_classes
        if _eq(j, (__tmp1 = labels; __tmp1.is_a?(Hash) ? __tmp1[i] : _idx(__tmp1, i)))
          row = _append(row, 1)
        else
          row = _append(row, 0)
        end
        j = _add(j, 1)
      end
      result = _append(result, row)
      i = _add(i, 1)
    end
    return result
  end
  def new_dataset(images, labels)
    return DataSet.new(images: images, labels: labels, num_examples: _len(images), index_in_epoch: 0, epochs_completed: 0)
  end
  def next_batch(ds, batch_size)
    start = ds.index_in_epoch
    if _add(start, batch_size) > ds.num_examples
      rest = ds.num_examples - start
      images_rest = ds.images[start...ds.num_examples]
      labels_rest = ds.labels[start...ds.num_examples]
      new_index = batch_size - rest
      images_new = ds.images[0...new_index]
      labels_new = ds.labels[0...new_index]
      batch_images = _add(images_rest, images_new)
      batch_labels = _add(labels_rest, labels_new)
      new_ds = DataSet.new(images: ds.images, labels: ds.labels, num_examples: ds.num_examples, index_in_epoch: new_index, epochs_completed: _add(ds.epochs_completed, 1))
      return BatchResult.new(dataset: new_ds, images: batch_images, labels: batch_labels)
    else
      end_ = _add(start, batch_size)
      batch_images = ds.images[start...end_]
      batch_labels = ds.labels[start...end_]
      new_ds = DataSet.new(images: ds.images, labels: ds.labels, num_examples: ds.num_examples, index_in_epoch: end_, epochs_completed: ds.epochs_completed)
      return BatchResult.new(dataset: new_ds, images: batch_images, labels: batch_labels)
    end
  end
  def read_data_sets(train_images, train_labels_raw, test_images, test_labels_raw, validation_size, num_classes)
    train_labels = dense_to_one_hot(train_labels_raw, num_classes)
    test_labels = dense_to_one_hot(test_labels_raw, num_classes)
    validation_images = train_images[0...validation_size]
    validation_labels = train_labels[0...validation_size]
    train_images_rest = train_images[validation_size..._len(train_images)]
    train_labels_rest = train_labels[validation_size..._len(train_labels)]
    train = new_dataset(train_images_rest, train_labels_rest)
    validation = new_dataset(validation_images, validation_labels)
    testset = new_dataset(test_images, test_labels)
    return Datasets.new(train: train, validation: validation, test_ds: testset)
  end
  def main()
    train_images = [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5]]
    train_labels_raw = [0, 1, 2, 3, 4]
    test_images = [[5, 6], [6, 7]]
    test_labels_raw = [5, 6]
    data = read_data_sets(train_images, train_labels_raw, test_images, test_labels_raw, 2, 10)
    ds = data.train
    res = next_batch(ds, 2)
    ds = res.dataset
    puts(((x = res.images); x.is_a?(Array) ? ("[" + x.map{ |x| if x.is_a?(Hash) then '{' + x.to_h.map{ |k,v| "#{k}: #{v.is_a?(String) ? v : v.to_s}" }.join(', ') + '}' else x.to_s end }.join(' ') + "]") : x.to_s))
    puts(((x = res.labels); x.is_a?(Array) ? ("[" + x.map{ |x| if x.is_a?(Hash) then '{' + x.to_h.map{ |k,v| "#{k}: #{v.is_a?(String) ? v : v.to_s}" }.join(', ') + '}' else x.to_s end }.join(' ') + "]") : x.to_s))
    res = next_batch(ds, 2)
    ds = res.dataset
    puts(((x = res.images); x.is_a?(Array) ? ("[" + x.map{ |x| if x.is_a?(Hash) then '{' + x.to_h.map{ |k,v| "#{k}: #{v.is_a?(String) ? v : v.to_s}" }.join(', ') + '}' else x.to_s end }.join(' ') + "]") : x.to_s))
    puts(((x = res.labels); x.is_a?(Array) ? ("[" + x.map{ |x| if x.is_a?(Hash) then '{' + x.to_h.map{ |k,v| "#{k}: #{v.is_a?(String) ? v : v.to_s}" }.join(', ') + '}' else x.to_s end }.join(' ') + "]") : x.to_s))
    res = next_batch(ds, 2)
    ds = res.dataset
    puts(((x = res.images); x.is_a?(Array) ? ("[" + x.map{ |x| if x.is_a?(Hash) then '{' + x.to_h.map{ |k,v| "#{k}: #{v.is_a?(String) ? v : v.to_s}" }.join(', ') + '}' else x.to_s end }.join(' ') + "]") : x.to_s))
    puts(((x = res.labels); x.is_a?(Array) ? ("[" + x.map{ |x| if x.is_a?(Hash) then '{' + x.to_h.map{ |k,v| "#{k}: #{v.is_a?(String) ? v : v.to_s}" }.join(', ') + '}' else x.to_s end }.join(' ') + "]") : x.to_s))
  end
  Object.send(:remove_const, :DataSet) if Object.const_defined?(:DataSet)
  Object.const_set(:DataSet, Struct.new(:images, :labels, :num_examples, :index_in_epoch, :epochs_completed, keyword_init: true))
  Object.send(:remove_const, :Datasets) if Object.const_defined?(:Datasets)
  Object.const_set(:Datasets, Struct.new(:train, :validation, :test_ds, keyword_init: true))
  Object.send(:remove_const, :BatchResult) if Object.const_defined?(:BatchResult)
  Object.const_set(:BatchResult, Struct.new(:dataset, :images, :labels, keyword_init: true))
  main()
end_time = Process.clock_gettime(Process::CLOCK_MONOTONIC, :nanosecond)
end_mem = _mem()
result = {"duration_us" => ((end_time - start) / 1000), "memory_bytes" => (end_mem - start_mem), "name" => "main"}
puts(JSON.pretty_generate(result))
