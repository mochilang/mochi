# Generated by Mochi transpiler v0.10.59 on 2025-08-07 08:16 +0700
require 'json'

$now_seed = 0
$now_seeded = false
s = ENV['MOCHI_NOW_SEED']
if (!s || s == '') && ENV['MOCHI_BENCHMARK']
  s = '1'
end
if s && s != ''
  begin
    $now_seed = Integer(s)
    $now_seeded = true
  rescue StandardError
  end
end
def _now()
  if $now_seeded
    $now_seed += 1_000_000
    $now_seed
  else
    Process.clock_gettime(Process::CLOCK_MONOTONIC, :nanosecond)
  end
end


require 'objspace'
def _mem()
  ObjectSpace.memsize_of_all
end


def _add(a, b)
  if a.is_a?(Array) && b.is_a?(String)
    a.join + b
  elsif a.is_a?(String) && b.is_a?(Array)
    a + b.join
  else
    a + b
  end
end


def _padStart(s, len, ch)
  s.to_s.rjust(len, ch)
end


def _str(x)
  if x.is_a?(Float) && x == x.to_i
    x.to_i.to_s
  else
    x.to_s
  end
end


class String
  alias each each_char
end


def panic(msg)
  raise RuntimeError, msg
end

start_mem = _mem()
start = _now()
  def rand()
    $seed = (_add($seed * 1103515245, 12345)) % 2147483648.clone
    return $seed
  end
  def random()
    return (1.0 * rand()) / 2147483648.0
  end
  def expApprox(x)
    y = x.clone
    is_neg = false.clone
    if x < 0.0
      is_neg = true.clone
      y = -x.clone
    end
    term = 1.0.clone
    sum = 1.0.clone
    n = 1.clone
    while n < 30
      term = term * y / ((n).to_f).clone
      sum = _add(sum, term).clone
      n = _add(n, 1).clone
    end
    if is_neg
      return 1.0 / sum
    end
    return sum
  end
  def sigmoid(z)
    return 1.0 / (_add(1.0, expApprox(-z)))
  end
  def sigmoid_vec(v)
    res = [].clone
    i = 0.clone
    while i < v.length
      res = (res << (sigmoid(v[i]))).clone
      i = _add(i, 1).clone
    end
    return res
  end
  def sigmoid_derivative(out)
    res = [].clone
    i = 0.clone
    while i < out.length
      val = out[i]
      res = (res << (val * (1.0 - val))).clone
      i = _add(i, 1).clone
    end
    return res
  end
  def random_vector(n)
    v = [].clone
    i = 0.clone
    while i < n
      v = (v << (random() - 0.5)).clone
      i = _add(i, 1).clone
    end
    return v
  end
  def random_matrix(r, c)
    m = [].clone
    i = 0.clone
    while i < r
      m = (m << (random_vector(c))).clone
      i = _add(i, 1).clone
    end
    return m
  end
  def matvec(mat, vec)
    res = [].clone
    i = 0.clone
    while i < mat.length
      s = 0.0.clone
      j = 0.clone
      while j < vec.length
        s = _add(s, mat[i][j] * vec[j]).clone
        j = _add(j, 1).clone
      end
      res = (res << (s)).clone
      i = _add(i, 1).clone
    end
    return res
  end
  def matTvec(mat, vec)
    cols = mat[0].length.clone
    res = [].clone
    j = 0.clone
    while j < cols
      s = 0.0.clone
      i = 0.clone
      while i < mat.length
        s = _add(s, mat[i][j] * vec[i]).clone
        i = _add(i, 1).clone
      end
      res = (res << (s)).clone
      j = _add(j, 1).clone
    end
    return res
  end
  def vec_sub(a, b)
    res = [].clone
    i = 0.clone
    while i < a.length
      res = (res << (a[i] - b[i])).clone
      i = _add(i, 1).clone
    end
    return res
  end
  def vec_mul(a, b)
    res = [].clone
    i = 0.clone
    while i < a.length
      res = (res << (a[i] * b[i])).clone
      i = _add(i, 1).clone
    end
    return res
  end
  def vec_scalar_mul(v, s)
    res = [].clone
    i = 0.clone
    while i < v.length
      res = (res << (v[i] * s)).clone
      i = _add(i, 1).clone
    end
    return res
  end
  def outer(a, b)
    res = [].clone
    i = 0.clone
    while i < a.length
      row = [].clone
      j = 0.clone
      while j < b.length
        row = (row << (a[i] * b[j])).clone
        j = _add(j, 1).clone
      end
      res = (res << (row)).clone
      i = _add(i, 1).clone
    end
    return res
  end
  def mat_scalar_mul(mat, s)
    res = [].clone
    i = 0.clone
    while i < mat.length
      row = [].clone
      j = 0.clone
      while j < mat[i].length
        row = (row << (mat[i][j] * s)).clone
        j = _add(j, 1).clone
      end
      res = (res << (row)).clone
      i = _add(i, 1).clone
    end
    return res
  end
  def mat_sub(a, b)
    res = [].clone
    i = 0.clone
    while i < a.length
      row = [].clone
      j = 0.clone
      while j < a[i].length
        row = (row << (a[i][j] - b[i][j])).clone
        j = _add(j, 1).clone
      end
      res = (res << (row)).clone
      i = _add(i, 1).clone
    end
    return res
  end
  def init_layer(units, back_units, lr)
    return Layer.new(units: units, weight: random_matrix(units, back_units), bias: random_vector(units), output: [], xdata: [], learn_rate: lr)
  end
  def forward(layers, x)
    data = x.clone
    i = 0.clone
    while i < layers.length
      layer = layers[i].clone
      layer["xdata"] = data
      if i == 0
        layer["output"] = data
      else
        z = vec_sub(matvec(layer.weight, data), layer.bias)
        layer["output"] = sigmoid_vec(z)
        data = layer.output.clone
      end
      layers[i] = layer
      i = _add(i, 1).clone
    end
    return layers
  end
  def backward(layers, grad)
    g = grad.clone
    i = layers.length - 1.clone
    while i > 0
      layer = layers[i].clone
      deriv = sigmoid_derivative(layer.output)
      delta = vec_mul(g, deriv)
      grad_w = outer(delta, layer.xdata)
      layer["weight"] = mat_sub(layer.weight, mat_scalar_mul(grad_w, layer.learn_rate))
      layer["bias"] = vec_sub(layer.bias, vec_scalar_mul(delta, layer.learn_rate))
      g = matTvec(layer.weight, delta).clone
      layers[i] = layer
      i = i - 1.clone
    end
    return layers
  end
  def calc_loss(y, yhat)
    s = 0.0.clone
    i = 0.clone
    while i < y.length
      d = y[i] - yhat[i]
      s = _add(s, d * d).clone
      i = _add(i, 1).clone
    end
    return s
  end
  def calc_gradient(y, yhat)
    g = [].clone
    i = 0.clone
    while i < y.length
      g = (g << (2.0 * (yhat[i] - y[i]))).clone
      i = _add(i, 1).clone
    end
    return g
  end
  def train(layers, xdata, ydata, rounds, acc)
    r = 0.clone
    while r < rounds
      i = 0.clone
      while i < xdata.length
        layers = forward(layers, xdata[i]).clone
        out = layers[layers.length - 1].output
        grad = calc_gradient(ydata[i], out)
        layers = backward(layers, grad).clone
        i = _add(i, 1).clone
      end
      r = _add(r, 1).clone
    end
    return 0.0
  end
  def create_data()
    x = [].clone
    i = 0.clone
    while i < 10
      x = (x << (random_vector(10))).clone
      i = _add(i, 1).clone
    end
    y = [[0.8, 0.4], [0.4, 0.3], [0.34, 0.45], [0.67, 0.32], [0.88, 0.67], [0.78, 0.77], [0.55, 0.66], [0.55, 0.43], [0.54, 0.1], [0.1, 0.5]]
    return Data.new(x: x, y: y)
  end
  def main()
    data = create_data()
    x = data.x
    y = data.y
    layers = [].clone
    layers = (layers << (init_layer(10, 0, 0.3))).clone
    layers = (layers << (init_layer(20, 10, 0.3))).clone
    layers = (layers << (init_layer(30, 20, 0.3))).clone
    layers = (layers << (init_layer(2, 30, 0.3))).clone
    final_mse = train(layers, x, y, 100, 0.01)
    puts(final_mse)
  end
  $seed = 1.clone
  Layer = Struct.new(:units, :weight, :bias, :output, :xdata, :learn_rate, keyword_init: true)
  Data = Struct.new(:x, :y, keyword_init: true)
  main()
end_time = _now()
end_mem = _mem()
result = {"duration_us" => ((end_time - start) / 1000), "memory_bytes" => (end_mem - start_mem), "name" => "main"}
puts(JSON.pretty_generate(result))
