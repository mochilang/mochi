# Generated by Mochi transpiler v0.10.64 on 2025-08-12 09:13 +0700
$VERBOSE = nil
require 'json'

$now_seed = 0
$now_seeded = false
s = ENV['MOCHI_NOW_SEED']
if s && s != ''
  begin
    $now_seed = Integer(s)
    $now_seeded = true
  rescue StandardError
  end
end
if !$now_seeded && ENV['MOCHI_BENCHMARK']
  $now_seeded = true
end
def _now()
  if $now_seeded
    $now_seed = ($now_seed * 1_664_525 + 1_013_904_223) % 2_147_483_647
    $now_seed
  else
    Process.clock_gettime(Process::CLOCK_MONOTONIC, :nanosecond)
  end
end


require 'objspace'
def _mem()
  ObjectSpace.memsize_of_all
end


def _add(a, b)
  if a.is_a?(Array) && b.is_a?(String)
    a.join + b
  elsif a.is_a?(String) && b.is_a?(Array)
    a + b.join
  elsif a.is_a?(Array) && !b.is_a?(Array)
    a + [b]
  elsif !a.is_a?(Array) && b.is_a?(Array)
    [a] + b
  elsif a.is_a?(String) || b.is_a?(String)
    a.to_s + b.to_s
  else
    a + b
  end
end


def _eq(a, b)
  if a.is_a?(Float) || b.is_a?(Float)
    (a.to_f - b.to_f).abs < 1e-6
  else
    a == b
  end
end


def _padStart(s, len, ch)
  s.to_s.rjust(len, ch)
end


def _padEnd(s, len, ch)
  s.to_s.ljust(len, ch)
end


def _str(x)
  if x.is_a?(Array)
    x.map { |e| _str(e) }.join(' ')
  elsif x.is_a?(Float) && x == x.to_i
    x.to_i.to_s
  else
    x.to_s
  end
end


class String
  alias each each_char
end


def panic(msg)
  raise RuntimeError, msg
end

__name__ = '__main__'
start_mem = _mem()
start = _now()
  def rand()
    $seed = (_add($seed * 1103515245, 12345)) % 2147483648
    return $seed
  end
  def random()
    return (1.0 * rand()) / 2147483648.0
  end
  def expApprox(x)
    y = x
    is_neg = false
    if x < 0.0
      is_neg = true
      y = -x
    end
    term = 1.0
    sum = 1.0
    n = 1
    while n < 30
      term = term * y / ((n).to_f)
      sum = _add(sum, term)
      n = _add(n, 1)
    end
    if is_neg
      return 1.0 / sum
    end
    return sum
  end
  def sigmoid(z)
    return 1.0 / (_add(1.0, expApprox(-z)))
  end
  def sigmoid_vec(v)
    res = []
    i = 0
    while i < v.length
      res = (res + [sigmoid(v[i])])
      i = _add(i, 1)
    end
    return res
  end
  def sigmoid_derivative(out)
    res = []
    i = 0
    while i < out.length
      val = out[i]
      res = (res + [val * (1.0 - val)])
      i = _add(i, 1)
    end
    return res
  end
  def random_vector(n)
    v = []
    i = 0
    while i < n
      v = (v + [random() - 0.5])
      i = _add(i, 1)
    end
    return v
  end
  def random_matrix(r, c)
    m = []
    i = 0
    while i < r
      m = (m + [random_vector(c)])
      i = _add(i, 1)
    end
    return m
  end
  def matvec(mat, vec)
    res = []
    i = 0
    while i < mat.length
      s = 0.0
      j = 0
      while j < vec.length
        s = _add(s, mat[i][j] * vec[j])
        j = _add(j, 1)
      end
      res = (res + [s])
      i = _add(i, 1)
    end
    return res
  end
  def matTvec(mat, vec)
    cols = mat[0].length
    res = []
    j = 0
    while j < cols
      s = 0.0
      i = 0
      while i < mat.length
        s = _add(s, mat[i][j] * vec[i])
        i = _add(i, 1)
      end
      res = (res + [s])
      j = _add(j, 1)
    end
    return res
  end
  def vec_sub(a, b)
    res = []
    i = 0
    while i < a.length
      res = (res + [a[i] - b[i]])
      i = _add(i, 1)
    end
    return res
  end
  def vec_mul(a, b)
    res = []
    i = 0
    while i < a.length
      res = (res + [a[i] * b[i]])
      i = _add(i, 1)
    end
    return res
  end
  def vec_scalar_mul(v, s)
    res = []
    i = 0
    while i < v.length
      res = (res + [v[i] * s])
      i = _add(i, 1)
    end
    return res
  end
  def outer(a, b)
    res = []
    i = 0
    while i < a.length
      row = []
      j = 0
      while j < b.length
        row = (row + [a[i] * b[j]])
        j = _add(j, 1)
      end
      res = (res + [row])
      i = _add(i, 1)
    end
    return res
  end
  def mat_scalar_mul(mat, s)
    res = []
    i = 0
    while i < mat.length
      row = []
      j = 0
      while j < mat[i].length
        row = (row + [mat[i][j] * s])
        j = _add(j, 1)
      end
      res = (res + [row])
      i = _add(i, 1)
    end
    return res
  end
  def mat_sub(a, b)
    res = []
    i = 0
    while i < a.length
      row = []
      j = 0
      while j < a[i].length
        row = (row + [a[i][j] - b[i][j]])
        j = _add(j, 1)
      end
      res = (res + [row])
      i = _add(i, 1)
    end
    return res
  end
  def init_layer(units, back_units, lr)
    return Layer.new(units: units, weight: random_matrix(units, back_units), bias: random_vector(units), output: [], xdata: [], learn_rate: lr)
  end
  def forward(layers, x)
    data = x
    i = 0
    while i < layers.length
      layer = layers[i]
      layer["xdata"] = data
      if _eq(i, 0)
        layer["output"] = data
      else
        z = vec_sub(matvec(layer.weight, data), layer.bias)
        layer["output"] = sigmoid_vec(z)
        data = layer.output
      end
      layers[i] = layer
      i = _add(i, 1)
    end
    return layers
  end
  def backward(layers, grad)
    g = grad
    i = layers.length - 1
    while i > 0
      layer = layers[i]
      deriv = sigmoid_derivative(layer.output)
      delta = vec_mul(g, deriv)
      grad_w = outer(delta, layer.xdata)
      layer["weight"] = mat_sub(layer.weight, mat_scalar_mul(grad_w, layer.learn_rate))
      layer["bias"] = vec_sub(layer.bias, vec_scalar_mul(delta, layer.learn_rate))
      g = matTvec(layer.weight, delta)
      layers[i] = layer
      i = i - 1
    end
    return layers
  end
  def calc_loss(y, yhat)
    s = 0.0
    i = 0
    while i < y.length
      d = y[i] - yhat[i]
      s = _add(s, d * d)
      i = _add(i, 1)
    end
    return s
  end
  def calc_gradient(y, yhat)
    g = []
    i = 0
    while i < y.length
      g = (g + [2.0 * (yhat[i] - y[i])])
      i = _add(i, 1)
    end
    return g
  end
  def train(layers, xdata, ydata, rounds, acc)
    r = 0
    while r < rounds
      i = 0
      while i < xdata.length
        layers = forward(layers, xdata[i])
        out = layers[layers.length - 1].output
        grad = calc_gradient(ydata[i], out)
        layers = backward(layers, grad)
        i = _add(i, 1)
      end
      r = _add(r, 1)
    end
    return 0.0
  end
  def create_data()
    x = []
    i = 0
    while i < 10
      x = (x + [random_vector(10)])
      i = _add(i, 1)
    end
    y = [[0.8, 0.4], [0.4, 0.3], [0.34, 0.45], [0.67, 0.32], [0.88, 0.67], [0.78, 0.77], [0.55, 0.66], [0.55, 0.43], [0.54, 0.1], [0.1, 0.5]]
    return Data.new(x: x, y: y)
  end
  def main()
    data = create_data()
    x = data.x
    y = data.y
    layers = []
    layers = (layers + [init_layer(10, 0, 0.3)])
    layers = (layers + [init_layer(20, 10, 0.3)])
    layers = (layers + [init_layer(30, 20, 0.3)])
    layers = (layers + [init_layer(2, 30, 0.3)])
    final_mse = train(layers, x, y, 100, 0.01)
    puts(final_mse)
  end
  $seed = 1
  Object.send(:remove_const, :Layer) if Object.const_defined?(:Layer)
  Layer = Struct.new(:units, :weight, :bias, :output, :xdata, :learn_rate, keyword_init: true)
  Object.send(:remove_const, :Data) if Object.const_defined?(:Data)
  Data = Struct.new(:x, :y, keyword_init: true)
  main()
end_time = _now()
end_mem = _mem()
result = {"duration_us" => ((end_time - start) / 1000), "memory_bytes" => (end_mem - start_mem), "name" => "main"}
puts(JSON.pretty_generate(result))
