# Generated by Mochi transpiler v0.10.66 on 2025-08-16 09:25 +0700
$VERBOSE = nil
require 'json'

$now_seed = 0
$now_seeded = false
s = ENV['MOCHI_NOW_SEED']
if s && s != ''
  begin
    $now_seed = Integer(s)
    $now_seeded = true
  rescue StandardError
  end
end
if !$now_seeded && ENV['MOCHI_BENCHMARK']
  $now_seeded = true
end
def _now()
  if $now_seeded
    $now_seed = ($now_seed * 1_664_525 + 1_013_904_223) % 2_147_483_647
    $now_seed
  else
    Process.clock_gettime(Process::CLOCK_MONOTONIC, :nanosecond)
  end
end


require 'objspace'
def _mem()
  ObjectSpace.memsize_of_all
end


def _idx(arr, idx)
  return nil if arr.nil?
  if arr.is_a?(Array) && idx.is_a?(Numeric)
    return nil if idx < 0 || idx >= arr.length
  end
  arr[idx]
end


def _pow(a, b)
  res = (a.nil? ? 0 : a) ** (b.nil? ? 0 : b)
  res.is_a?(Float) && res == res.to_i ? res.to_i : res
end


def _len(x)
  x.respond_to?(:length) ? x.length : 0
end


def _has(obj, key)
  if obj.is_a?(Hash)
    obj.key?(key)
  elsif obj.respond_to?(:include?)
    obj.include?(key)
  elsif obj.respond_to?(:to_h)
    k = key.respond_to?(:to_sym) ? key.to_sym : key
    obj.to_h.key?(k)
  else
    false
  end
end


def _add(a, b)
  if a.is_a?(Array) && b.is_a?(String)
    a.join + b
  elsif a.is_a?(String) && b.is_a?(Array)
    a + b.join
  elsif a.is_a?(Array) && !b.is_a?(Array)
    a + [b]
  elsif !a.is_a?(Array) && b.is_a?(Array)
    [a] + b
  elsif a.is_a?(String) || b.is_a?(String)
    a.to_s + b.to_s
  else
    (a.nil? ? 0 : a) + (b.nil? ? 0 : b)
  end
end


def _append(arr, x)
  x = x.clone if x.is_a?(Array)
  (arr || []) + [x]
end


def _eq(a, b)
  if a.is_a?(Float) || b.is_a?(Float)
    diff = (a.to_f - b.to_f).abs
    scale = [a.to_f.abs, b.to_f.abs].max
    scale = 1.0 if scale == 0.0
    diff <= 1e-6 * scale
  else
    a == b
  end
end


def _padStart(s, len, ch)
  s.to_s.rjust(len, ch)
end


def _padEnd(s, len, ch)
  s.to_s.ljust(len, ch)
end


def _str(x)
  if x.is_a?(Array)
    x.map { |e| _str(e) }.join(' ')
  elsif x.is_a?(Float)
    s = x.to_s
    if s.include?('e') || s.include?('E')
      s
    elsif x == x.to_i
      x.to_i.to_s
    else
      s
    end
  else
    x.to_s
  end
end


class String
  alias each each_char
end


def panic(msg)
  raise RuntimeError, msg
end

__name__ = '__main__'
start_mem = _mem()
start = Process.clock_gettime(Process::CLOCK_MONOTONIC, :nanosecond)
  def random()
    $seed = (_add($seed * 13, 7)) % 100
    return (($seed).to_f) / 100.0
  end
  def sigmoid(x)
    return 1.0 / (_add(1.0, exp(-x)))
  end
  def to_float(x)
    return x * 1.0
  end
  def exp(x)
    return Math.exp(x)
  end
  def convolve(data, kernel, step, bias)
    size_data = _len(data)
    size_kernel = _len(kernel)
    out = []
    i = 0
    while i <= size_data - size_kernel
      row = []
      j = 0
      while j <= size_data - size_kernel
        sum = 0.0
        a = 0
        while a < size_kernel
          b = 0
          while b < size_kernel
            sum = _add(sum, (__tmp1 = (__tmp2 = data; __tmp2.is_a?(Hash) ? __tmp2[_add(i, a)] : _idx(__tmp2, _add(i, a))); __tmp1.is_a?(Hash) ? __tmp1[_add(j, b)] : _idx(__tmp1, _add(j, b))) * (__tmp3 = (__tmp4 = kernel; __tmp4.is_a?(Hash) ? __tmp4[a] : _idx(__tmp4, a)); __tmp3.is_a?(Hash) ? __tmp3[b] : _idx(__tmp3, b)))
            b = _add(b, 1)
          end
          a = _add(a, 1)
        end
        row = _append(row, sigmoid(sum - bias))
        j = _add(j, step)
      end
      out = _append(out, row)
      i = _add(i, step)
    end
    return out
  end
  def average_pool(map, size)
    out = []
    i = 0
    while i < _len(map)
      row = []
      j = 0
      while j < _len((__tmp5 = map; __tmp5.is_a?(Hash) ? __tmp5[i] : _idx(__tmp5, i)))
        sum = 0.0
        a = 0
        while a < size
          b = 0
          while b < size
            sum = _add(sum, (__tmp6 = (__tmp7 = map; __tmp7.is_a?(Hash) ? __tmp7[_add(i, a)] : _idx(__tmp7, _add(i, a))); __tmp6.is_a?(Hash) ? __tmp6[_add(j, b)] : _idx(__tmp6, _add(j, b))))
            b = _add(b, 1)
          end
          a = _add(a, 1)
        end
        row = _append(row, sum / (((size * size)).to_f))
        j = _add(j, size)
      end
      out = _append(out, row)
      i = _add(i, size)
    end
    return out
  end
  def flatten(maps)
    out = []
    i = 0
    while i < _len(maps)
      j = 0
      while j < _len((__tmp8 = maps; __tmp8.is_a?(Hash) ? __tmp8[i] : _idx(__tmp8, i)))
        k = 0
        while k < _len((__tmp9 = (__tmp10 = maps; __tmp10.is_a?(Hash) ? __tmp10[i] : _idx(__tmp10, i)); __tmp9.is_a?(Hash) ? __tmp9[j] : _idx(__tmp9, j)))
          out = _append(out, (__tmp11 = (__tmp12 = (__tmp13 = maps; __tmp13.is_a?(Hash) ? __tmp13[i] : _idx(__tmp13, i)); __tmp12.is_a?(Hash) ? __tmp12[j] : _idx(__tmp12, j)); __tmp11.is_a?(Hash) ? __tmp11[k] : _idx(__tmp11, k)))
          k = _add(k, 1)
        end
        j = _add(j, 1)
      end
      i = _add(i, 1)
    end
    return out
  end
  def vec_mul_mat(v, m)
    cols = _len((__tmp14 = m; __tmp14.is_a?(Hash) ? __tmp14[0] : _idx(__tmp14, 0)))
    res = []
    j = 0
    while j < cols
      sum = 0.0
      i = 0
      while i < _len(v)
        sum = _add(sum, (__tmp15 = v; __tmp15.is_a?(Hash) ? __tmp15[i] : _idx(__tmp15, i)) * (__tmp16 = (__tmp17 = m; __tmp17.is_a?(Hash) ? __tmp17[i] : _idx(__tmp17, i)); __tmp16.is_a?(Hash) ? __tmp16[j] : _idx(__tmp16, j)))
        i = _add(i, 1)
      end
      res = _append(res, sum)
      j = _add(j, 1)
    end
    return res
  end
  def matT_vec_mul(m, v)
    res = []
    i = 0
    while i < _len(m)
      sum = 0.0
      j = 0
      while j < _len((__tmp18 = m; __tmp18.is_a?(Hash) ? __tmp18[i] : _idx(__tmp18, i)))
        sum = _add(sum, (__tmp19 = (__tmp20 = m; __tmp20.is_a?(Hash) ? __tmp20[i] : _idx(__tmp20, i)); __tmp19.is_a?(Hash) ? __tmp19[j] : _idx(__tmp19, j)) * (__tmp21 = v; __tmp21.is_a?(Hash) ? __tmp21[j] : _idx(__tmp21, j)))
        j = _add(j, 1)
      end
      res = _append(res, sum)
      i = _add(i, 1)
    end
    return res
  end
  def vec_add(a, b)
    res = []
    i = 0
    while i < _len(a)
      res = _append(res, _add((__tmp22 = a; __tmp22.is_a?(Hash) ? __tmp22[i] : _idx(__tmp22, i)), (__tmp23 = b; __tmp23.is_a?(Hash) ? __tmp23[i] : _idx(__tmp23, i))))
      i = _add(i, 1)
    end
    return res
  end
  def vec_sub(a, b)
    res = []
    i = 0
    while i < _len(a)
      res = _append(res, (__tmp24 = a; __tmp24.is_a?(Hash) ? __tmp24[i] : _idx(__tmp24, i)) - (__tmp25 = b; __tmp25.is_a?(Hash) ? __tmp25[i] : _idx(__tmp25, i)))
      i = _add(i, 1)
    end
    return res
  end
  def vec_mul(a, b)
    res = []
    i = 0
    while i < _len(a)
      res = _append(res, (__tmp26 = a; __tmp26.is_a?(Hash) ? __tmp26[i] : _idx(__tmp26, i)) * (__tmp27 = b; __tmp27.is_a?(Hash) ? __tmp27[i] : _idx(__tmp27, i)))
      i = _add(i, 1)
    end
    return res
  end
  def vec_map_sig(v)
    res = []
    i = 0
    while i < _len(v)
      res = _append(res, sigmoid((__tmp28 = v; __tmp28.is_a?(Hash) ? __tmp28[i] : _idx(__tmp28, i))))
      i = _add(i, 1)
    end
    return res
  end
  def new_cnn()
    k1 = [[1.0, 0.0], [0.0, 1.0]]
    k2 = [[0.0, 1.0], [1.0, 0.0]]
    conv_kernels = [k1, k2]
    conv_bias = [0.0, 0.0]
    conv_step = 2
    pool_size = 2
    input_size = 2
    hidden_size = 2
    output_size = 2
    w_hidden = []
    i = 0
    while i < input_size
      row = []
      j = 0
      while j < hidden_size
        row = _append(row, random() - 0.5)
        j = _add(j, 1)
      end
      w_hidden = _append(w_hidden, row)
      i = _add(i, 1)
    end
    w_out = []
    i = 0
    while i < hidden_size
      row = []
      j = 0
      while j < output_size
        row = _append(row, random() - 0.5)
        j = _add(j, 1)
      end
      w_out = _append(w_out, row)
      i = _add(i, 1)
    end
    b_hidden = [0.0, 0.0]
    b_out = [0.0, 0.0]
    return CNN.new(conv_kernels: conv_kernels, conv_bias: conv_bias, conv_step: conv_step, pool_size: pool_size, w_hidden: w_hidden, w_out: w_out, b_hidden: b_hidden, b_out: b_out, rate_weight: 0.2, rate_bias: 0.2)
  end
  def forward(cnn, data)
    maps = []
    i = 0
    while i < _len(cnn.conv_kernels)
      conv_map = convolve(data, (__tmp29 = cnn.conv_kernels; __tmp29.is_a?(Hash) ? __tmp29[i] : _idx(__tmp29, i)), cnn.conv_step, (__tmp30 = cnn.conv_bias; __tmp30.is_a?(Hash) ? __tmp30[i] : _idx(__tmp30, i)))
      pooled = average_pool(conv_map, cnn.pool_size)
      maps = _append(maps, pooled)
      i = _add(i, 1)
    end
    flat = flatten(maps)
    hidden_net = vec_add(vec_mul_mat(flat, cnn.w_hidden), cnn.b_hidden)
    hidden_out = vec_map_sig(hidden_net)
    out_net = vec_add(vec_mul_mat(hidden_out, cnn.w_out), cnn.b_out)
    out = vec_map_sig(out_net)
    return out
  end
  def train(cnn, samples, epochs)
    w_out = cnn.w_out
    b_out = cnn.b_out
    w_hidden = cnn.w_hidden
    b_hidden = cnn.b_hidden
    e = 0
    while e < epochs
      s = 0
      while s < _len(samples)
        data = (__tmp31 = samples; __tmp31.is_a?(Hash) ? __tmp31[s] : _idx(__tmp31, s)).image
        target = (__tmp32 = samples; __tmp32.is_a?(Hash) ? __tmp32[s] : _idx(__tmp32, s)).target
        maps = []
        i = 0
        while i < _len(cnn.conv_kernels)
          conv_map = convolve(data, (__tmp33 = cnn.conv_kernels; __tmp33.is_a?(Hash) ? __tmp33[i] : _idx(__tmp33, i)), cnn.conv_step, (__tmp34 = cnn.conv_bias; __tmp34.is_a?(Hash) ? __tmp34[i] : _idx(__tmp34, i)))
          pooled = average_pool(conv_map, cnn.pool_size)
          maps = _append(maps, pooled)
          i = _add(i, 1)
        end
        flat = flatten(maps)
        hidden_net = vec_add(vec_mul_mat(flat, w_hidden), b_hidden)
        hidden_out = vec_map_sig(hidden_net)
        out_net = vec_add(vec_mul_mat(hidden_out, w_out), b_out)
        out = vec_map_sig(out_net)
        error_out = vec_sub(target, out)
        pd_out = vec_mul(error_out, vec_mul(out, vec_sub([1.0, 1.0], out)))
        error_hidden = matT_vec_mul(w_out, pd_out)
        pd_hidden = vec_mul(error_hidden, vec_mul(hidden_out, vec_sub([1.0, 1.0], hidden_out)))
        j = 0
        while j < _len(w_out)
          k = 0
          while k < _len((__tmp35 = w_out; __tmp35.is_a?(Hash) ? __tmp35[j] : _idx(__tmp35, j)))
            (__tmp36 = w_out; __tmp36.is_a?(Hash) ? __tmp36[j] : _idx(__tmp36, j))[k] = _add((__tmp37 = (__tmp38 = w_out; __tmp38.is_a?(Hash) ? __tmp38[j] : _idx(__tmp38, j)); __tmp37.is_a?(Hash) ? __tmp37[k] : _idx(__tmp37, k)), cnn.rate_weight * (__tmp39 = hidden_out; __tmp39.is_a?(Hash) ? __tmp39[j] : _idx(__tmp39, j)) * (__tmp40 = pd_out; __tmp40.is_a?(Hash) ? __tmp40[k] : _idx(__tmp40, k)))
            k = _add(k, 1)
          end
          j = _add(j, 1)
        end
        j = 0
        while j < _len(b_out)
          b_out[j] = (__tmp41 = b_out; __tmp41.is_a?(Hash) ? __tmp41[j] : _idx(__tmp41, j)) - cnn.rate_bias * (__tmp42 = pd_out; __tmp42.is_a?(Hash) ? __tmp42[j] : _idx(__tmp42, j))
          j = _add(j, 1)
        end
        i_h = 0
        while i_h < _len(w_hidden)
          j_h = 0
          while j_h < _len((__tmp43 = w_hidden; __tmp43.is_a?(Hash) ? __tmp43[i_h] : _idx(__tmp43, i_h)))
            (__tmp44 = w_hidden; __tmp44.is_a?(Hash) ? __tmp44[i_h] : _idx(__tmp44, i_h))[j_h] = _add((__tmp45 = (__tmp46 = w_hidden; __tmp46.is_a?(Hash) ? __tmp46[i_h] : _idx(__tmp46, i_h)); __tmp45.is_a?(Hash) ? __tmp45[j_h] : _idx(__tmp45, j_h)), cnn.rate_weight * (__tmp47 = flat; __tmp47.is_a?(Hash) ? __tmp47[i_h] : _idx(__tmp47, i_h)) * (__tmp48 = pd_hidden; __tmp48.is_a?(Hash) ? __tmp48[j_h] : _idx(__tmp48, j_h)))
            j_h = _add(j_h, 1)
          end
          i_h = _add(i_h, 1)
        end
        j = 0
        while j < _len(b_hidden)
          b_hidden[j] = (__tmp49 = b_hidden; __tmp49.is_a?(Hash) ? __tmp49[j] : _idx(__tmp49, j)) - cnn.rate_bias * (__tmp50 = pd_hidden; __tmp50.is_a?(Hash) ? __tmp50[j] : _idx(__tmp50, j))
          j = _add(j, 1)
        end
        s = _add(s, 1)
      end
      e = _add(e, 1)
    end
    return CNN.new(conv_kernels: cnn.conv_kernels, conv_bias: cnn.conv_bias, conv_step: cnn.conv_step, pool_size: cnn.pool_size, w_hidden: w_hidden, w_out: w_out, b_hidden: b_hidden, b_out: b_out, rate_weight: cnn.rate_weight, rate_bias: cnn.rate_bias)
  end
  def main()
    cnn = new_cnn()
    image = [[1.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 1.0], [1.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 1.0]]
    sample = TrainSample.new(image: image, target: [1.0, 0.0])
    puts(((["Before training:", ((x = forward(cnn, image)); x.is_a?(Array) ? ("[" + x.map{ |x| if x.is_a?(String) then '\'' + x + '\'' elsif x.is_a?(Hash) then '{' + x.to_h.map{ |k,v| "'#{k}': #{v.is_a?(String) ? '\'' + v + '\'' : v.to_s}" }.join(', ') + '}' else x.to_s end }.join(', ') + "]") : x.to_s)]).map{ |x| if x.nil? then 'None' elsif x == true then 'True' elsif x == false then 'False' elsif x.respond_to?(:to_h) then '{' + x.to_h.map{ |k,v| "'#{k}': #{v.is_a?(String) ? '\'' + v + '\'' : v.to_s}" }.join(', ') + '}' else x.to_s end }.join(' ')).rstrip())
    trained = train(cnn, [sample], 50)
    puts(((["After training:", ((x = forward(trained, image)); x.is_a?(Array) ? ("[" + x.map{ |x| if x.is_a?(String) then '\'' + x + '\'' elsif x.is_a?(Hash) then '{' + x.to_h.map{ |k,v| "'#{k}': #{v.is_a?(String) ? '\'' + v + '\'' : v.to_s}" }.join(', ') + '}' else x.to_s end }.join(', ') + "]") : x.to_s)]).map{ |x| if x.nil? then 'None' elsif x == true then 'True' elsif x == false then 'False' elsif x.respond_to?(:to_h) then '{' + x.to_h.map{ |k,v| "'#{k}': #{v.is_a?(String) ? '\'' + v + '\'' : v.to_s}" }.join(', ') + '}' else x.to_s end }.join(' ')).rstrip())
  end
  Object.send(:remove_const, :CNN) if Object.const_defined?(:CNN)
  Object.const_set(:CNN, Struct.new(:conv_kernels, :conv_bias, :conv_step, :pool_size, :w_hidden, :w_out, :b_hidden, :b_out, :rate_weight, :rate_bias, keyword_init: true))
  $seed = 1
  Object.send(:remove_const, :TrainSample) if Object.const_defined?(:TrainSample)
  Object.const_set(:TrainSample, Struct.new(:image, :target, keyword_init: true))
  main()
end_time = Process.clock_gettime(Process::CLOCK_MONOTONIC, :nanosecond)
end_mem = _mem()
result = {"duration_us" => ((end_time - start) / 1000), "memory_bytes" => (end_mem - start_mem), "name" => "main"}
puts(JSON.pretty_generate(result))
