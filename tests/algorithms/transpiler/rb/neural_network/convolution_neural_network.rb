# Generated by Mochi transpiler v0.10.64 on 2025-08-12 09:13 +0700
$VERBOSE = nil
require 'json'

$now_seed = 0
$now_seeded = false
s = ENV['MOCHI_NOW_SEED']
if s && s != ''
  begin
    $now_seed = Integer(s)
    $now_seeded = true
  rescue StandardError
  end
end
if !$now_seeded && ENV['MOCHI_BENCHMARK']
  $now_seeded = true
end
def _now()
  if $now_seeded
    $now_seed = ($now_seed * 1_664_525 + 1_013_904_223) % 2_147_483_647
    $now_seed
  else
    Process.clock_gettime(Process::CLOCK_MONOTONIC, :nanosecond)
  end
end


require 'objspace'
def _mem()
  ObjectSpace.memsize_of_all
end


def _add(a, b)
  if a.is_a?(Array) && b.is_a?(String)
    a.join + b
  elsif a.is_a?(String) && b.is_a?(Array)
    a + b.join
  elsif a.is_a?(Array) && !b.is_a?(Array)
    a + [b]
  elsif !a.is_a?(Array) && b.is_a?(Array)
    [a] + b
  elsif a.is_a?(String) || b.is_a?(String)
    a.to_s + b.to_s
  else
    a + b
  end
end


def _eq(a, b)
  if a.is_a?(Float) || b.is_a?(Float)
    (a.to_f - b.to_f).abs < 1e-6
  else
    a == b
  end
end


def _padStart(s, len, ch)
  s.to_s.rjust(len, ch)
end


def _padEnd(s, len, ch)
  s.to_s.ljust(len, ch)
end


def _str(x)
  if x.is_a?(Array)
    x.map { |e| _str(e) }.join(' ')
  elsif x.is_a?(Float) && x == x.to_i
    x.to_i.to_s
  else
    x.to_s
  end
end


class String
  alias each each_char
end


def panic(msg)
  raise RuntimeError, msg
end

__name__ = '__main__'
start_mem = _mem()
start = _now()
  def random()
    $seed = (_add($seed * 13, 7)) % 100
    return (($seed).to_f) / 100.0
  end
  def sigmoid(x)
    return 1.0 / (_add(1.0, exp(-x)))
  end
  def to_float(x)
    return x * 1.0
  end
  def exp(x)
    term = 1.0
    sum = 1.0
    n = 1
    while n < 20
      term = term * x / (n).to_f
      sum = _add(sum, term)
      n = _add(n, 1)
    end
    return sum
  end
  def convolve(data, kernel, step, bias)
    size_data = data.length
    size_kernel = kernel.length
    out = []
    i = 0
    while i <= size_data - size_kernel
      row = []
      j = 0
      while j <= size_data - size_kernel
        sum = 0.0
        a = 0
        while a < size_kernel
          b = 0
          while b < size_kernel
            sum = _add(sum, data[_add(i, a)][_add(j, b)] * kernel[a][b])
            b = _add(b, 1)
          end
          a = _add(a, 1)
        end
        row = (row + [sigmoid(sum - bias)])
        j = _add(j, step)
      end
      out = (out + [row])
      i = _add(i, step)
    end
    return out
  end
  def average_pool(map, size)
    out = []
    i = 0
    while i < map.length
      row = []
      j = 0
      while j < map[i].length
        sum = 0.0
        a = 0
        while a < size
          b = 0
          while b < size
            sum = _add(sum, map[_add(i, a)][_add(j, b)])
            b = _add(b, 1)
          end
          a = _add(a, 1)
        end
        row = (row + [sum / (((size * size)).to_f)])
        j = _add(j, size)
      end
      out = (out + [row])
      i = _add(i, size)
    end
    return out
  end
  def flatten(maps)
    out = []
    i = 0
    while i < maps.length
      j = 0
      while j < maps[i].length
        k = 0
        while k < maps[i][j].length
          out = (out + [maps[i][j][k]])
          k = _add(k, 1)
        end
        j = _add(j, 1)
      end
      i = _add(i, 1)
    end
    return out
  end
  def vec_mul_mat(v, m)
    cols = m[0].length
    res = []
    j = 0
    while j < cols
      sum = 0.0
      i = 0
      while i < v.length
        sum = _add(sum, v[i] * m[i][j])
        i = _add(i, 1)
      end
      res = (res + [sum])
      j = _add(j, 1)
    end
    return res
  end
  def matT_vec_mul(m, v)
    res = []
    i = 0
    while i < m.length
      sum = 0.0
      j = 0
      while j < m[i].length
        sum = _add(sum, m[i][j] * v[j])
        j = _add(j, 1)
      end
      res = (res + [sum])
      i = _add(i, 1)
    end
    return res
  end
  def vec_add(a, b)
    res = []
    i = 0
    while i < a.length
      res = (res + [_add(a[i], b[i])])
      i = _add(i, 1)
    end
    return res
  end
  def vec_sub(a, b)
    res = []
    i = 0
    while i < a.length
      res = (res + [a[i] - b[i]])
      i = _add(i, 1)
    end
    return res
  end
  def vec_mul(a, b)
    res = []
    i = 0
    while i < a.length
      res = (res + [a[i] * b[i]])
      i = _add(i, 1)
    end
    return res
  end
  def vec_map_sig(v)
    res = []
    i = 0
    while i < v.length
      res = (res + [sigmoid(v[i])])
      i = _add(i, 1)
    end
    return res
  end
  def new_cnn()
    k1 = [[1.0, 0.0], [0.0, 1.0]]
    k2 = [[0.0, 1.0], [1.0, 0.0]]
    conv_kernels = [k1, k2]
    conv_bias = [0.0, 0.0]
    conv_step = 2
    pool_size = 2
    input_size = 2
    hidden_size = 2
    output_size = 2
    w_hidden = []
    i = 0
    while i < input_size
      row = []
      j = 0
      while j < hidden_size
        row = (row + [random() - 0.5])
        j = _add(j, 1)
      end
      w_hidden = (w_hidden + [row])
      i = _add(i, 1)
    end
    w_out = []
    i = 0
    while i < hidden_size
      row = []
      j = 0
      while j < output_size
        row = (row + [random() - 0.5])
        j = _add(j, 1)
      end
      w_out = (w_out + [row])
      i = _add(i, 1)
    end
    b_hidden = [0.0, 0.0]
    b_out = [0.0, 0.0]
    return CNN.new(conv_kernels: conv_kernels, conv_bias: conv_bias, conv_step: conv_step, pool_size: pool_size, w_hidden: w_hidden, w_out: w_out, b_hidden: b_hidden, b_out: b_out, rate_weight: 0.2, rate_bias: 0.2)
  end
  def forward(cnn, data)
    maps = []
    i = 0
    while i < cnn.conv_kernels.length
      conv_map = convolve(data, cnn.conv_kernels[i], cnn.conv_step, cnn.conv_bias[i])
      pooled = average_pool(conv_map, cnn.pool_size)
      maps = (maps + [pooled])
      i = _add(i, 1)
    end
    flat = flatten(maps)
    hidden_net = vec_add(vec_mul_mat(flat, cnn.w_hidden), cnn.b_hidden)
    hidden_out = vec_map_sig(hidden_net)
    out_net = vec_add(vec_mul_mat(hidden_out, cnn.w_out), cnn.b_out)
    out = vec_map_sig(out_net)
    return out
  end
  def train(cnn, samples, epochs)
    w_out = cnn.w_out
    b_out = cnn.b_out
    w_hidden = cnn.w_hidden
    b_hidden = cnn.b_hidden
    e = 0
    while e < epochs
      s = 0
      while s < samples.length
        data = samples[s].image
        target = samples[s].target
        maps = []
        i = 0
        while i < cnn.conv_kernels.length
          conv_map = convolve(data, cnn.conv_kernels[i], cnn.conv_step, cnn.conv_bias[i])
          pooled = average_pool(conv_map, cnn.pool_size)
          maps = (maps + [pooled])
          i = _add(i, 1)
        end
        flat = flatten(maps)
        hidden_net = vec_add(vec_mul_mat(flat, w_hidden), b_hidden)
        hidden_out = vec_map_sig(hidden_net)
        out_net = vec_add(vec_mul_mat(hidden_out, w_out), b_out)
        out = vec_map_sig(out_net)
        error_out = vec_sub(target, out)
        pd_out = vec_mul(error_out, vec_mul(out, vec_sub([1.0, 1.0], out)))
        error_hidden = matT_vec_mul(w_out, pd_out)
        pd_hidden = vec_mul(error_hidden, vec_mul(hidden_out, vec_sub([1.0, 1.0], hidden_out)))
        j = 0
        while j < w_out.length
          k = 0
          while k < w_out[j].length
            w_out[j][k] = _add(w_out[j][k], cnn.rate_weight * hidden_out[j] * pd_out[k])
            k = _add(k, 1)
          end
          j = _add(j, 1)
        end
        j = 0
        while j < b_out.length
          b_out[j] = b_out[j] - cnn.rate_bias * pd_out[j]
          j = _add(j, 1)
        end
        i_h = 0
        while i_h < w_hidden.length
          j_h = 0
          while j_h < w_hidden[i_h].length
            w_hidden[i_h][j_h] = _add(w_hidden[i_h][j_h], cnn.rate_weight * flat[i_h] * pd_hidden[j_h])
            j_h = _add(j_h, 1)
          end
          i_h = _add(i_h, 1)
        end
        j = 0
        while j < b_hidden.length
          b_hidden[j] = b_hidden[j] - cnn.rate_bias * pd_hidden[j]
          j = _add(j, 1)
        end
        s = _add(s, 1)
      end
      e = _add(e, 1)
    end
    return CNN.new(conv_kernels: cnn.conv_kernels, conv_bias: cnn.conv_bias, conv_step: cnn.conv_step, pool_size: cnn.pool_size, w_hidden: w_hidden, w_out: w_out, b_hidden: b_hidden, b_out: b_out, rate_weight: cnn.rate_weight, rate_bias: cnn.rate_bias)
  end
  def main()
    cnn = new_cnn()
    image = [[1.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 1.0], [1.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 1.0]]
    sample = TrainSample.new(image: image, target: [1.0, 0.0])
    puts(((["Before training:", ((x = forward(cnn, image)); x.is_a?(Array) ? ("[" + x.map{ |x| if x.is_a?(String) then '\'' + x + '\'' elsif x.is_a?(Hash) then '{' + x.to_h.map{ |k,v| "'#{k}': #{v.is_a?(String) ? '\'' + v + '\'' : v.to_s}" }.join(', ') + '}' else x.to_s end }.join(', ') + "]") : x.to_s)]).map{ |x| if x.nil? then 'None' elsif x == true then 'True' elsif x == false then 'False' elsif x.respond_to?(:to_h) then '{' + x.to_h.map{ |k,v| "'#{k}': #{v.is_a?(String) ? '\'' + v + '\'' : v.to_s}" }.join(', ') + '}' else x end }.join(' ')).rstrip())
    trained = train(cnn, [sample], 50)
    puts(((["After training:", ((x = forward(trained, image)); x.is_a?(Array) ? ("[" + x.map{ |x| if x.is_a?(String) then '\'' + x + '\'' elsif x.is_a?(Hash) then '{' + x.to_h.map{ |k,v| "'#{k}': #{v.is_a?(String) ? '\'' + v + '\'' : v.to_s}" }.join(', ') + '}' else x.to_s end }.join(', ') + "]") : x.to_s)]).map{ |x| if x.nil? then 'None' elsif x == true then 'True' elsif x == false then 'False' elsif x.respond_to?(:to_h) then '{' + x.to_h.map{ |k,v| "'#{k}': #{v.is_a?(String) ? '\'' + v + '\'' : v.to_s}" }.join(', ') + '}' else x end }.join(' ')).rstrip())
  end
  Object.send(:remove_const, :CNN) if Object.const_defined?(:CNN)
  CNN = Struct.new(:conv_kernels, :conv_bias, :conv_step, :pool_size, :w_hidden, :w_out, :b_hidden, :b_out, :rate_weight, :rate_bias, keyword_init: true)
  $seed = 1
  Object.send(:remove_const, :TrainSample) if Object.const_defined?(:TrainSample)
  TrainSample = Struct.new(:image, :target, keyword_init: true)
  main()
end_time = _now()
end_mem = _mem()
result = {"duration_us" => ((end_time - start) / 1000), "memory_bytes" => (end_mem - start_mem), "name" => "main"}
puts(JSON.pretty_generate(result))
