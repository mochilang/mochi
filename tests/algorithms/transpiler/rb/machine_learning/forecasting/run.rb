# Generated by Mochi transpiler v0.10.59 on 2025-08-06 22:14 +0700
require 'json'

$now_seed = 0
$now_seeded = false
s = ENV['MOCHI_NOW_SEED']
if (!s || s == '') && ENV['MOCHI_BENCHMARK']
  s = '1'
end
if s && s != ''
  begin
    $now_seed = Integer(s)
    $now_seeded = true
  rescue StandardError
  end
end
def _now()
  if $now_seeded
    $now_seed += 1_000_000
    $now_seed
  else
    Process.clock_gettime(Process::CLOCK_MONOTONIC, :nanosecond)
  end
end


require 'objspace'
def _mem()
  ObjectSpace.memsize_of_all
end


def _add(a, b)
  if a.is_a?(Array) && b.is_a?(String)
    a.join + b
  elsif a.is_a?(String) && b.is_a?(Array)
    a + b.join
  else
    a + b
  end
end


def _padStart(s, len, ch)
  s.to_s.rjust(len, ch)
end


def _str(x)
  if x.is_a?(Float) && x == x.to_i
    x.to_i.to_s
  else
    x.to_s
  end
end


class String
  alias each each_char
end

start_mem = _mem()
start = _now()
  def int_to_float(x)
    return x * 1.0
  end
  def abs_float(x)
    if x < 0.0
      return 0.0 - x
    end
    return x
  end
  def exp_approx(x)
    term = 1.0.clone
    sum = 1.0.clone
    i = 1.clone
    while i < 10
      term = term * x / int_to_float(i).clone
      sum = _add(sum, term).clone
      i = _add(i, 1).clone
    end
    return sum
  end
  def floor_int(x)
    i = 0.clone
    while int_to_float(_add(i, 1)) <= x
      i = _add(i, 1).clone
    end
    return i
  end
  def dot(a, b)
    s = 0.0.clone
    i = 0.clone
    while i < a.length
      s = _add(s, a[i] * b[i]).clone
      i = _add(i, 1).clone
    end
    return s
  end
  def transpose(m)
    rows = m.length
    cols = m[0].length
    res = [].clone
    j = 0.clone
    while j < cols
      row = [].clone
      i = 0.clone
      while i < rows
        row = (row << (m[i][j])).clone
        i = _add(i, 1).clone
      end
      res = (res << (row)).clone
      j = _add(j, 1).clone
    end
    return res
  end
  def matmul(a, b)
    n = a.length
    m = b[0].length
    p = b.length
    res = [].clone
    i = 0.clone
    while i < n
      row = [].clone
      j = 0.clone
      while j < m
        s = 0.0.clone
        k = 0.clone
        while k < p
          s = _add(s, a[i][k] * b[k][j]).clone
          k = _add(k, 1).clone
        end
        row = (row << (s)).clone
        j = _add(j, 1).clone
      end
      res = (res << (row)).clone
      i = _add(i, 1).clone
    end
    return res
  end
  def matvec(a, b)
    res = [].clone
    i = 0.clone
    while i < a.length
      res = (res << (dot(a[i], b))).clone
      i = _add(i, 1).clone
    end
    return res
  end
  def identity(n)
    res = [].clone
    i = 0.clone
    while i < n
      row = [].clone
      j = 0.clone
      while j < n
        row = (row << ((i == j ? 1.0 : 0.0))).clone
        j = _add(j, 1).clone
      end
      res = (res << (row)).clone
      i = _add(i, 1).clone
    end
    return res
  end
  def invert(mat)
    n = mat.length
    a = mat.clone
    inv = identity(n).clone
    i = 0.clone
    while i < n
      pivot = a[i][i]
      j = 0.clone
      while j < n
        a[i][j] = a[i][j] / pivot
        inv[i][j] = inv[i][j] / pivot
        j = _add(j, 1).clone
      end
      k = 0.clone
      while k < n
        if k != i
          factor = a[k][i]
          j = 0.clone
          while j < n
            a[k][j] = a[k][j] - factor * a[i][j]
            inv[k][j] = inv[k][j] - factor * inv[i][j]
            j = _add(j, 1).clone
          end
        end
        k = _add(k, 1).clone
      end
      i = _add(i, 1).clone
    end
    return inv
  end
  def normal_equation(x, y)
    _Xt = transpose(x)
    _XtX = matmul(_Xt, x)
    _XtX_inv = invert(_XtX)
    _Xty = matvec(_Xt, y)
    return matvec(_XtX_inv, _Xty)
  end
  def linear_regression_prediction(train_dt, train_usr, train_mtch, test_dt, test_mtch)
    _X = [].clone
    i = 0.clone
    while i < train_dt.length
      _X = (_X << ([1.0, train_dt[i], train_mtch[i]])).clone
      i = _add(i, 1).clone
    end
    beta = normal_equation(_X, train_usr)
    return abs_float(_add(_add(beta[0], test_dt[0] * beta[1]), test_mtch[0] * beta[2]))
  end
  def sarimax_predictor(train_user, train_match, test_match)
    n = train_user.length
    _X = [].clone
    y = [].clone
    i = 1.clone
    while i < n
      _X = (_X << ([1.0, train_user[i - 1], train_match[i]])).clone
      y = (y << (train_user[i])).clone
      i = _add(i, 1).clone
    end
    beta = normal_equation(_X, y)
    return _add(_add(beta[0], beta[1] * train_user[n - 1]), beta[2] * test_match[0])
  end
  def rbf_kernel(a, b, gamma)
    sum = 0.0.clone
    i = 0.clone
    while i < a.length
      diff = a[i] - b[i]
      sum = _add(sum, diff * diff).clone
      i = _add(i, 1).clone
    end
    return exp_approx(-gamma * sum)
  end
  def support_vector_regressor(x_train, x_test, train_user)
    gamma = 0.1
    weights = [].clone
    i = 0.clone
    while i < x_train.length
      weights = (weights << (rbf_kernel(x_train[i], x_test[0], gamma))).clone
      i = _add(i, 1).clone
    end
    num = 0.0.clone
    den = 0.0.clone
    i = 0.clone
    while i < train_user.length
      num = _add(num, weights[i] * train_user[i]).clone
      den = _add(den, weights[i]).clone
      i = _add(i, 1).clone
    end
    return num / den
  end
  def set_at_float(xs, idx, value)
    i = 0.clone
    res = [].clone
    while i < xs.length
      if i == idx
        res = (res << (value)).clone
      else
        res = (res << (xs[i])).clone
      end
      i = _add(i, 1).clone
    end
    return res
  end
  def sort_float(xs)
    res = xs.clone
    i = 1.clone
    while i < res.length
      key = res[i]
      j = i - 1.clone
      while j >= 0 && res[j] > key
        res = set_at_float(res, _add(j, 1), res[j]).clone
        j = j - 1.clone
      end
      res = set_at_float(res, _add(j, 1), key).clone
      i = _add(i, 1).clone
    end
    return res
  end
  def percentile(data, q)
    sorted = sort_float(data).clone
    n = sorted.length
    pos = (q / 100.0) * int_to_float(n - 1)
    idx = floor_int(pos)
    frac = pos - int_to_float(idx)
    if _add(idx, 1) < n
      return _add(sorted[idx] * (1.0 - frac), sorted[_add(idx, 1)] * frac)
    end
    return sorted[idx]
  end
  def interquartile_range_checker(train_user)
    q1 = percentile(train_user, 25.0)
    q3 = percentile(train_user, 75.0)
    iqr = q3 - q1
    return q1 - iqr * 0.1
  end
  def data_safety_checker(list_vote, actual_result)
    safe = 0.clone
    not_safe = 0.clone
    i = 0.clone
    while i < list_vote.length
      v = list_vote[i]
      if v > actual_result
        safe = _add(not_safe, 1).clone
      else
        if abs_float(abs_float(v) - abs_float(actual_result)) <= 0.1
          safe = _add(safe, 1).clone
        else
          not_safe = _add(not_safe, 1).clone
        end
      end
      i = _add(i, 1).clone
    end
    return safe > not_safe
  end
  def main()
    vote = [linear_regression_prediction([2.0, 3.0, 4.0, 5.0], [5.0, 3.0, 4.0, 6.0], [3.0, 1.0, 2.0, 4.0], [2.0], [2.0]), sarimax_predictor([4.0, 2.0, 6.0, 8.0], [3.0, 1.0, 2.0, 4.0], [2.0]), support_vector_regressor([[5.0, 2.0], [1.0, 5.0], [6.0, 2.0]], [[3.0, 2.0]], [2.0, 1.0, 4.0])]
    puts(vote[0])
    puts(vote[1])
    puts(vote[2])
    puts((data_safety_checker(vote, 5.0) ? 'true' : 'false'))
  end
  main()
end_time = _now()
end_mem = _mem()
result = {"duration_us" => ((end_time - start) / 1000), "memory_bytes" => (end_mem - start_mem), "name" => "main"}
puts(JSON.pretty_generate(result))
