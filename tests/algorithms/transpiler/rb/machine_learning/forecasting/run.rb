# Generated by Mochi transpiler v0.10.63 on 2025-08-11 18:28 +0700
$VERBOSE = nil
require 'json'

$now_seed = 0
$now_seeded = false
s = ENV['MOCHI_NOW_SEED']
if s && s != ''
  begin
    $now_seed = Integer(s)
    $now_seeded = true
  rescue StandardError
  end
end
if !$now_seeded && ENV['MOCHI_BENCHMARK']
  $now_seeded = true
end
def _now()
  if $now_seeded
    $now_seed = ($now_seed * 1_664_525 + 1_013_904_223) % 2_147_483_647
    $now_seed
  else
    Process.clock_gettime(Process::CLOCK_MONOTONIC, :nanosecond)
  end
end


require 'objspace'
def _mem()
  ObjectSpace.memsize_of_all
end


def _add(a, b)
  if a.is_a?(Array) && b.is_a?(String)
    a.join + b
  elsif a.is_a?(String) && b.is_a?(Array)
    a + b.join
  elsif a.is_a?(Array) && !b.is_a?(Array)
    a + [b]
  elsif !a.is_a?(Array) && b.is_a?(Array)
    [a] + b
  elsif a.is_a?(String) || b.is_a?(String)
    a.to_s + b.to_s
  else
    a + b
  end
end


def _eq(a, b)
  if a.is_a?(Float) || b.is_a?(Float)
    (a.to_f - b.to_f).abs < 1e-6
  else
    a == b
  end
end


def _padStart(s, len, ch)
  s.to_s.rjust(len, ch)
end


def _padEnd(s, len, ch)
  s.to_s.ljust(len, ch)
end


def _str(x)
  if x.is_a?(Array)
    x.map { |e| _str(e) }.join(' ')
  elsif x.is_a?(Float) && x == x.to_i
    x.to_i.to_s
  else
    x.to_s
  end
end


class String
  alias each each_char
end


def panic(msg)
  raise RuntimeError, msg
end

__name__ = '__main__'
start_mem = _mem()
start = _now()
  def int_to_float(x)
    return x * 1.0
  end
  def abs_float(x)
    if x < 0.0
      return 0.0 - x
    end
    return x
  end
  def exp_approx(x)
    term = 1.0
    sum = 1.0
    i = 1
    while i < 10
      term = term * x / int_to_float(i)
      sum = _add(sum, term)
      i = _add(i, 1)
    end
    return sum
  end
  def floor_int(x)
    i = 0
    while int_to_float(_add(i, 1)) <= x
      i = _add(i, 1)
    end
    return i
  end
  def dot(a, b)
    s = 0.0
    i = 0
    while i < a.length
      s = _add(s, a[i] * b[i])
      i = _add(i, 1)
    end
    return s
  end
  def transpose(m)
    rows = m.length
    cols = m[0].length
    res = []
    j = 0
    while j < cols
      row = []
      i = 0
      while i < rows
        row = (row + [m[i][j]])
        i = _add(i, 1)
      end
      res = (res + [row])
      j = _add(j, 1)
    end
    return res
  end
  def matmul(a, b)
    n = a.length
    m = b[0].length
    p = b.length
    res = []
    i = 0
    while i < n
      row = []
      j = 0
      while j < m
        s = 0.0
        k = 0
        while k < p
          s = _add(s, a[i][k] * b[k][j])
          k = _add(k, 1)
        end
        row = (row + [s])
        j = _add(j, 1)
      end
      res = (res + [row])
      i = _add(i, 1)
    end
    return res
  end
  def matvec(a, b)
    res = []
    i = 0
    while i < a.length
      res = (res + [dot(a[i], b)])
      i = _add(i, 1)
    end
    return res
  end
  def identity(n)
    res = []
    i = 0
    while i < n
      row = []
      j = 0
      while j < n
        row = (row + [(_eq(i, j) ? 1.0 : 0.0)])
        j = _add(j, 1)
      end
      res = (res + [row])
      i = _add(i, 1)
    end
    return res
  end
  def invert(mat)
    n = mat.length
    a = mat
    inv = identity(n)
    i = 0
    while i < n
      pivot = a[i][i]
      j = 0
      while j < n
        a[i][j] = a[i][j] / pivot
        inv[i][j] = inv[i][j] / pivot
        j = _add(j, 1)
      end
      k = 0
      while k < n
        if !_eq(k, i)
          factor = a[k][i]
          j = 0
          while j < n
            a[k][j] = a[k][j] - factor * a[i][j]
            inv[k][j] = inv[k][j] - factor * inv[i][j]
            j = _add(j, 1)
          end
        end
        k = _add(k, 1)
      end
      i = _add(i, 1)
    end
    return inv
  end
  def normal_equation(x, y)
    _Xt = transpose(x)
    _XtX = matmul(_Xt, x)
    _XtX_inv = invert(_XtX)
    _Xty = matvec(_Xt, y)
    return matvec(_XtX_inv, _Xty)
  end
  def linear_regression_prediction(train_dt, train_usr, train_mtch, test_dt, test_mtch)
    _X = []
    i = 0
    while i < train_dt.length
      _X = (_X + [[1.0, train_dt[i], train_mtch[i]]])
      i = _add(i, 1)
    end
    beta = normal_equation(_X, train_usr)
    return abs_float(_add(_add(beta[0], test_dt[0] * beta[1]), test_mtch[0] * beta[2]))
  end
  def sarimax_predictor(train_user, train_match, test_match)
    n = train_user.length
    _X = []
    y = []
    i = 1
    while i < n
      _X = (_X + [[1.0, train_user[i - 1], train_match[i]]])
      y = (y + [train_user[i]])
      i = _add(i, 1)
    end
    beta = normal_equation(_X, y)
    return _add(_add(beta[0], beta[1] * train_user[n - 1]), beta[2] * test_match[0])
  end
  def rbf_kernel(a, b, gamma)
    sum = 0.0
    i = 0
    while i < a.length
      diff = a[i] - b[i]
      sum = _add(sum, diff * diff)
      i = _add(i, 1)
    end
    return exp_approx(-gamma * sum)
  end
  def support_vector_regressor(x_train, x_test, train_user)
    gamma = 0.1
    weights = []
    i = 0
    while i < x_train.length
      weights = (weights + [rbf_kernel(x_train[i], x_test[0], gamma)])
      i = _add(i, 1)
    end
    num = 0.0
    den = 0.0
    i = 0
    while i < train_user.length
      num = _add(num, weights[i] * train_user[i])
      den = _add(den, weights[i])
      i = _add(i, 1)
    end
    return num / den
  end
  def set_at_float(xs, idx, value)
    i = 0
    res = []
    while i < xs.length
      if _eq(i, idx)
        res = (res + [value])
      else
        res = (res + [xs[i]])
      end
      i = _add(i, 1)
    end
    return res
  end
  def sort_float(xs)
    res = xs
    i = 1
    while i < res.length
      key = res[i]
      j = i - 1
      while j >= 0 && res[j] > key
        res = set_at_float(res, _add(j, 1), res[j])
        j = j - 1
      end
      res = set_at_float(res, _add(j, 1), key)
      i = _add(i, 1)
    end
    return res
  end
  def percentile(data, q)
    sorted = sort_float(data)
    n = sorted.length
    pos = (q / 100.0) * int_to_float(n - 1)
    idx = floor_int(pos)
    frac = pos - int_to_float(idx)
    if _add(idx, 1) < n
      return _add(sorted[idx] * (1.0 - frac), sorted[_add(idx, 1)] * frac)
    end
    return sorted[idx]
  end
  def interquartile_range_checker(train_user)
    q1 = percentile(train_user, 25.0)
    q3 = percentile(train_user, 75.0)
    iqr = q3 - q1
    return q1 - iqr * 0.1
  end
  def data_safety_checker(list_vote, actual_result)
    safe = 0
    not_safe = 0
    i = 0
    while i < list_vote.length
      v = list_vote[i]
      if v > actual_result
        safe = _add(not_safe, 1)
      else
        if abs_float(abs_float(v) - abs_float(actual_result)) <= 0.1
          safe = _add(safe, 1)
        else
          not_safe = _add(not_safe, 1)
        end
      end
      i = _add(i, 1)
    end
    return safe > not_safe
  end
  def main()
    vote = [linear_regression_prediction([2.0, 3.0, 4.0, 5.0], [5.0, 3.0, 4.0, 6.0], [3.0, 1.0, 2.0, 4.0], [2.0], [2.0]), sarimax_predictor([4.0, 2.0, 6.0, 8.0], [3.0, 1.0, 2.0, 4.0], [2.0]), support_vector_regressor([[5.0, 2.0], [1.0, 5.0], [6.0, 2.0]], [[3.0, 2.0]], [2.0, 1.0, 4.0])]
    puts(vote[0])
    puts(vote[1])
    puts(vote[2])
    puts((data_safety_checker(vote, 5.0) ? 'true' : 'false'))
  end
  main()
end_time = _now()
end_mem = _mem()
result = {"duration_us" => ((end_time - start) / 1000), "memory_bytes" => (end_mem - start_mem), "name" => "main"}
puts(JSON.pretty_generate(result))
