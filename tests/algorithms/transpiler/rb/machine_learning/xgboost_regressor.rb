# Generated by Mochi transpiler v0.10.66 on 2025-08-16 14:44 +0700
$VERBOSE = nil
require 'json'

$now_seed = 0
$now_seeded = false
s = ENV['MOCHI_NOW_SEED']
if s && s != ''
  begin
    $now_seed = Integer(s)
    $now_seeded = true
  rescue StandardError
  end
end
if !$now_seeded && ENV['MOCHI_BENCHMARK']
  $now_seeded = true
end
def _now()
  if $now_seeded
    $now_seed = ($now_seed * 1_664_525 + 1_013_904_223) % 2_147_483_647
    $now_seed
  else
    Process.clock_gettime(Process::CLOCK_MONOTONIC, :nanosecond)
  end
end


require 'objspace'
def _mem()
  ObjectSpace.memsize_of_all
end


def _idx(arr, idx)
  return nil if arr.nil?
  if arr.is_a?(Array) && idx.is_a?(Numeric)
    return nil if idx < 0 || idx >= arr.length
  end
  arr[idx]
end


def _pow(a, b)
  res = (a.nil? ? 0 : a) ** (b.nil? ? 0 : b)
  res.is_a?(Float) && res == res.to_i ? res.to_i : res
end


def _len(x)
  x.respond_to?(:length) ? x.length : 0
end


def _has(obj, key)
  if obj.is_a?(Hash)
    obj.key?(key)
  elsif obj.respond_to?(:include?)
    obj.include?(key)
  elsif obj.respond_to?(:to_h)
    k = key.respond_to?(:to_sym) ? key.to_sym : key
    obj.to_h.key?(k)
  else
    false
  end
end


def _add(a, b)
  if a.is_a?(Array) && b.is_a?(String)
    a.join + b
  elsif a.is_a?(String) && b.is_a?(Array)
    a + b.join
  elsif a.is_a?(Array) && !b.is_a?(Array)
    a + [b]
  elsif !a.is_a?(Array) && b.is_a?(Array)
    [a] + b
  elsif a.is_a?(String) || b.is_a?(String)
    a.to_s + b.to_s
  else
    (a.nil? ? 0 : a) + (b.nil? ? 0 : b)
  end
end


def _append(arr, x)
  x = x.clone if x.is_a?(Array)
  (arr || []) + [x]
end


def _eq(a, b)
  if a.is_a?(Float) || b.is_a?(Float)
    diff = (a.to_f - b.to_f).abs
    scale = [a.to_f.abs, b.to_f.abs].max
    scale = 1.0 if scale == 0.0
    diff <= 1e-6 * scale
  else
    a == b
  end
end


def _padStart(s, len, ch)
  s.to_s.rjust(len, ch)
end


def _padEnd(s, len, ch)
  s.to_s.ljust(len, ch)
end


def _str(x)
  if x.is_a?(Array)
    x.map { |e| _str(e) }.join(' ')
  elsif x.is_a?(Float)
    s = x.to_s
    if s.include?('e') || s.include?('E')
      s
    elsif x == x.to_i
      x.to_i.to_s
    else
      s
    end
  else
    x.to_s
  end
end


class String
  alias each each_char
end


def panic(msg)
  raise RuntimeError, msg
end

__name__ = '__main__'
start_mem = _mem()
start = Process.clock_gettime(Process::CLOCK_MONOTONIC, :nanosecond)
  def data_handling(dataset)
    return dataset
  end
  def xgboost(features, target, test_features)
    learning_rate = 0.5
    n_estimators = 3
    trees = []
    predictions = []
    i = 0
    while i < _len(target)
      predictions = _append(predictions, 0.0)
      i = _add(i, 1)
    end
    est = 0
    while est < n_estimators
      residuals = []
      j = 0
      while j < _len(target)
        residuals = _append(residuals, (__tmp1 = target; __tmp1.is_a?(Hash) ? __tmp1[j] : _idx(__tmp1, j)) - (__tmp2 = predictions; __tmp2.is_a?(Hash) ? __tmp2[j] : _idx(__tmp2, j)))
        j = _add(j, 1)
      end
      sum_feat = 0.0
      j = 0
      while j < _len(features)
        sum_feat = _add(sum_feat, (__tmp3 = (__tmp4 = features; __tmp4.is_a?(Hash) ? __tmp4[j] : _idx(__tmp4, j)); __tmp3.is_a?(Hash) ? __tmp3[0] : _idx(__tmp3, 0)))
        j = _add(j, 1)
      end
      threshold = sum_feat / ((_len(features)).to_f)
      left_sum = 0.0
      left_count = 0
      right_sum = 0.0
      right_count = 0
      j = 0
      while j < _len(features)
        if (__tmp5 = (__tmp6 = features; __tmp6.is_a?(Hash) ? __tmp6[j] : _idx(__tmp6, j)); __tmp5.is_a?(Hash) ? __tmp5[0] : _idx(__tmp5, 0)) <= threshold
          left_sum = _add(left_sum, (__tmp7 = residuals; __tmp7.is_a?(Hash) ? __tmp7[j] : _idx(__tmp7, j)))
          left_count = _add(left_count, 1)
        else
          right_sum = _add(right_sum, (__tmp8 = residuals; __tmp8.is_a?(Hash) ? __tmp8[j] : _idx(__tmp8, j)))
          right_count = _add(right_count, 1)
        end
        j = _add(j, 1)
      end
      left_value = 0.0
      if left_count > 0
        left_value = left_sum / ((left_count).to_f)
      end
      right_value = 0.0
      if right_count > 0
        right_value = right_sum / ((right_count).to_f)
      end
      j = 0
      while j < _len(features)
        if (__tmp9 = (__tmp10 = features; __tmp10.is_a?(Hash) ? __tmp10[j] : _idx(__tmp10, j)); __tmp9.is_a?(Hash) ? __tmp9[0] : _idx(__tmp9, 0)) <= threshold
          predictions[j] = _add((__tmp11 = predictions; __tmp11.is_a?(Hash) ? __tmp11[j] : _idx(__tmp11, j)), learning_rate * left_value)
        else
          predictions[j] = _add((__tmp12 = predictions; __tmp12.is_a?(Hash) ? __tmp12[j] : _idx(__tmp12, j)), learning_rate * right_value)
        end
        j = _add(j, 1)
      end
      trees = _append(trees, Tree.new(threshold: threshold, left_value: left_value, right_value: right_value))
      est = _add(est, 1)
    end
    preds = []
    t = 0
    while t < _len(test_features)
      pred = 0.0
      k = 0
      while k < _len(trees)
        if (__tmp13 = (__tmp14 = test_features; __tmp14.is_a?(Hash) ? __tmp14[t] : _idx(__tmp14, t)); __tmp13.is_a?(Hash) ? __tmp13[0] : _idx(__tmp13, 0)) <= (__tmp15 = (__tmp16 = trees; __tmp16.is_a?(Hash) ? __tmp16[k] : _idx(__tmp16, k)); __tmp15.is_a?(Hash) ? __tmp15["threshold"] : _idx(__tmp15, "threshold"))
          pred = _add(pred, learning_rate * (__tmp17 = (__tmp18 = trees; __tmp18.is_a?(Hash) ? __tmp18[k] : _idx(__tmp18, k)); __tmp17.is_a?(Hash) ? __tmp17["left_value"] : _idx(__tmp17, "left_value")))
        else
          pred = _add(pred, learning_rate * (__tmp19 = (__tmp20 = trees; __tmp20.is_a?(Hash) ? __tmp20[k] : _idx(__tmp20, k)); __tmp19.is_a?(Hash) ? __tmp19["right_value"] : _idx(__tmp19, "right_value")))
        end
        k = _add(k, 1)
      end
      preds = _append(preds, pred)
      t = _add(t, 1)
    end
    return preds
  end
  def mean_absolute_error(y_true, y_pred)
    sum = 0.0
    i = 0
    while i < _len(y_true)
      diff = (__tmp21 = y_true; __tmp21.is_a?(Hash) ? __tmp21[i] : _idx(__tmp21, i)) - (__tmp22 = y_pred; __tmp22.is_a?(Hash) ? __tmp22[i] : _idx(__tmp22, i))
      if diff < 0.0
        diff = -diff
      end
      sum = _add(sum, diff)
      i = _add(i, 1)
    end
    return sum / ((_len(y_true)).to_f)
  end
  def mean_squared_error(y_true, y_pred)
    sum = 0.0
    i = 0
    while i < _len(y_true)
      diff = (__tmp23 = y_true; __tmp23.is_a?(Hash) ? __tmp23[i] : _idx(__tmp23, i)) - (__tmp24 = y_pred; __tmp24.is_a?(Hash) ? __tmp24[i] : _idx(__tmp24, i))
      sum = _add(sum, diff * diff)
      i = _add(i, 1)
    end
    return sum / ((_len(y_true)).to_f)
  end
  def main()
    california = Dataset.new(data: [[1.0], [2.0], [3.0], [4.0]], target: [2.0, 3.0, 4.0, 5.0])
    ds = data_handling(california)
    x_train = ds.data
    y_train = ds.target
    x_test = [[1.5], [3.5]]
    y_test = [2.5, 4.5]
    predictions = xgboost(x_train, y_train, x_test)
    puts("Predictions:")
    puts(((x = predictions); x.is_a?(Array) ? ("[" + x.map{ |x| if x.is_a?(String) then '\'' + x + '\'' elsif x.is_a?(Hash) then '{' + x.to_h.map{ |k,v| "'#{k}': #{v.is_a?(String) ? '\'' + v + '\'' : v.to_s}" }.join(', ') + '}' else x.to_s end }.join(', ') + "]") : x.to_s))
    puts("Mean Absolute Error:")
    puts(mean_absolute_error(y_test, predictions))
    puts("Mean Square Error:")
    puts(mean_squared_error(y_test, predictions))
  end
  Object.send(:remove_const, :Dataset) if Object.const_defined?(:Dataset)
  Object.const_set(:Dataset, Struct.new(:data, :target, keyword_init: true))
  Object.send(:remove_const, :Tree) if Object.const_defined?(:Tree)
  Object.const_set(:Tree, Struct.new(:threshold, :left_value, :right_value, keyword_init: true))
  main()
end_time = Process.clock_gettime(Process::CLOCK_MONOTONIC, :nanosecond)
end_mem = _mem()
result = {"duration_us" => ((end_time - start) / 1000), "memory_bytes" => (end_mem - start_mem), "name" => "main"}
puts(JSON.pretty_generate(result))
