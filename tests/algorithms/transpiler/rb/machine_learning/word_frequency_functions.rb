# Generated by Mochi transpiler v0.10.63 on 2025-08-11 18:28 +0700
$VERBOSE = nil
require 'json'

$now_seed = 0
$now_seeded = false
s = ENV['MOCHI_NOW_SEED']
if s && s != ''
  begin
    $now_seed = Integer(s)
    $now_seeded = true
  rescue StandardError
  end
end
if !$now_seeded && ENV['MOCHI_BENCHMARK']
  $now_seeded = true
end
def _now()
  if $now_seeded
    $now_seed = ($now_seed * 1_664_525 + 1_013_904_223) % 2_147_483_647
    $now_seed
  else
    Process.clock_gettime(Process::CLOCK_MONOTONIC, :nanosecond)
  end
end


require 'objspace'
def _mem()
  ObjectSpace.memsize_of_all
end


def _add(a, b)
  if a.is_a?(Array) && b.is_a?(String)
    a.join + b
  elsif a.is_a?(String) && b.is_a?(Array)
    a + b.join
  elsif a.is_a?(Array) && !b.is_a?(Array)
    a + [b]
  elsif !a.is_a?(Array) && b.is_a?(Array)
    [a] + b
  elsif a.is_a?(String) || b.is_a?(String)
    a.to_s + b.to_s
  else
    a + b
  end
end


def _eq(a, b)
  if a.is_a?(Float) || b.is_a?(Float)
    (a.to_f - b.to_f).abs < 1e-6
  else
    a == b
  end
end


def _padStart(s, len, ch)
  s.to_s.rjust(len, ch)
end


def _padEnd(s, len, ch)
  s.to_s.ljust(len, ch)
end


def _str(x)
  if x.is_a?(Array)
    x.map { |e| _str(e) }.join(' ')
  elsif x.is_a?(Float) && x == x.to_i
    x.to_i.to_s
  else
    x.to_s
  end
end


class String
  alias each each_char
end


def panic(msg)
  raise RuntimeError, msg
end

__name__ = '__main__'
start_mem = _mem()
start = _now()
  def to_lowercase(s)
    res = ""
    i = 0
    while i < s.length
      c = s[i]
      j = 0
      found = false
      while j < $UPPER.length
        if _eq(c, $UPPER[j])
          res = _add(res, $LOWER[j])
          found = true
          break
        end
        j = _add(j, 1)
      end
      if !found
        res = _add(res, c)
      end
      i = _add(i, 1)
    end
    return res
  end
  def is_punct(c)
    i = 0
    while i < $PUNCT.length
      if _eq(c, $PUNCT[i])
        return true
      end
      i = _add(i, 1)
    end
    return false
  end
  def clean_text(text, keep_newlines)
    lower = to_lowercase(text)
    res = ""
    i = 0
    while i < lower.length
      ch = lower[i]
      if is_punct(ch)
      else
        if _eq(ch, "\n")
          if keep_newlines
            res = _add(res, "\n")
          end
        else
          res = _add(res, ch)
        end
      end
      i = _add(i, 1)
    end
    return res
  end
  def split(s, sep)
    res = []
    current = ""
    i = 0
    while i < s.length
      ch = s[i]
      if _eq(ch, sep)
        res = (res + [current])
        current = ""
      else
        current = _add(current, ch)
      end
      i = _add(i, 1)
    end
    res = (res + [current])
    return res
  end
  def contains(s, sub)
    n = s.length
    m = sub.length
    if _eq(m, 0)
      return true
    end
    i = 0
    while i <= n - m
      j = 0
      is_match = true
      while j < m
        if !_eq(s[_add(i, j)], sub[j])
          is_match = false
          break
        end
        j = _add(j, 1)
      end
      if is_match
        return true
      end
      i = _add(i, 1)
    end
    return false
  end
  def floor(x)
    i = (x).to_i
    if ((i).to_f) > x
      i = i - 1
    end
    return (i).to_f
  end
  def round3(x)
    return (_add(x * 1000.0, 0.5)).floor() / 1000.0
  end
  def ln(x)
    t = (x - 1.0) / (_add(x, 1.0))
    term = t
    sum = 0.0
    k = 1
    while k <= 99
      sum = _add(sum, term / ((k).to_f))
      term = term * t * t
      k = _add(k, 2)
    end
    return 2.0 * sum
  end
  def log10(x)
    return ln(x) / ln(10.0)
  end
  def term_frequency(term, document)
    clean = clean_text(document, false)
    tokens = split(clean, " ")
    t = to_lowercase(term)
    count = 0
    i = 0
    while i < tokens.length
      if !_eq(tokens[i], "") && _eq(tokens[i], t)
        count = _add(count, 1)
      end
      i = _add(i, 1)
    end
    return count
  end
  def document_frequency(term, corpus)
    clean = clean_text(corpus, true)
    docs = split(clean, "\n")
    t = to_lowercase(term)
    matches = 0
    i = 0
    while i < docs.length
      if contains(docs[i], t)
        matches = _add(matches, 1)
      end
      i = _add(i, 1)
    end
    return [matches, docs.length]
  end
  def inverse_document_frequency(df, n, smoothing)
    if smoothing
      if _eq(n, 0)
        panic("log10(0) is undefined.")
      end
      ratio = ((n).to_f) / (_add(1.0, ((df).to_f)))
      l = log10(ratio)
      result = round3(_add(1.0, l))
      puts(result)
      return result
    end
    if _eq(df, 0)
      panic("df must be > 0")
    end
    if _eq(n, 0)
      panic("log10(0) is undefined.")
    end
    ratio = ((n).to_f) / ((df).to_f)
    l = log10(ratio)
    result = round3(l)
    puts(result)
    return result
  end
  def tf_idf(tf, idf)
    prod = ((tf).to_f) * idf
    result = round3(prod)
    puts(result)
    return result
  end
  $LOWER = "abcdefghijklmnopqrstuvwxyz"
  $UPPER = "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
  $PUNCT = "!\"#$%&'()*+,-./:;<=>?@[\\]^_{|}~"
  puts(term_frequency("to", "To be, or not to be"))
  $corpus = "This is the first document in the corpus.\nThIs is the second document in the corpus.\nTHIS is the third document in the corpus."
  puts(((x = document_frequency("first", $corpus)); x.is_a?(Array) ? ("[" + x.map{ |x| if x.is_a?(Hash) then '{' + x.to_h.map{ |k,v| "#{k}: #{v.is_a?(String) ? v : v.to_s}" }.join(', ') + '}' else x.to_s end }.join(' ') + "]") : x.to_s))
  $idf_val = inverse_document_frequency(1, 3, false)
  tf_idf(2, $idf_val)
end_time = _now()
end_mem = _mem()
result = {"duration_us" => ((end_time - start) / 1000), "memory_bytes" => (end_mem - start_mem), "name" => "main"}
puts(JSON.pretty_generate(result))
