# Generated by Mochi transpiler v0.10.67 on 2025-08-16 19:42 +0700
$VERBOSE = nil
require 'json'

$now_seed = 0
$now_seeded = false
s = ENV['MOCHI_NOW_SEED']
if s && s != ''
  begin
    $now_seed = Integer(s)
    $now_seeded = true
  rescue StandardError
  end
end
if !$now_seeded && ENV['MOCHI_BENCHMARK']
  $now_seeded = true
end
def _now()
  if $now_seeded
    $now_seed = ($now_seed * 1_664_525 + 1_013_904_223) % 2_147_483_647
    $now_seed
  else
    Process.clock_gettime(Process::CLOCK_MONOTONIC, :nanosecond)
  end
end


require 'objspace'
def _mem()
  ObjectSpace.memsize_of_all
end


def _idx(arr, idx)
  return nil if arr.nil?
  if arr.is_a?(Array) && idx.is_a?(Numeric)
    return nil if idx < 0 || idx >= arr.length
  end
  arr[idx]
end


def _pow(a, b)
  res = (a.nil? ? 0 : a) ** (b.nil? ? 0 : b)
  res.is_a?(Float) && res == res.to_i ? res.to_i : res
end


def _len(x)
  x.respond_to?(:length) ? x.length : 0
end


def _has(obj, key)
  if obj.is_a?(Hash)
    obj.key?(key)
  elsif obj.respond_to?(:include?)
    obj.include?(key)
  elsif obj.respond_to?(:to_h)
    k = key.respond_to?(:to_sym) ? key.to_sym : key
    obj.to_h.key?(k)
  else
    false
  end
end


def _add(a, b)
  if a.is_a?(Array) && b.is_a?(String)
    a.join + b
  elsif a.is_a?(String) && b.is_a?(Array)
    a + b.join
  elsif a.is_a?(Array) && !b.is_a?(Array)
    a + [b]
  elsif !a.is_a?(Array) && b.is_a?(Array)
    [a] + b
  elsif a.is_a?(String) || b.is_a?(String)
    a.to_s + b.to_s
  else
    (a.nil? ? 0 : a) + (b.nil? ? 0 : b)
  end
end


def _append(arr, x)
  x = x.clone if x.is_a?(Array)
  (arr || []) + [x]
end


def _eq(a, b)
  if a.is_a?(Float) || b.is_a?(Float)
    diff = (a.to_f - b.to_f).abs
    scale = [a.to_f.abs, b.to_f.abs].max
    scale = 1.0 if scale == 0.0
    diff <= 1e-6 * scale
  else
    a == b
  end
end


def _padStart(s, len, ch)
  s.to_s.rjust(len, ch)
end


def _padEnd(s, len, ch)
  s.to_s.ljust(len, ch)
end


def _str(x)
  if x.is_a?(Array)
    x.map { |e| _str(e) }.join(' ')
  elsif x.is_a?(Float)
    s = x.to_s
    if s.include?('e') || s.include?('E')
      s
    elsif x == x.to_i
      x.to_i.to_s
    else
      s
    end
  else
    x.to_s
  end
end


class String
  alias each each_char
end


def panic(msg)
  raise RuntimeError, msg
end

__name__ = '__main__'
start_mem = _mem()
start = Process.clock_gettime(Process::CLOCK_MONOTONIC, :nanosecond)
  def to_lowercase(s)
    res = ""
    i = 0
    while i < _len(s)
      c = (__tmp1 = s; __tmp1.is_a?(Hash) ? __tmp1[i] : _idx(__tmp1, i))
      j = 0
      found = false
      while j < _len($UPPER)
        if _eq(c, (__tmp2 = $UPPER; __tmp2.is_a?(Hash) ? __tmp2[j] : _idx(__tmp2, j)))
          res = _add(res, (__tmp3 = $LOWER; __tmp3.is_a?(Hash) ? __tmp3[j] : _idx(__tmp3, j)))
          found = true
          break
        end
        j = _add(j, 1)
      end
      if !found
        res = _add(res, c)
      end
      i = _add(i, 1)
    end
    return res
  end
  def is_punct(c)
    i = 0
    while i < _len($PUNCT)
      if _eq(c, (__tmp4 = $PUNCT; __tmp4.is_a?(Hash) ? __tmp4[i] : _idx(__tmp4, i)))
        return true
      end
      i = _add(i, 1)
    end
    return false
  end
  def clean_text(text, keep_newlines)
    lower = to_lowercase(text)
    res = ""
    i = 0
    while i < _len(lower)
      ch = (__tmp5 = lower; __tmp5.is_a?(Hash) ? __tmp5[i] : _idx(__tmp5, i))
      if is_punct(ch)
      else
        if _eq(ch, "\n")
          if keep_newlines
            res = _add(res, "\n")
          end
        else
          res = _add(res, ch)
        end
      end
      i = _add(i, 1)
    end
    return res
  end
  def split(s, sep)
    res = []
    current = ""
    i = 0
    while i < _len(s)
      ch = (__tmp6 = s; __tmp6.is_a?(Hash) ? __tmp6[i] : _idx(__tmp6, i))
      if _eq(ch, sep)
        res = _append(res, current)
        current = ""
      else
        current = _add(current, ch)
      end
      i = _add(i, 1)
    end
    res = _append(res, current)
    return res
  end
  def contains(s, sub)
    n = _len(s)
    m = _len(sub)
    if _eq(m, 0)
      return true
    end
    i = 0
    while i <= n - m
      j = 0
      is_match = true
      while j < m
        if !_eq((__tmp7 = s; __tmp7.is_a?(Hash) ? __tmp7[_add(i, j)] : _idx(__tmp7, _add(i, j))), (__tmp8 = sub; __tmp8.is_a?(Hash) ? __tmp8[j] : _idx(__tmp8, j)))
          is_match = false
          break
        end
        j = _add(j, 1)
      end
      if is_match
        return true
      end
      i = _add(i, 1)
    end
    return false
  end
  def floor(x)
    i = (x).to_i
    if ((i).to_f) > x
      i = i - 1
    end
    return (i).to_f
  end
  def round3(x)
    return (_add(x * 1000.0, 0.5)).floor() / 1000.0
  end
  def ln(x)
    return Math.log(x)
  end
  def log10(x)
    return ln(x) / ln(10.0)
  end
  def term_frequency(term, document)
    clean = clean_text(document, false)
    tokens = split(clean, " ")
    t = to_lowercase(term)
    count = 0
    i = 0
    while i < _len(tokens)
      if !_eq((__tmp9 = tokens; __tmp9.is_a?(Hash) ? __tmp9[i] : _idx(__tmp9, i)), "") && _eq((__tmp10 = tokens; __tmp10.is_a?(Hash) ? __tmp10[i] : _idx(__tmp10, i)), t)
        count = _add(count, 1)
      end
      i = _add(i, 1)
    end
    return count
  end
  def document_frequency(term, corpus)
    clean = clean_text(corpus, true)
    docs = split(clean, "\n")
    t = to_lowercase(term)
    matches = 0
    i = 0
    while i < _len(docs)
      if contains((__tmp11 = docs; __tmp11.is_a?(Hash) ? __tmp11[i] : _idx(__tmp11, i)), t)
        matches = _add(matches, 1)
      end
      i = _add(i, 1)
    end
    return [matches, _len(docs)]
  end
  def inverse_document_frequency(df, n, smoothing)
    if smoothing
      if _eq(n, 0)
        panic("log10(0) is undefined.")
      end
      ratio = ((n).to_f) / (_add(1.0, ((df).to_f)))
      l = log10(ratio)
      result = round3(_add(1.0, l))
      puts(result)
      return result
    end
    if _eq(df, 0)
      panic("df must be > 0")
    end
    if _eq(n, 0)
      panic("log10(0) is undefined.")
    end
    ratio = ((n).to_f) / ((df).to_f)
    l = log10(ratio)
    result = round3(l)
    puts(result)
    return result
  end
  def tf_idf(tf, idf)
    prod = ((tf).to_f) * idf
    result = round3(prod)
    puts(result)
    return result
  end
  $LOWER = "abcdefghijklmnopqrstuvwxyz"
  $UPPER = "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
  $PUNCT = "!\"#$%&'()*+,-./:;<=>?@[\\]^_{|}~"
  puts(term_frequency("to", "To be, or not to be"))
  $corpus = "This is the first document in the corpus.\nThIs is the second document in the corpus.\nTHIS is the third document in the corpus."
  puts(((x = document_frequency("first", $corpus)); x.is_a?(Array) ? ("[" + x.map{ |x| if x.is_a?(Hash) then '{' + x.to_h.map{ |k,v| "#{k}: #{v.is_a?(String) ? v : v.to_s}" }.join(', ') + '}' else x.to_s end }.join(' ') + "]") : x.to_s))
  $idf_val = inverse_document_frequency(1, 3, false)
  tf_idf(2, $idf_val)
end_time = Process.clock_gettime(Process::CLOCK_MONOTONIC, :nanosecond)
end_mem = _mem()
result = {"duration_us" => ((end_time - start) / 1000), "memory_bytes" => (end_mem - start_mem), "name" => "main"}
puts(JSON.pretty_generate(result))
