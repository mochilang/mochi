# Generated by Mochi transpiler v0.10.67 on 2025-08-16 19:42 +0700
$VERBOSE = nil
require 'json'

$now_seed = 0
$now_seeded = false
s = ENV['MOCHI_NOW_SEED']
if s && s != ''
  begin
    $now_seed = Integer(s)
    $now_seeded = true
  rescue StandardError
  end
end
if !$now_seeded && ENV['MOCHI_BENCHMARK']
  $now_seeded = true
end
def _now()
  if $now_seeded
    $now_seed = ($now_seed * 1_664_525 + 1_013_904_223) % 2_147_483_647
    $now_seed
  else
    Process.clock_gettime(Process::CLOCK_MONOTONIC, :nanosecond)
  end
end


require 'objspace'
def _mem()
  ObjectSpace.memsize_of_all
end


def _idx(arr, idx)
  return nil if arr.nil?
  if arr.is_a?(Array) && idx.is_a?(Numeric)
    return nil if idx < 0 || idx >= arr.length
  end
  arr[idx]
end


def _pow(a, b)
  res = (a.nil? ? 0 : a) ** (b.nil? ? 0 : b)
  res.is_a?(Float) && res == res.to_i ? res.to_i : res
end


def _len(x)
  x.respond_to?(:length) ? x.length : 0
end


def _has(obj, key)
  if obj.is_a?(Hash)
    obj.key?(key)
  elsif obj.respond_to?(:include?)
    obj.include?(key)
  elsif obj.respond_to?(:to_h)
    k = key.respond_to?(:to_sym) ? key.to_sym : key
    obj.to_h.key?(k)
  else
    false
  end
end


def _add(a, b)
  if a.is_a?(Array) && b.is_a?(String)
    a.join + b
  elsif a.is_a?(String) && b.is_a?(Array)
    a + b.join
  elsif a.is_a?(Array) && !b.is_a?(Array)
    a + [b]
  elsif !a.is_a?(Array) && b.is_a?(Array)
    [a] + b
  elsif a.is_a?(String) || b.is_a?(String)
    a.to_s + b.to_s
  else
    (a.nil? ? 0 : a) + (b.nil? ? 0 : b)
  end
end


def _append(arr, x)
  x = x.clone if x.is_a?(Array)
  (arr || []) + [x]
end


def _eq(a, b)
  if a.is_a?(Float) || b.is_a?(Float)
    diff = (a.to_f - b.to_f).abs
    scale = [a.to_f.abs, b.to_f.abs].max
    scale = 1.0 if scale == 0.0
    diff <= 1e-6 * scale
  else
    a == b
  end
end


def _padStart(s, len, ch)
  s.to_s.rjust(len, ch)
end


def _padEnd(s, len, ch)
  s.to_s.ljust(len, ch)
end


def _str(x)
  if x.is_a?(Array)
    x.map { |e| _str(e) }.join(' ')
  elsif x.is_a?(Float)
    s = x.to_s
    if s.include?('e') || s.include?('E')
      s
    elsif x == x.to_i
      x.to_i.to_s
    else
      s
    end
  else
    x.to_s
  end
end


class String
  alias each each_char
end


def panic(msg)
  raise RuntimeError, msg
end

__name__ = '__main__'
start_mem = _mem()
start = Process.clock_gettime(Process::CLOCK_MONOTONIC, :nanosecond)
  def dot(x, y)
    sum = 0.0
    i = 0
    while i < _len(x)
      sum = _add(sum, (__tmp1 = x; __tmp1.is_a?(Hash) ? __tmp1[i] : _idx(__tmp1, i)) * (__tmp2 = y; __tmp2.is_a?(Hash) ? __tmp2[i] : _idx(__tmp2, i)))
      i = _add(i, 1)
    end
    return sum
  end
  def run_steep_gradient_descent(data_x, data_y, len_data, alpha, theta)
    gradients = []
    j = 0
    while j < _len(theta)
      gradients = _append(gradients, 0.0)
      j = _add(j, 1)
    end
    i = 0
    while i < len_data
      prediction = dot(theta, (__tmp3 = data_x; __tmp3.is_a?(Hash) ? __tmp3[i] : _idx(__tmp3, i)))
      error = prediction - (__tmp4 = data_y; __tmp4.is_a?(Hash) ? __tmp4[i] : _idx(__tmp4, i))
      k = 0
      while k < _len(theta)
        gradients[k] = _add((__tmp5 = gradients; __tmp5.is_a?(Hash) ? __tmp5[k] : _idx(__tmp5, k)), error * (__tmp6 = (__tmp7 = data_x; __tmp7.is_a?(Hash) ? __tmp7[i] : _idx(__tmp7, i)); __tmp6.is_a?(Hash) ? __tmp6[k] : _idx(__tmp6, k)))
        k = _add(k, 1)
      end
      i = _add(i, 1)
    end
    t = []
    g = 0
    while g < _len(theta)
      t = _append(t, (__tmp8 = theta; __tmp8.is_a?(Hash) ? __tmp8[g] : _idx(__tmp8, g)) - (alpha / len_data) * (__tmp9 = gradients; __tmp9.is_a?(Hash) ? __tmp9[g] : _idx(__tmp9, g)))
      g = _add(g, 1)
    end
    return t
  end
  def sum_of_square_error(data_x, data_y, len_data, theta)
    total = 0.0
    i = 0
    while i < len_data
      prediction = dot(theta, (__tmp10 = data_x; __tmp10.is_a?(Hash) ? __tmp10[i] : _idx(__tmp10, i)))
      diff = prediction - (__tmp11 = data_y; __tmp11.is_a?(Hash) ? __tmp11[i] : _idx(__tmp11, i))
      total = _add(total, diff * diff)
      i = _add(i, 1)
    end
    return total / (2.0 * len_data)
  end
  def run_linear_regression(data_x, data_y)
    iterations = 10
    alpha = 0.01
    no_features = _len((__tmp12 = data_x; __tmp12.is_a?(Hash) ? __tmp12[0] : _idx(__tmp12, 0)))
    len_data = _len(data_x)
    theta = []
    i = 0
    while i < no_features
      theta = _append(theta, 0.0)
      i = _add(i, 1)
    end
    iter = 0
    while iter < iterations
      theta = run_steep_gradient_descent(data_x, data_y, len_data, alpha, theta)
      error = sum_of_square_error(data_x, data_y, len_data, theta)
      puts(_add(_add(_add("At Iteration ", _str(_add(iter, 1))), " - Error is "), _str(error)))
      iter = _add(iter, 1)
    end
    return theta
  end
  def absf(x)
    if x < 0.0
      return -x
    else
      return x
    end
  end
  def mean_absolute_error(predicted_y, original_y)
    total = 0.0
    i = 0
    while i < _len(predicted_y)
      diff = absf((__tmp13 = predicted_y; __tmp13.is_a?(Hash) ? __tmp13[i] : _idx(__tmp13, i)) - (__tmp14 = original_y; __tmp14.is_a?(Hash) ? __tmp14[i] : _idx(__tmp14, i)))
      total = _add(total, diff)
      i = _add(i, 1)
    end
    return total / _len(predicted_y)
  end
  $data_x = [[1.0, 1.0], [1.0, 2.0], [1.0, 3.0]]
  $data_y = [1.0, 2.0, 3.0]
  $theta = run_linear_regression($data_x, $data_y)
  puts("Resultant Feature vector :")
  $i = 0
  while $i < _len($theta)
    puts(_str((__tmp15 = $theta; __tmp15.is_a?(Hash) ? __tmp15[$i] : _idx(__tmp15, $i))))
    $i = _add($i, 1)
  end
  $predicted_y = [3.0, -0.5, 2.0, 7.0]
  $original_y = [2.5, 0.0, 2.0, 8.0]
  $mae = mean_absolute_error($predicted_y, $original_y)
  puts(_add("Mean Absolute Error : ", _str($mae)))
end_time = Process.clock_gettime(Process::CLOCK_MONOTONIC, :nanosecond)
end_mem = _mem()
result = {"duration_us" => ((end_time - start) / 1000), "memory_bytes" => (end_mem - start_mem), "name" => "main"}
puts(JSON.pretty_generate(result))
