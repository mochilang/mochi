# [Huffman's Greed](https://www.spoj.com/problems/GREEDULM/)

## Problem Summary
Given `n` keys in sorted order, the frequency of searching for each key `p1..pn` and the frequency of unsuccessful searches in the gaps `q0..qn` are provided (all as integers).  Construct a binary search tree storing the keys that minimises the expected number of comparisons when searching.  Output that minimal expectation multiplied by the sum of all frequencies.

## Algorithm
We use the standard dynamic programming solution for the optimal binary search tree.

1. Read `p[0..n-1]` and `q[0..n]` from the input.
2. Initialise two `(n+1)×(n+1)` tables `e` and `w`:
   - `e[i][i] = 0` represents the cost of an empty subtree.
   - `w[i][i] = q[i]` is the total frequency within interval `i..i`.
3. For each length `len` from `1` to `n` and each starting index `i`:
   - let `j = i + len`;
   - update the accumulated weight `w[i][j] = w[i][j-1] + p[j-1] + q[j]`;
   - set `e[i][j]` to the minimum over all roots `r` in `[i, j)` of
     `e[i][r] + e[r+1][j] + w[i][j]`.
4. The answer is `e[0][n]`.

`w[i][j]` equals the total frequency in the interval, so adding it once for each level correctly accounts for the increased depth of all nodes when joining subtrees under a new root.

## Correctness
We prove by induction on `len` that `e[i][j]` contains the minimal possible cost for keys in `[i, j)`.

- **Base:** For `len = 0`, `e[i][i] = 0`, the cost of an empty tree, which is minimal.
- **Step:** Assume the claim holds for all intervals of length `< len`. For an interval `[i, j)` of length `len`, the algorithm tries every possible root `r`. The left and right subtrees have lengths smaller than `len`, so by the induction hypothesis `e[i][r]` and `e[r+1][j]` are minimal. Adding `w[i][j]` accounts for increasing every node's depth by one when joining the subtrees under root `r`. Thus the minimum over all `r` gives the optimal cost for `[i, j)`.

By induction, `e[0][n]` is the minimal cost for all keys, which is exactly the required output.

## Complexity
The dynamic program considers `O(n^2)` intervals and, for each, checks up to `O(n)` possible roots. Hence the time complexity is `O(n^3)` and the memory usage is `O(n^2)`. With `n ≤ 200` both bounds are easily manageable.
